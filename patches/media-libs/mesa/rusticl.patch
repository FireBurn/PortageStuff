diff --git a/src/amd/llvm/ac_nir_to_llvm.c b/src/amd/llvm/ac_nir_to_llvm.c
index 69dc14c3cad..4d3fa0b2539 100644
--- a/src/amd/llvm/ac_nir_to_llvm.c
+++ b/src/amd/llvm/ac_nir_to_llvm.c
@@ -683,6 +683,23 @@ static bool visit_alu(struct ac_nir_context *ctx, const nir_alu_instr *instr)
    case nir_op_fmul:
       src[0] = ac_to_float(&ctx->ac, src[0]);
       src[1] = ac_to_float(&ctx->ac, src[1]);
+      if (nir_src_is_const(instr->src[0].src) && nir_src_as_float(instr->src[0].src) == 1.0) {
+         if (ac_get_type_size(def_type) == 8) {
+            result = ac_build_intrinsic(&ctx->ac, "llvm.canonicalize.f64", ctx->ac.f64, &src[1], 1, AC_FUNC_ATTR_READNONE);
+            break;
+         } else if (ac_get_type_size(def_type) == 4) {
+            result = ac_build_intrinsic(&ctx->ac, "llvm.canonicalize.f32", ctx->ac.f32, &src[1], 1, AC_FUNC_ATTR_READNONE);
+            break;
+         }
+      } else if (nir_src_is_const(instr->src[1].src) && nir_src_as_float(instr->src[1].src) == 1.0) {
+         if (ac_get_type_size(def_type) == 8) {
+            result = ac_build_intrinsic(&ctx->ac, "llvm.canonicalize.f64", ctx->ac.f64, &src[0], 1, AC_FUNC_ATTR_READNONE);
+            break;
+         } else if (ac_get_type_size(def_type) == 4) {
+            result = ac_build_intrinsic(&ctx->ac, "llvm.canonicalize.f32", ctx->ac.f32, &src[0], 1, AC_FUNC_ATTR_READNONE);
+            break;
+         }
+      }
       result = LLVMBuildFMul(ctx->ac.builder, src[0], src[1], "");
       break;
    case nir_op_fmulz:
@@ -997,7 +1014,6 @@ static bool visit_alu(struct ac_nir_context *ctx, const nir_alu_instr *instr)
       result = LLVMBuildUIToFP(ctx->ac.builder, src[0], ac_to_float_type(&ctx->ac, def_type), "");
       break;
    case nir_op_f2f16_rtz:
-   case nir_op_f2f16:
    case nir_op_f2fmp:
       src[0] = ac_to_float(&ctx->ac, src[0]);
 
@@ -1036,6 +1052,7 @@ static bool visit_alu(struct ac_nir_context *ctx, const nir_alu_instr *instr)
                LLVMBuildFPTrunc(ctx->ac.builder, src[0], ac_to_float_type(&ctx->ac, def_type), "");
       }
       break;
+   case nir_op_f2f16:
    case nir_op_f2f16_rtne:
    case nir_op_f2f32:
    case nir_op_f2f64:
@@ -2310,31 +2327,32 @@ static LLVMValueRef visit_load_ubo_buffer(struct ac_nir_context *ctx, nir_intrin
    if (ctx->abi->load_ubo)
       rsrc = ctx->abi->load_ubo(ctx->abi, rsrc);
 
-   /* Convert to a scalar 32-bit load. */
    if (instr->dest.ssa.bit_size == 64)
       num_components *= 2;
-   else if (instr->dest.ssa.bit_size == 16)
-      num_components = DIV_ROUND_UP(num_components, 2);
-   else if (instr->dest.ssa.bit_size == 8)
-      num_components = DIV_ROUND_UP(num_components, 4);
 
-   ret =
-      ac_build_buffer_load(&ctx->ac, rsrc, num_components, NULL, offset, NULL,
-                           ctx->ac.f32, 0, true, true);
+   if (instr->dest.ssa.bit_size == 16 || instr->dest.ssa.bit_size == 8) {
+      unsigned load_bytes = instr->dest.ssa.bit_size / 8;
+      LLVMValueRef *const results = alloca(num_components * sizeof(LLVMValueRef));
+      for (unsigned i = 0; i < num_components; ++i) {
+         LLVMValueRef immoffset = LLVMConstInt(ctx->ac.i32, load_bytes * i, 0);
 
-   /* Convert to the original type. */
-   if (instr->dest.ssa.bit_size == 64) {
-      ret = LLVMBuildBitCast(ctx->ac.builder, ret,
-                             LLVMVectorType(ctx->ac.i64, num_components / 2), "");
-   } else if (instr->dest.ssa.bit_size == 16) {
-      ret = LLVMBuildBitCast(ctx->ac.builder, ret,
-                             LLVMVectorType(ctx->ac.i16, num_components * 2), "");
-   } else if (instr->dest.ssa.bit_size == 8) {
-      ret = LLVMBuildBitCast(ctx->ac.builder, ret,
-                             LLVMVectorType(ctx->ac.i8, num_components * 4), "");
+         if (load_bytes == 1) {
+            results[i] =
+               ac_build_buffer_load_byte(&ctx->ac, rsrc, offset, immoffset, 0);
+         } else {
+            assert(load_bytes == 2);
+            results[i] =
+               ac_build_buffer_load_short(&ctx->ac, rsrc, offset, immoffset, 0);
+         }
+      }
+      ret = ac_build_gather_values(&ctx->ac, results, num_components);
+   } else {
+      ret =
+         ac_build_buffer_load(&ctx->ac, rsrc, num_components, NULL, offset, NULL, 0, 0, true, true);
+
+      ret = ac_trim_vector(&ctx->ac, ret, num_components);
    }
 
-   ret = ac_trim_vector(&ctx->ac, ret, instr->num_components);
    ret = LLVMBuildBitCast(ctx->ac.builder, ret, get_def_type(ctx, &instr->dest.ssa), "");
 
    return exit_waterfall(ctx, &wctx, ret);
diff --git a/src/amd/vulkan/radv_pipeline_rt.c b/src/amd/vulkan/radv_pipeline_rt.c
index 3006d24c9af..30f3ee8e427 100644
--- a/src/amd/vulkan/radv_pipeline_rt.c
+++ b/src/amd/vulkan/radv_pipeline_rt.c
@@ -856,7 +856,7 @@ parse_rt_stage(struct radv_device *device, const VkPipelineShaderStageCreateInfo
 
    NIR_PASS(_, shader, lower_rt_derefs);
 
-   NIR_PASS(_, shader, nir_lower_explicit_io, nir_var_function_temp,
+   NIR_PASS(_, shader, nir_lower_explicit_io, nir_var_function_temp, false,
             nir_address_format_32bit_offset);
 
    return shader;
diff --git a/src/amd/vulkan/radv_shader.c b/src/amd/vulkan/radv_shader.c
index e31c128c4f9..6de693ee863 100644
--- a/src/amd/vulkan/radv_shader.c
+++ b/src/amd/vulkan/radv_shader.c
@@ -1056,9 +1056,9 @@ radv_shader_spirv_to_nir(struct radv_device *device, const struct radv_pipeline_
    };
    NIR_PASS(_, nir, nir_opt_access, &opt_access_options);
 
-   NIR_PASS(_, nir, nir_lower_explicit_io, nir_var_mem_push_const, nir_address_format_32bit_offset);
+   NIR_PASS(_, nir, nir_lower_explicit_io, nir_var_mem_push_const, false, nir_address_format_32bit_offset);
 
-   NIR_PASS(_, nir, nir_lower_explicit_io, nir_var_mem_ubo | nir_var_mem_ssbo,
+   NIR_PASS(_, nir, nir_lower_explicit_io, nir_var_mem_ubo | nir_var_mem_ssbo, false,
             nir_address_format_vec2_index_32bit_offset);
 
    NIR_PASS(_, nir, lower_intrinsics, key);
@@ -1076,7 +1076,7 @@ radv_shader_spirv_to_nir(struct radv_device *device, const struct radv_pipeline_
       if (!nir->info.shared_memory_explicit_layout) {
          NIR_PASS(_, nir, nir_lower_vars_to_explicit_types, var_modes, shared_var_info);
       }
-      NIR_PASS(_, nir, nir_lower_explicit_io, var_modes, nir_address_format_32bit_offset);
+      NIR_PASS(_, nir, nir_lower_explicit_io, var_modes, false, nir_address_format_32bit_offset);
 
       if (nir->info.zero_initialize_shared_memory && nir->info.shared_size > 0) {
          const unsigned chunk_size = 16; /* max single store size */
@@ -1085,7 +1085,7 @@ radv_shader_spirv_to_nir(struct radv_device *device, const struct radv_pipeline_
       }
    }
 
-   NIR_PASS(_, nir, nir_lower_explicit_io, nir_var_mem_global | nir_var_mem_constant,
+   NIR_PASS(_, nir, nir_lower_explicit_io, nir_var_mem_global | nir_var_mem_constant, false,
             nir_address_format_64bit_global);
 
    /* Lower large variables that are always constant with load_constant
diff --git a/src/compiler/glsl/gl_nir_lower_buffers.c b/src/compiler/glsl/gl_nir_lower_buffers.c
index 12a2aebb858..0dfb4085b59 100644
--- a/src/compiler/glsl/gl_nir_lower_buffers.c
+++ b/src/compiler/glsl/gl_nir_lower_buffers.c
@@ -353,7 +353,7 @@ gl_nir_lower_buffers(nir_shader *shader,
     */
    if (progress) {
       nir_validate_shader(shader, "Lowering buffer interface derefs");
-      nir_lower_explicit_io(shader, nir_var_mem_ubo | nir_var_mem_ssbo,
+      nir_lower_explicit_io(shader, nir_var_mem_ubo | nir_var_mem_ssbo, false,
                             nir_address_format_32bit_index_offset);
    }
 
diff --git a/src/compiler/nir/nir.h b/src/compiler/nir/nir.h
index af5fbfb6f55..9a67e8c0605 100644
--- a/src/compiler/nir/nir.h
+++ b/src/compiler/nir/nir.h
@@ -4832,6 +4832,7 @@ void nir_lower_explicit_io_instr(struct nir_builder *b,
 
 bool nir_lower_explicit_io(nir_shader *shader,
                            nir_variable_mode modes,
+                           bool skip_samplers,
                            nir_address_format);
 
 typedef struct nir_lower_shader_calls_options {
@@ -5490,7 +5491,7 @@ bool nir_lower_ssa_defs_to_regs_block(nir_block *block);
 bool nir_rematerialize_derefs_in_use_blocks_impl(nir_function_impl *impl);
 
 bool nir_lower_samplers(nir_shader *shader);
-bool nir_lower_cl_images(nir_shader *shader);
+bool nir_lower_cl_images(nir_shader *shader, bool lower_derefs);
 bool nir_dedup_inline_samplers(nir_shader *shader);
 bool nir_lower_ssbo(nir_shader *shader);
 
diff --git a/src/compiler/nir/nir_lower_cl_images.c b/src/compiler/nir/nir_lower_cl_images.c
index 8b4423fff47..0498607bcef 100644
--- a/src/compiler/nir/nir_lower_cl_images.c
+++ b/src/compiler/nir/nir_lower_cl_images.c
@@ -108,7 +108,7 @@ nir_dedup_inline_samplers(nir_shader *nir)
 }
 
 bool
-nir_lower_cl_images(nir_shader *shader)
+nir_lower_cl_images(nir_shader *shader, bool lower_deref)
 {
    nir_function_impl *impl = nir_shader_get_entrypoint(shader);
 
@@ -155,6 +155,12 @@ nir_lower_cl_images(nir_shader *shader)
    nir_builder b;
    nir_builder_init(&b, impl);
 
+   /* don't need any lowering if we can keep the derefs */
+   if (!lower_deref) {
+      nir_metadata_preserve(impl, nir_metadata_all);
+      return false;
+   }
+
    bool progress = false;
    nir_foreach_block_reverse(block, impl) {
       nir_foreach_instr_reverse_safe(instr, block) {
diff --git a/src/compiler/nir/nir_lower_io.c b/src/compiler/nir/nir_lower_io.c
index 1776648c456..d5306b6591d 100644
--- a/src/compiler/nir/nir_lower_io.c
+++ b/src/compiler/nir/nir_lower_io.c
@@ -925,7 +925,7 @@ static nir_ssa_def *
 build_addr_for_var(nir_builder *b, nir_variable *var,
                    nir_address_format addr_format)
 {
-   assert(var->data.mode & (nir_var_uniform | nir_var_mem_shared |
+   assert(var->data.mode & (nir_var_uniform | nir_var_image | nir_var_mem_shared |
                             nir_var_mem_task_payload |
                             nir_var_mem_global |
                             nir_var_shader_temp | nir_var_function_temp |
@@ -1498,6 +1498,10 @@ build_explicit_io_load(nir_builder *b, nir_intrinsic_instr *intrin,
    if (op == nir_intrinsic_load_constant) {
       nir_intrinsic_set_base(load, 0);
       nir_intrinsic_set_range(load, b->shader->constant_data_size);
+   } else if (op == nir_intrinsic_load_kernel_input) {
+      nir_variable *var = nir_deref_instr_get_variable(deref);
+      nir_intrinsic_set_base(load, 0);
+      nir_intrinsic_set_range(load, glsl_get_explicit_size(var->type, false));
    } else if (mode == nir_var_mem_push_const) {
       /* Push constants are required to be able to be chased back to the
        * variable so we can provide a base/range.
@@ -2205,7 +2209,7 @@ lower_explicit_io_mode_check(nir_builder *b, nir_intrinsic_instr *intrin,
 
 static bool
 nir_lower_explicit_io_impl(nir_function_impl *impl, nir_variable_mode modes,
-                           nir_address_format addr_format)
+                           bool skip_samplers, nir_address_format addr_format)
 {
    bool progress = false;
 
@@ -2222,6 +2226,8 @@ nir_lower_explicit_io_impl(nir_function_impl *impl, nir_variable_mode modes,
          case nir_instr_type_deref: {
             nir_deref_instr *deref = nir_instr_as_deref(instr);
             if (nir_deref_mode_is_in_set(deref, modes)) {
+               if (glsl_type_is_sampler(deref->var->type) && skip_samplers)
+                  break;
                lower_explicit_io_deref(&b, deref, addr_format);
                progress = true;
             }
@@ -2352,13 +2358,13 @@ nir_lower_explicit_io_impl(nir_function_impl *impl, nir_variable_mode modes,
  */
 bool
 nir_lower_explicit_io(nir_shader *shader, nir_variable_mode modes,
-                      nir_address_format addr_format)
+                      bool skip_samplers, nir_address_format addr_format)
 {
    bool progress = false;
 
    nir_foreach_function(function, shader) {
       if (function->impl &&
-          nir_lower_explicit_io_impl(function->impl, modes, addr_format))
+          nir_lower_explicit_io_impl(function->impl, modes, skip_samplers, addr_format))
          progress = true;
    }
 
diff --git a/src/compiler/nir/nir_opt_algebraic.py b/src/compiler/nir/nir_opt_algebraic.py
index cc55b866657..d1230510de1 100644
--- a/src/compiler/nir/nir_opt_algebraic.py
+++ b/src/compiler/nir/nir_opt_algebraic.py
@@ -1053,7 +1053,7 @@ for s in [8, 16, 32, 64]:
        (('ineg', ('b2i{}'.format(s), 'a@{}'.format(s))), a),
 
        # SM5 32-bit shifts are defined to use the 5 least significant bits (or 4 bits for 16 bits)
-       (('ishl', 'a@{}'.format(s), ('iand', s - 1, b)), ('ishl', a, b)),
+#       (('ishl', 'a@{}'.format(s), ('iand', s - 1, b)), ('ishl', a, b)),
        (('ishr', 'a@{}'.format(s), ('iand', s - 1, b)), ('ishr', a, b)),
        (('ushr', 'a@{}'.format(s), ('iand', s - 1, b)), ('ushr', a, b)),
        (('ushr', 'a@{}'.format(s), ('ishl(is_used_once)', ('iand', b, 1), last_shift_bit)), ('ushr', a, ('ishl', b, last_shift_bit))),
@@ -1266,8 +1266,10 @@ optimizations.extend([
    (('ior', ('ushr@16', a, b), ('ishl@16', a, ('isub', 16, b))), ('uror', a, b), '!options->lower_rotate'),
    (('ior', ('ushr@32', a, b), ('ishl@32', a, ('iadd', 32, ('ineg', b)))), ('uror', a, b), '!options->lower_rotate'),
    (('ior', ('ushr@32', a, b), ('ishl@32', a, ('isub', 32, b))), ('uror', a, b), '!options->lower_rotate'),
+   (('urol@8',  a, b), ('ior', ('ishl', a, b), ('ushr', a, ('isub',  8, b))), 'options->lower_rotate'),
    (('urol@16', a, b), ('ior', ('ishl', a, b), ('ushr', a, ('isub', 16, b))), 'options->lower_rotate'),
    (('urol@32', a, b), ('ior', ('ishl', a, b), ('ushr', a, ('isub', 32, b))), 'options->lower_rotate'),
+   (('urol@64', a, b), ('ior', ('ishl', a, b), ('ushr', a, ('isub', 64, b))), 'options->lower_rotate'),
    (('uror@16', a, b), ('ior', ('ushr', a, b), ('ishl', a, ('isub', 16, b))), 'options->lower_rotate'),
    (('uror@32', a, b), ('ior', ('ushr', a, b), ('ishl', a, ('isub', 32, b))), 'options->lower_rotate'),
    # Exponential/logarithmic identities
@@ -2600,6 +2602,11 @@ late_optimizations = [
    (('~feq', ('fadd(is_used_once)', a, b), 0.0), ('feq', a, ('fneg', b))),
    (('~fneu', ('fadd(is_used_once)', a, b), 0.0), ('fneu', a, ('fneg', b))),
 
+   (('imul_high@8' , a, b), ('i2i8',  ('ishr', ('imul', ('i2i32', a), ('i2i32', b)),  8))),
+   (('umul_high@8' , a, b), ('u2u8',  ('ushr', ('imul', ('u2u32', a), ('u2u32', b)),  8))),
+   (('imul_high@16', a, b), ('i2i16', ('ishr', ('imul', ('i2i32', a), ('i2i32', b)), 16))),
+   (('umul_high@16', a, b), ('u2u16', ('ushr', ('imul', ('u2u32', a), ('u2u32', b)), 16))),
+
    # If either source must be finite, then the original (a+b) cannot produce
    # NaN due to Inf-Inf.  The patterns and the replacements produce the same
    # result if b is NaN. Therefore, the replacements are exact.
diff --git a/src/compiler/spirv/vtn_opencl.c b/src/compiler/spirv/vtn_opencl.c
index c41628fd475..5c2ec15a15f 100644
--- a/src/compiler/spirv/vtn_opencl.c
+++ b/src/compiler/spirv/vtn_opencl.c
@@ -297,7 +297,6 @@ static const struct {
    REMAP(Normalize, "normalize"),
    REMAP(Degrees, "degrees"),
    REMAP(Radians, "radians"),
-   REMAP(Rotate, "rotate"),
    REMAP(Smoothstep, "smoothstep"),
    REMAP(Step, "step"),
 
@@ -553,6 +552,8 @@ handle_special(struct vtn_builder *b, uint32_t opcode,
       if (nb->shader->options->lower_ffma32 && srcs[0]->bit_size == 32)
          break;
       return nir_ffma(nb, srcs[0], srcs[1], srcs[2]);
+   case OpenCLstd_Rotate:
+         return nir_urol(nb, srcs[0], nir_iand(nb, nir_imm_int(nb, srcs[0]->bit_size - 1), nir_u2u(nb, srcs[1], 32)));
    default:
       break;
    }
diff --git a/src/gallium/auxiliary/driver_trace/tr_dump_state.c b/src/gallium/auxiliary/driver_trace/tr_dump_state.c
index 036e43c0ad8..20b507c4efb 100644
--- a/src/gallium/auxiliary/driver_trace/tr_dump_state.c
+++ b/src/gallium/auxiliary/driver_trace/tr_dump_state.c
@@ -349,8 +349,7 @@ void trace_dump_compute_state(const struct pipe_compute_state *state)
    }
    trace_dump_member_end();
 
-   trace_dump_member(uint, state, req_local_mem);
-   trace_dump_member(uint, state, req_private_mem);
+   trace_dump_member(uint, state, static_shared_mem);
    trace_dump_member(uint, state, req_input_mem);
 
    trace_dump_struct_end();
@@ -1082,6 +1081,7 @@ void trace_dump_grid_info(const struct pipe_grid_info *state)
 
    trace_dump_member(uint, state, pc);
    trace_dump_member(ptr, state, input);
+   trace_dump_member(uint, state, variable_shared_mem);
 
    trace_dump_member_begin("block");
    trace_dump_array(uint, state->block, ARRAY_SIZE(state->block));
diff --git a/src/gallium/drivers/freedreno/a6xx/fd6_compute.c b/src/gallium/drivers/freedreno/a6xx/fd6_compute.c
index 774e1603cb6..9d9df192f94 100644
--- a/src/gallium/drivers/freedreno/a6xx/fd6_compute.c
+++ b/src/gallium/drivers/freedreno/a6xx/fd6_compute.c
@@ -42,7 +42,8 @@
 /* maybe move to fd6_program? */
 static void
 cs_program_emit(struct fd_context *ctx, struct fd_ringbuffer *ring,
-                struct ir3_shader_variant *v) assert_dt
+                struct ir3_shader_variant *v,
+                uint32_t variable_shared_size) assert_dt
 {
    const struct ir3_info *i = &v->info;
    enum a6xx_threadsize thrsz = i->double_threadsize ? THREAD128 : THREAD64;
@@ -71,7 +72,8 @@ cs_program_emit(struct fd_context *ctx, struct fd_ringbuffer *ring,
                COND(v->mergedregs, A6XX_SP_CS_CTRL_REG0_MERGEDREGS) |
                A6XX_SP_CS_CTRL_REG0_BRANCHSTACK(ir3_shader_branchstack_hw(v)));
 
-   uint32_t shared_size = MAX2(((int)v->cs.req_local_mem - 1) / 1024, 1);
+   uint32_t shared_size =
+      MAX2(((int)v->cs.req_local_mem + variable_shared_size- 1) / 1024, 1);
    OUT_PKT4(ring, REG_A6XX_SP_CS_UNKNOWN_A9B1, 1);
    OUT_RING(ring, A6XX_SP_CS_UNKNOWN_A9B1_SHARED_SIZE(shared_size) |
                      A6XX_SP_CS_UNKNOWN_A9B1_UNK6);
@@ -125,7 +127,7 @@ fd6_launch_grid(struct fd_context *ctx, const struct pipe_grid_info *info) in_dt
       return;
 
    if (ctx->dirty_shader[PIPE_SHADER_COMPUTE] & FD_DIRTY_SHADER_PROG)
-      cs_program_emit(ctx, ring, v);
+      cs_program_emit(ctx, ring, v, info->variable_shared_mem);
 
    fd6_emit_cs_state(ctx, ring, v);
    fd6_emit_cs_consts(v, ring, ctx, info);
diff --git a/src/gallium/drivers/freedreno/ir3/ir3_gallium.c b/src/gallium/drivers/freedreno/ir3/ir3_gallium.c
index 57788c2e788..f2a574ac9c9 100644
--- a/src/gallium/drivers/freedreno/ir3/ir3_gallium.c
+++ b/src/gallium/drivers/freedreno/ir3/ir3_gallium.c
@@ -315,7 +315,7 @@ ir3_shader_compute_state_create(struct pipe_context *pctx,
                               .real_wavesize = IR3_SINGLE_OR_DOUBLE,
                           }, NULL);
    shader->cs.req_input_mem = align(cso->req_input_mem, 4) / 4;     /* byte->dword */
-   shader->cs.req_local_mem = cso->req_local_mem;
+   shader->cs.req_local_mem = cso->static_shared_mem;
 
    struct ir3_shader_state *hwcso = calloc(1, sizeof(*hwcso));
 
diff --git a/src/gallium/drivers/iris/iris_context.c b/src/gallium/drivers/iris/iris_context.c
index 8cbc4c702ec..489214cdc09 100644
--- a/src/gallium/drivers/iris/iris_context.c
+++ b/src/gallium/drivers/iris/iris_context.c
@@ -83,6 +83,7 @@ iris_lost_context_state(struct iris_batch *batch)
    memset(&ice->shaders.urb, 0, sizeof(ice->shaders.urb));
    memset(ice->state.last_block, 0, sizeof(ice->state.last_block));
    memset(ice->state.last_grid, 0, sizeof(ice->state.last_grid));
+   ice->state.last_grid_dim = 0;
    batch->last_binder_address = ~0ull;
    batch->last_aux_map_state = 0;
    batch->screen->vtbl.lost_genx_state(ice, batch);
diff --git a/src/gallium/drivers/iris/iris_context.h b/src/gallium/drivers/iris/iris_context.h
index 699ad379ed2..d03afdeea8f 100644
--- a/src/gallium/drivers/iris/iris_context.h
+++ b/src/gallium/drivers/iris/iris_context.h
@@ -756,6 +756,8 @@ struct iris_context {
 
       /** The last compute grid size */
       uint32_t last_grid[3];
+      /** The last compute grid dimensions */
+      uint32_t last_grid_dim;
       /** Reference to the BO containing the compute grid size */
       struct iris_state_ref grid_size;
       /** Reference to the SURFACE_STATE for the compute grid resource */
diff --git a/src/gallium/drivers/iris/iris_draw.c b/src/gallium/drivers/iris/iris_draw.c
index 2bf23ab1b3e..04680097d80 100644
--- a/src/gallium/drivers/iris/iris_draw.c
+++ b/src/gallium/drivers/iris/iris_draw.c
@@ -408,6 +408,12 @@ iris_launch_grid(struct pipe_context *ctx, const struct pipe_grid_info *grid)
       ice->state.shaders[MESA_SHADER_COMPUTE].sysvals_need_upload = true;
    }
 
+   if (ice->state.last_grid_dim != grid->work_dim) {
+      ice->state.last_grid_dim = grid->work_dim;
+      ice->state.stage_dirty |= IRIS_STAGE_DIRTY_CONSTANTS_CS;
+      ice->state.shaders[MESA_SHADER_COMPUTE].sysvals_need_upload = true;
+   }
+
    iris_update_grid_size_resource(ice, grid);
 
    iris_binder_reserve_compute(ice);
diff --git a/src/gallium/drivers/iris/iris_program.c b/src/gallium/drivers/iris/iris_program.c
index 4d909b8bb01..49f40ac4ef2 100644
--- a/src/gallium/drivers/iris/iris_program.c
+++ b/src/gallium/drivers/iris/iris_program.c
@@ -2534,7 +2534,7 @@ iris_create_compute_state(struct pipe_context *ctx,
    struct iris_uncompiled_shader *ish =
       iris_create_uncompiled_shader(screen, nir, NULL);
    ish->kernel_input_size = state->req_input_mem;
-   ish->kernel_shared_size = state->req_local_mem;
+   ish->kernel_shared_size = state->static_shared_mem;
 
    // XXX: disallow more than 64KB of shared variables
 
diff --git a/src/gallium/drivers/iris/iris_state.c b/src/gallium/drivers/iris/iris_state.c
index 5fa58a9a69c..b8648a341f3 100644
--- a/src/gallium/drivers/iris/iris_state.c
+++ b/src/gallium/drivers/iris/iris_state.c
@@ -7372,7 +7372,7 @@ iris_upload_gpgpu_walker(struct iris_context *ice,
 
       iris_pack_state(GENX(INTERFACE_DESCRIPTOR_DATA), desc, idd) {
          idd.SharedLocalMemorySize =
-            encode_slm_size(GFX_VER, ish->kernel_shared_size);
+            encode_slm_size(GFX_VER, ish->kernel_shared_size + grid->variable_shared_mem);
          idd.KernelStartPointer =
             KSP(shader) + brw_cs_prog_data_prog_offset(cs_prog_data,
                                                        dispatch.simd_size);
diff --git a/src/gallium/drivers/llvmpipe/lp_state_cs.c b/src/gallium/drivers/llvmpipe/lp_state_cs.c
index 8a2c28a7b34..8554a7f45f6 100644
--- a/src/gallium/drivers/llvmpipe/lp_state_cs.c
+++ b/src/gallium/drivers/llvmpipe/lp_state_cs.c
@@ -500,7 +500,6 @@ llvmpipe_create_compute_state(struct pipe_context *pipe,
    shader->no = cs_no++;
 
    shader->base.type = templ->ir_type;
-   shader->req_local_mem = templ->req_local_mem;
    if (templ->ir_type == PIPE_SHADER_IR_NIR_SERIALIZED) {
       struct blob_reader reader;
       const struct pipe_binary_program_header *hdr = templ->prog;
@@ -1428,7 +1427,7 @@ llvmpipe_launch_grid(struct pipe_context *pipe,
    job_info.block_size[1] = info->block[1];
    job_info.block_size[2] = info->block[2];
    job_info.work_dim = info->work_dim;
-   job_info.req_local_mem = llvmpipe->cs->req_local_mem;
+   job_info.req_local_mem = llvmpipe->cs->req_local_mem + info->variable_shared_mem;
    job_info.zero_initialize_shared_memory = llvmpipe->cs->zero_initialize_shared_memory;
    job_info.current = &llvmpipe->csctx->cs.current;
 
diff --git a/src/gallium/drivers/nouveau/nv50/nv50_compute.c b/src/gallium/drivers/nouveau/nv50/nv50_compute.c
index 1213effd53d..e6a597c8182 100644
--- a/src/gallium/drivers/nouveau/nv50/nv50_compute.c
+++ b/src/gallium/drivers/nouveau/nv50/nv50_compute.c
@@ -579,8 +579,9 @@ nv50_launch_grid(struct pipe_context *pipe, const struct pipe_grid_info *info)
    BEGIN_NV04(push, NV50_CP(CP_START_ID), 1);
    PUSH_DATA (push, cp->code_base);
 
+   int shared_size = cp->cp.smem_size + info->variable_shared_mem + cp->parm_size + 0x14;
    BEGIN_NV04(push, NV50_CP(SHARED_SIZE), 1);
-   PUSH_DATA (push, align(cp->cp.smem_size + cp->parm_size + 0x14, 0x40));
+   PUSH_DATA (push, align(shared_size, 0x40));
    BEGIN_NV04(push, NV50_CP(CP_REG_ALLOC_TEMP), 1);
    PUSH_DATA (push, cp->max_gpr);
 
diff --git a/src/gallium/drivers/nouveau/nv50/nv50_program.h b/src/gallium/drivers/nouveau/nv50/nv50_program.h
index d89cd9d13d2..f2b945cd0b1 100644
--- a/src/gallium/drivers/nouveau/nv50/nv50_program.h
+++ b/src/gallium/drivers/nouveau/nv50/nv50_program.h
@@ -107,7 +107,6 @@ struct nv50_program {
    } gp;
 
    struct {
-      uint32_t lmem_size; /* local memory (TGSI PRIVATE resource) size */
       uint32_t smem_size; /* shared memory (TGSI LOCAL resource) size */
       struct nv50_gmem_state gmem[NV50_MAX_GLOBALS];
    } cp;
diff --git a/src/gallium/drivers/nouveau/nv50/nv50_state.c b/src/gallium/drivers/nouveau/nv50/nv50_state.c
index 21758408253..3161549c815 100644
--- a/src/gallium/drivers/nouveau/nv50/nv50_state.c
+++ b/src/gallium/drivers/nouveau/nv50/nv50_state.c
@@ -861,8 +861,7 @@ nv50_cp_state_create(struct pipe_context *pipe,
       return NULL;
    }
 
-   prog->cp.smem_size = cso->req_local_mem;
-   prog->cp.lmem_size = cso->req_private_mem;
+   prog->cp.smem_size = cso->static_shared_mem;
    prog->parm_size = cso->req_input_mem;
 
    return (void *)prog;
diff --git a/src/gallium/drivers/nouveau/nvc0/nvc0_compute.c b/src/gallium/drivers/nouveau/nvc0/nvc0_compute.c
index b2b00f4ba98..237b74ef4b5 100644
--- a/src/gallium/drivers/nouveau/nvc0/nvc0_compute.c
+++ b/src/gallium/drivers/nouveau/nvc0/nvc0_compute.c
@@ -441,12 +441,12 @@ nvc0_launch_grid(struct pipe_context *pipe, const struct pipe_grid_info *info)
    PUSH_DATA (push, cp->code_base);
 
    BEGIN_NVC0(push, NVC0_CP(LOCAL_POS_ALLOC), 3);
-   PUSH_DATA (push, (cp->hdr[1] & 0xfffff0) + align(cp->cp.lmem_size, 0x10));
+   PUSH_DATA (push, cp->hdr[1] & 0xfffff0);
    PUSH_DATA (push, 0);
    PUSH_DATA (push, 0x800); /* WARP_CSTACK_SIZE */
 
    BEGIN_NVC0(push, NVC0_CP(SHARED_SIZE), 3);
-   PUSH_DATA (push, align(cp->cp.smem_size, 0x100));
+   PUSH_DATA (push, align(cp->cp.smem_size + info->variable_shared_mem, 0x100));
    PUSH_DATA (push, info->block[0] * info->block[1] * info->block[2]);
    PUSH_DATA (push, cp->num_barriers);
    BEGIN_NVC0(push, NVC0_CP(CP_GPR_ALLOC), 1);
diff --git a/src/gallium/drivers/nouveau/nvc0/nvc0_program.h b/src/gallium/drivers/nouveau/nvc0/nvc0_program.h
index 74996fbc867..536841f60f7 100644
--- a/src/gallium/drivers/nouveau/nvc0/nvc0_program.h
+++ b/src/gallium/drivers/nouveau/nvc0/nvc0_program.h
@@ -60,7 +60,6 @@ struct nvc0_program {
       uint32_t tess_mode; /* ~0 if defined by the other stage */
    } tp;
    struct {
-      uint32_t lmem_size; /* local memory (TGSI PRIVATE resource) size */
       uint32_t smem_size; /* shared memory (TGSI LOCAL resource) size */
    } cp;
    uint8_t num_barriers;
diff --git a/src/gallium/drivers/nouveau/nvc0/nvc0_state.c b/src/gallium/drivers/nouveau/nvc0/nvc0_state.c
index 2f4a9c117d2..9eb442c3c10 100644
--- a/src/gallium/drivers/nouveau/nvc0/nvc0_state.c
+++ b/src/gallium/drivers/nouveau/nvc0/nvc0_state.c
@@ -741,8 +741,7 @@ nvc0_cp_state_create(struct pipe_context *pipe,
    prog->type = PIPE_SHADER_COMPUTE;
    prog->pipe.type = cso->ir_type;
 
-   prog->cp.smem_size = cso->req_local_mem;
-   prog->cp.lmem_size = cso->req_private_mem;
+   prog->cp.smem_size = cso->static_shared_mem;
    prog->parm_size = cso->req_input_mem;
 
    switch(cso->ir_type) {
diff --git a/src/gallium/drivers/nouveau/nvc0/nve4_compute.c b/src/gallium/drivers/nouveau/nvc0/nve4_compute.c
index 23d157fd4bf..e673984bc87 100644
--- a/src/gallium/drivers/nouveau/nvc0/nve4_compute.c
+++ b/src/gallium/drivers/nouveau/nvc0/nve4_compute.c
@@ -627,6 +627,7 @@ nve4_compute_setup_launch_desc(struct nvc0_context *nvc0, uint32_t *qmd,
 {
    const struct nvc0_screen *screen = nvc0->screen;
    const struct nvc0_program *cp = nvc0->compprog;
+   uint32_t shared_size = cp->cp.smem_size + info->variable_shared_mem;
 
    NVA0C0_QMDV00_06_DEF_SET(qmd, INVALIDATE_TEXTURE_HEADER_CACHE, TRUE);
    NVA0C0_QMDV00_06_DEF_SET(qmd, INVALIDATE_TEXTURE_SAMPLER_CACHE, TRUE);
@@ -647,19 +648,16 @@ nve4_compute_setup_launch_desc(struct nvc0_context *nvc0, uint32_t *qmd,
    NVA0C0_QMDV00_06_VAL_SET(qmd, CTA_THREAD_DIMENSION1, info->block[1]);
    NVA0C0_QMDV00_06_VAL_SET(qmd, CTA_THREAD_DIMENSION2, info->block[2]);
 
-   NVA0C0_QMDV00_06_VAL_SET(qmd, SHARED_MEMORY_SIZE,
-                                 align(cp->cp.smem_size, 0x100));
-   NVA0C0_QMDV00_06_VAL_SET(qmd, SHADER_LOCAL_MEMORY_LOW_SIZE,
-                                 (cp->hdr[1] & 0xfffff0) +
-                                 align(cp->cp.lmem_size, 0x10));
+   NVA0C0_QMDV00_06_VAL_SET(qmd, SHARED_MEMORY_SIZE, align(shared_size, 0x100));
+   NVA0C0_QMDV00_06_VAL_SET(qmd, SHADER_LOCAL_MEMORY_LOW_SIZE, cp->hdr[1] & 0xfffff0);
    NVA0C0_QMDV00_06_VAL_SET(qmd, SHADER_LOCAL_MEMORY_HIGH_SIZE, 0);
    NVA0C0_QMDV00_06_VAL_SET(qmd, SHADER_LOCAL_MEMORY_CRS_SIZE, 0x800);
 
-   if (cp->cp.smem_size > (32 << 10))
+   if (shared_size > (32 << 10))
       NVA0C0_QMDV00_06_DEF_SET(qmd, L1_CONFIGURATION,
                                     DIRECTLY_ADDRESSABLE_MEMORY_SIZE_48KB);
    else
-   if (cp->cp.smem_size > (16 << 10))
+   if (shared_size > (16 << 10))
       NVA0C0_QMDV00_06_DEF_SET(qmd, L1_CONFIGURATION,
                                     DIRECTLY_ADDRESSABLE_MEMORY_SIZE_32KB);
    else
@@ -692,6 +690,7 @@ gp100_compute_setup_launch_desc(struct nvc0_context *nvc0, uint32_t *qmd,
 {
    const struct nvc0_screen *screen = nvc0->screen;
    const struct nvc0_program *cp = nvc0->compprog;
+   uint32_t shared_size = cp->cp.smem_size + info->variable_shared_mem;
 
    NVC0C0_QMDV02_01_VAL_SET(qmd, SM_GLOBAL_CACHING_ENABLE, 1);
    NVC0C0_QMDV02_01_DEF_SET(qmd, RELEASE_MEMBAR_TYPE, FE_SYSMEMBAR);
@@ -707,11 +706,8 @@ gp100_compute_setup_launch_desc(struct nvc0_context *nvc0, uint32_t *qmd,
    NVC0C0_QMDV02_01_VAL_SET(qmd, CTA_THREAD_DIMENSION1, info->block[1]);
    NVC0C0_QMDV02_01_VAL_SET(qmd, CTA_THREAD_DIMENSION2, info->block[2]);
 
-   NVC0C0_QMDV02_01_VAL_SET(qmd, SHARED_MEMORY_SIZE,
-                                 align(cp->cp.smem_size, 0x100));
-   NVC0C0_QMDV02_01_VAL_SET(qmd, SHADER_LOCAL_MEMORY_LOW_SIZE,
-                                 (cp->hdr[1] & 0xfffff0) +
-                                 align(cp->cp.lmem_size, 0x10));
+   NVC0C0_QMDV02_01_VAL_SET(qmd, SHARED_MEMORY_SIZE, align(shared_size, 0x100));
+   NVC0C0_QMDV02_01_VAL_SET(qmd, SHADER_LOCAL_MEMORY_LOW_SIZE, cp->hdr[1] & 0xfffff0);
    NVC0C0_QMDV02_01_VAL_SET(qmd, SHADER_LOCAL_MEMORY_HIGH_SIZE, 0);
    NVC0C0_QMDV02_01_VAL_SET(qmd, SHADER_LOCAL_MEMORY_CRS_SIZE, 0x800);
 
@@ -753,15 +749,13 @@ gv100_compute_setup_launch_desc(struct nvc0_context *nvc0, u32 *qmd,
    struct nvc0_program *cp = nvc0->compprog;
    struct nvc0_screen *screen = nvc0->screen;
    uint64_t entry = screen->text->offset + cp->code_base;
+   uint32_t shared_size = cp->cp.smem_size + info->variable_shared_mem;
 
    NVC3C0_QMDV02_02_VAL_SET(qmd, SM_GLOBAL_CACHING_ENABLE, 1);
    NVC3C0_QMDV02_02_DEF_SET(qmd, API_VISIBLE_CALL_LIMIT, NO_CHECK);
    NVC3C0_QMDV02_02_DEF_SET(qmd, SAMPLER_INDEX, INDEPENDENTLY);
-   NVC3C0_QMDV02_02_VAL_SET(qmd, SHARED_MEMORY_SIZE,
-                                  align(cp->cp.smem_size, 0x100));
-   NVC3C0_QMDV02_02_VAL_SET(qmd, SHADER_LOCAL_MEMORY_LOW_SIZE,
-                                 (cp->hdr[1] & 0xfffff0) +
-                                 align(cp->cp.lmem_size, 0x10));
+   NVC3C0_QMDV02_02_VAL_SET(qmd, SHARED_MEMORY_SIZE, align(shared_size, 0x100));
+   NVC3C0_QMDV02_02_VAL_SET(qmd, SHADER_LOCAL_MEMORY_LOW_SIZE, cp->hdr[1] & 0xfffff0);
    NVC3C0_QMDV02_02_VAL_SET(qmd, SHADER_LOCAL_MEMORY_HIGH_SIZE, 0);
    NVC3C0_QMDV02_02_VAL_SET(qmd, MIN_SM_CONFIG_SHARED_MEM_SIZE,
                                   gv100_sm_config_smem_size(8 * 1024));
@@ -770,7 +764,7 @@ gv100_compute_setup_launch_desc(struct nvc0_context *nvc0, u32 *qmd,
    NVC3C0_QMDV02_02_VAL_SET(qmd, QMD_VERSION, 2);
    NVC3C0_QMDV02_02_VAL_SET(qmd, QMD_MAJOR_VERSION, 2);
    NVC3C0_QMDV02_02_VAL_SET(qmd, TARGET_SM_CONFIG_SHARED_MEM_SIZE,
-                                  gv100_sm_config_smem_size(cp->cp.smem_size));
+                                  gv100_sm_config_smem_size(shared_size));
 
    NVC3C0_QMDV02_02_VAL_SET(qmd, CTA_RASTER_WIDTH, info->grid[0]);
    NVC3C0_QMDV02_02_VAL_SET(qmd, CTA_RASTER_HEIGHT, info->grid[1]);
diff --git a/src/gallium/drivers/panfrost/pan_cmdstream.c b/src/gallium/drivers/panfrost/pan_cmdstream.c
index ad170821187..5aec6dcc4db 100644
--- a/src/gallium/drivers/panfrost/pan_cmdstream.c
+++ b/src/gallium/drivers/panfrost/pan_cmdstream.c
@@ -1625,7 +1625,7 @@ panfrost_emit_shared_memory(struct panfrost_batch *batch,
 
         struct pan_tls_info info = {
                 .tls.size = ss->info.tls_size,
-                .wls.size = ss->info.wls_size,
+                .wls.size = ss->info.wls_size + grid->variable_shared_mem,
                 .wls.instances = panfrost_choose_wls_instance_count(grid),
         };
 
@@ -4156,7 +4156,16 @@ panfrost_launch_grid(struct pipe_context *pipe,
                                      batch->rsd[PIPE_SHADER_COMPUTE],
                                      panfrost_emit_shared_memory(batch, info));
 
-                cfg.allow_merging_workgroups = cs->info.cs.allow_merging_workgroups;
+                /* Workgroups may be merged if the shader does not use barriers
+                 * or shared memory. This condition is checked against the
+                 * static shared_size at compile-time. We need to check the
+                 * variable shared size at launch_grid time, because the
+                 * compiler doesn't know about that.
+                 */
+                cfg.allow_merging_workgroups =
+                        cs->info.cs.allow_merging_workgroups &&
+                        (info->variable_shared_mem == 0);
+
                 cfg.task_increment = 1;
                 cfg.task_axis = MALI_TASK_AXIS_Z;
         }
diff --git a/src/gallium/drivers/panfrost/pan_compute.c b/src/gallium/drivers/panfrost/pan_compute.c
index 780b2b521b5..4cbdb84cac6 100644
--- a/src/gallium/drivers/panfrost/pan_compute.c
+++ b/src/gallium/drivers/panfrost/pan_compute.c
@@ -57,7 +57,7 @@ panfrost_create_compute_state(
 
         panfrost_shader_compile(pctx->screen, &ctx->shaders, &ctx->descs,
                                 cso->prog, &ctx->base.debug, v,
-                                cso->req_local_mem);
+                                cso->static_shared_mem);
 
         return so;
 }
diff --git a/src/gallium/drivers/r600/evergreen_compute.c b/src/gallium/drivers/r600/evergreen_compute.c
index d1fe115bbd2..8f22d2d5d15 100644
--- a/src/gallium/drivers/r600/evergreen_compute.c
+++ b/src/gallium/drivers/r600/evergreen_compute.c
@@ -435,8 +435,7 @@ static void *evergreen_create_compute_state(struct pipe_context *ctx,
 #endif
 
 	shader->ctx = rctx;
-	shader->local_size = cso->req_local_mem;
-	shader->private_size = cso->req_private_mem;
+	shader->local_size = cso->static_shared_mem;
 	shader->input_size = cso->req_input_mem;
 
 	shader->ir_type = cso->ir_type;
@@ -611,7 +610,7 @@ static void evergreen_emit_dispatch(struct r600_context *rctx,
 	unsigned num_pipes = rctx->screen->b.info.r600_max_quad_pipes;
 	unsigned wave_divisor = (16 * num_pipes);
 	int group_size = 1;
-	unsigned lds_size = shader->local_size / 4;
+	unsigned lds_size = (shader->local_size + info->variable_shared_mem) / 4;
 
 	if (shader->ir_type != PIPE_SHADER_IR_TGSI &&
 	    shader->ir_type != PIPE_SHADER_IR_NIR)
diff --git a/src/gallium/drivers/r600/evergreen_compute_internal.h b/src/gallium/drivers/r600/evergreen_compute_internal.h
index 4f3ba564fd0..b2722fe7999 100644
--- a/src/gallium/drivers/r600/evergreen_compute_internal.h
+++ b/src/gallium/drivers/r600/evergreen_compute_internal.h
@@ -81,7 +81,6 @@ struct r600_pipe_compute {
 	struct r600_bytecode bc;
 
 	unsigned local_size;
-	unsigned private_size;
 	unsigned input_size;
 	struct r600_resource *kernel_param;
 
diff --git a/src/gallium/drivers/radeonsi/si_compute.c b/src/gallium/drivers/radeonsi/si_compute.c
index f59cf3aed81..791a78d16d4 100644
--- a/src/gallium/drivers/radeonsi/si_compute.c
+++ b/src/gallium/drivers/radeonsi/si_compute.c
@@ -49,7 +49,6 @@ struct dispatch_packet {
    uint32_t grid_size_x;
    uint32_t grid_size_y;
    uint32_t grid_size_z;
-   uint32_t private_segment_size;
    uint32_t group_segment_size;
    uint64_t kernel_object;
    uint64_t kernarg_address;
@@ -241,11 +240,10 @@ static void *si_create_compute_state(struct pipe_context *ctx, const struct pipe
       si_const_and_shader_buffer_descriptors_idx(PIPE_SHADER_COMPUTE);
    sel->sampler_and_images_descriptors_index =
       si_sampler_and_image_descriptors_idx(PIPE_SHADER_COMPUTE);
-   sel->info.base.shared_size = cso->req_local_mem;
+   sel->info.base.shared_size = cso->static_shared_mem;
    program->shader.selector = &program->sel;
    program->shader.wave_size = si_determine_wave_size(sscreen, &program->shader);
    program->ir_type = cso->ir_type;
-   program->private_size = cso->req_private_mem;
    program->input_size = cso->req_input_mem;
 
    if (cso->ir_type != PIPE_SHADER_IR_NATIVE) {
@@ -507,48 +505,64 @@ static bool si_setup_compute_scratch_buffer(struct si_context *sctx, struct si_s
 
 static bool si_switch_compute_shader(struct si_context *sctx, struct si_compute *program,
                                      struct si_shader *shader, const amd_kernel_code_t *code_object,
-                                     unsigned offset, bool *prefetch)
+                                     unsigned offset, bool *prefetch, unsigned variable_shared_size)
 {
    struct radeon_cmdbuf *cs = &sctx->gfx_cs;
-   struct ac_shader_config inline_config = {0};
-   struct ac_shader_config *config;
+   struct ac_shader_config config = {0};
    uint64_t shader_va;
+   unsigned stage = shader->selector->info.base.stage;
 
    *prefetch = false;
 
-   if (sctx->cs_shader_state.emitted_program == program && sctx->cs_shader_state.offset == offset)
+   assert(variable_shared_size == 0 || stage == MESA_SHADER_KERNEL || program->ir_type == PIPE_SHADER_IR_NATIVE);
+   if (sctx->cs_shader_state.emitted_program == program && sctx->cs_shader_state.offset == offset &&
+       sctx->cs_shader_state.variable_shared_size == variable_shared_size)
       return true;
 
+   /* copy the config, so we don't have to change it inside the si_shader object */
    if (program->ir_type != PIPE_SHADER_IR_NATIVE) {
-      config = &shader->config;
+      config = shader->config;
    } else {
+      code_object_to_config(code_object, &config);
+   }
+
+   /* only do this for OpenCL */
+   if (program->ir_type == PIPE_SHADER_IR_NATIVE || stage == MESA_SHADER_KERNEL) {
+      unsigned shared_size = program->sel.info.base.shared_size + variable_shared_size;
       unsigned lds_blocks;
 
-      config = &inline_config;
-      code_object_to_config(code_object, config);
+      /* Clover uses the compute API differently than other frontends and expects drivers to parse
+       * the shared_size out of the shader headers.
+       * Adding on top of the old value is fine though as Clover always creates a new CSO when it
+       * changes.
+       */
+      if (program->ir_type == PIPE_SHADER_IR_NATIVE) {
+         lds_blocks = config.lds_size;
+      } else {
+         lds_blocks = 0;
+      }
 
-      lds_blocks = config->lds_size;
       /* XXX: We are over allocating LDS.  For GFX6, the shader reports
        * LDS in blocks of 256 bytes, so if there are 4 bytes lds
        * allocated in the shader and 4 bytes allocated by the state
        * tracker, then we will set LDS_SIZE to 512 bytes rather than 256.
        */
       if (sctx->gfx_level <= GFX6) {
-         lds_blocks += align(program->sel.info.base.shared_size, 256) >> 8;
+         lds_blocks += align(shared_size, 256) >> 8;
       } else {
-         lds_blocks += align(program->sel.info.base.shared_size, 512) >> 9;
+         lds_blocks += align(shared_size, 512) >> 9;
       }
 
       /* TODO: use si_multiwave_lds_size_workaround */
       assert(lds_blocks <= 0xFF);
 
-      config->rsrc2 &= C_00B84C_LDS_SIZE;
-      config->rsrc2 |= S_00B84C_LDS_SIZE(lds_blocks);
+      config.rsrc2 &= C_00B84C_LDS_SIZE;
+      config.rsrc2 |= S_00B84C_LDS_SIZE(lds_blocks);
    }
 
    unsigned tmpring_size;
    ac_get_scratch_tmpring_size(&sctx->screen->info, true,
-                               config->scratch_bytes_per_wave,
+                               config.scratch_bytes_per_wave,
                                &sctx->max_seen_compute_scratch_bytes_per_wave, &tmpring_size);
 
    if (!si_setup_compute_scratch_buffer(sctx, shader))
@@ -585,19 +599,20 @@ static bool si_switch_compute_shader(struct si_context *sctx, struct si_compute
       radeon_set_sh_reg_seq(R_00B848_COMPUTE_PGM_RSRC1, 2);
    }
 
-   radeon_emit(config->rsrc1);
-   radeon_emit(config->rsrc2);
+   radeon_emit(config.rsrc1);
+   radeon_emit(config.rsrc2);
 
    COMPUTE_DBG(sctx->screen,
                "COMPUTE_PGM_RSRC1: 0x%08x "
                "COMPUTE_PGM_RSRC2: 0x%08x\n",
-               config->rsrc1, config->rsrc2);
+               config.rsrc1, config.rsrc2);
 
    radeon_set_sh_reg(R_00B860_COMPUTE_TMPRING_SIZE, tmpring_size);
    radeon_end();
 
    sctx->cs_shader_state.emitted_program = program;
    sctx->cs_shader_state.offset = offset;
+   sctx->cs_shader_state.variable_shared_size = variable_shared_size;
 
    *prefetch = true;
    return true;
@@ -684,8 +699,8 @@ static void si_setup_user_sgprs_co_v2(struct si_context *sctx, const amd_kernel_
       dispatch.grid_size_y = util_cpu_to_le32(info->grid[1] * info->block[1]);
       dispatch.grid_size_z = util_cpu_to_le32(info->grid[2] * info->block[2]);
 
-      dispatch.private_segment_size = util_cpu_to_le32(program->private_size);
-      dispatch.group_segment_size = util_cpu_to_le32(program->sel.info.base.shared_size);
+      dispatch.group_segment_size =
+         util_cpu_to_le32(program->sel.info.base.shared_size + info->variable_shared_mem);
 
       dispatch.kernarg_address = util_cpu_to_le64(kernel_args_va);
 
@@ -1004,7 +1019,8 @@ static void si_launch_grid(struct pipe_context *ctx, const struct pipe_grid_info
 
    /* First emit registers. */
    bool prefetch;
-   if (!si_switch_compute_shader(sctx, program, &program->shader, code_object, info->pc, &prefetch))
+   if (!si_switch_compute_shader(sctx, program, &program->shader, code_object, info->pc, &prefetch,
+                                 info->variable_shared_mem))
       return;
 
    si_upload_compute_shader_descriptors(sctx);
diff --git a/src/gallium/drivers/radeonsi/si_compute.h b/src/gallium/drivers/radeonsi/si_compute.h
index 305059a6cb6..b5624f20195 100644
--- a/src/gallium/drivers/radeonsi/si_compute.h
+++ b/src/gallium/drivers/radeonsi/si_compute.h
@@ -33,7 +33,6 @@ struct si_compute {
    struct si_shader shader;
 
    unsigned ir_type;
-   unsigned private_size;
    unsigned input_size;
 
    int max_global_buffers;
diff --git a/src/gallium/drivers/radeonsi/si_get.c b/src/gallium/drivers/radeonsi/si_get.c
index ff5292495cd..29bb1c1486f 100644
--- a/src/gallium/drivers/radeonsi/si_get.c
+++ b/src/gallium/drivers/radeonsi/si_get.c
@@ -1178,7 +1178,7 @@ void si_init_screen_get_functions(struct si_screen *sscreen)
       .lower_fisnormal = true,
       .lower_rotate = true,
       .lower_to_scalar = true,
-      .lower_int64_options = nir_lower_imul_2x32_64,
+      .lower_int64_options = nir_lower_imul_2x32_64 | nir_lower_imul_high64,
       .has_sdot_4x8 = sscreen->info.has_accelerated_dot_product,
       .has_sudot_4x8 = sscreen->info.has_accelerated_dot_product && sscreen->info.gfx_level >= GFX11,
       .has_udot_4x8 = sscreen->info.has_accelerated_dot_product,
diff --git a/src/gallium/drivers/radeonsi/si_pipe.h b/src/gallium/drivers/radeonsi/si_pipe.h
index 95e252187b4..0dcddfa7e39 100644
--- a/src/gallium/drivers/radeonsi/si_pipe.h
+++ b/src/gallium/drivers/radeonsi/si_pipe.h
@@ -739,6 +739,7 @@ struct si_cs_shader_state {
    struct si_compute *program;
    struct si_compute *emitted_program;
    unsigned offset;
+   uint32_t variable_shared_size;
    bool initialized;
 };
 
diff --git a/src/gallium/drivers/radeonsi/si_shader_nir.c b/src/gallium/drivers/radeonsi/si_shader_nir.c
index 04722413240..207d62bf465 100644
--- a/src/gallium/drivers/radeonsi/si_shader_nir.c
+++ b/src/gallium/drivers/radeonsi/si_shader_nir.c
@@ -342,7 +342,7 @@ char *si_finalize_nir(struct pipe_screen *screen, void *nirptr)
 
    nir_lower_io_passes(nir);
 
-   NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_mem_shared, nir_address_format_32bit_offset);
+   NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_mem_shared, false, nir_address_format_32bit_offset);
 
    /* Remove dead derefs, so that we can remove uniforms. */
    NIR_PASS_V(nir, nir_opt_dce);
diff --git a/src/gallium/drivers/softpipe/sp_compute.c b/src/gallium/drivers/softpipe/sp_compute.c
index 221ef7ec797..2b70fb9777b 100644
--- a/src/gallium/drivers/softpipe/sp_compute.c
+++ b/src/gallium/drivers/softpipe/sp_compute.c
@@ -184,8 +184,9 @@ softpipe_launch_grid(struct pipe_context *context,
 
    fill_grid_size(context, info, grid_size);
 
-   if (cs->shader.req_local_mem) {
-      local_mem = CALLOC(1, cs->shader.req_local_mem);
+   uint32_t shared_mem_size = cs->shader.static_shared_mem + info->variable_shared_mem;
+   if (shared_mem_size) {
+      local_mem = CALLOC(1, shared_mem_size);
    }
 
    machines = CALLOC(sizeof(struct tgsi_exec_machine *), num_threads_in_group);
@@ -202,7 +203,7 @@ softpipe_launch_grid(struct pipe_context *context,
             machines[idx] = tgsi_exec_machine_create(PIPE_SHADER_COMPUTE);
 
             machines[idx]->LocalMem = local_mem;
-            machines[idx]->LocalMemSize = cs->shader.req_local_mem;
+            machines[idx]->LocalMemSize = shared_mem_size;
             machines[idx]->NonHelperMask = (1 << (MIN2(TGSI_QUAD_SIZE, bwidth - local_x))) - 1;
             cs_prepare(cs, machines[idx],
                        local_x, local_y, local_z,
diff --git a/src/gallium/drivers/svga/svga_pipe_cs.c b/src/gallium/drivers/svga/svga_pipe_cs.c
index 7b2293863b7..428afd77c81 100644
--- a/src/gallium/drivers/svga/svga_pipe_cs.c
+++ b/src/gallium/drivers/svga/svga_pipe_cs.c
@@ -70,7 +70,7 @@ svga_create_compute_state(struct pipe_context *pipe,
    /* Collect shader basic info */
    svga_tgsi_scan_shader(&cs->base);
 
-   cs->shared_mem_size = templ->req_local_mem;
+   cs->shared_mem_size = templ->static_shared_mem;
 
    SVGA_STATS_TIME_POP(svga_sws(svga));
    return cs;
diff --git a/src/gallium/drivers/virgl/virgl_context.c b/src/gallium/drivers/virgl/virgl_context.c
index dbd572da0ed..c1ea961092d 100644
--- a/src/gallium/drivers/virgl/virgl_context.c
+++ b/src/gallium/drivers/virgl/virgl_context.c
@@ -1440,7 +1440,7 @@ static void *virgl_create_compute_state(struct pipe_context *ctx,
    handle = virgl_object_assign_handle();
    ret = virgl_encode_shader_state(vctx, handle, PIPE_SHADER_COMPUTE,
                                    &so_info,
-                                   state->req_local_mem,
+                                   state->static_shared_mem,
                                    new_tokens);
    if (ret) {
       FREE((void *)ntt_tokens);
diff --git a/src/gallium/frontends/clover/core/kernel.cpp b/src/gallium/frontends/clover/core/kernel.cpp
index b07907e471b..f1ff5a49b1a 100644
--- a/src/gallium/frontends/clover/core/kernel.cpp
+++ b/src/gallium/frontends/clover/core/kernel.cpp
@@ -100,6 +100,7 @@ kernel::launch(command_queue &q,
    copy(pad_vector(q, reduced_grid_size, 1), info.grid);
    info.pc = find(name_equals(_name), b.syms).offset;
    info.input = exec.input.data();
+   info.variable_shared_mem = exec.mem_local;
 
    q.pipe->launch_grid(q.pipe, &info);
 
@@ -274,14 +275,14 @@ kernel::exec_context::bind(intrusive_ptr<command_queue> _q,
 
    // Create a new compute state if anything changed.
    if (!st || q != _q ||
-       cs.req_local_mem != mem_local ||
        cs.req_input_mem != input.size()) {
       if (st)
          _q->pipe->delete_compute_state(_q->pipe, st);
 
       cs.ir_type = q->device().ir_format();
       cs.prog = &(msec.data[0]);
-      cs.req_local_mem = mem_local;
+      // we only pass in NIRs or LLVMs and both IRs decode the size
+      cs.static_shared_mem = 0;
       cs.req_input_mem = input.size();
       st = q->pipe->create_compute_state(q->pipe, &cs);
       if (!st) {
diff --git a/src/gallium/frontends/clover/nir/invocation.cpp b/src/gallium/frontends/clover/nir/invocation.cpp
index 907f79bce08..d6ce8641bcd 100644
--- a/src/gallium/frontends/clover/nir/invocation.cpp
+++ b/src/gallium/frontends/clover/nir/invocation.cpp
@@ -359,7 +359,7 @@ binary clover::nir::spirv_to_nir(const binary &mod, const device &dev,
                                              nir->constant_data_size,
                                              nir_var_mem_constant);
       }
-      NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_mem_constant,
+      NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_mem_constant, false,
                  spirv_options.constant_addr_format);
 
       auto args = sym.args;
@@ -376,24 +376,24 @@ binary clover::nir::spirv_to_nir(const binary &mod, const device &dev,
 
       NIR_PASS_V(nir, nir_opt_deref);
       NIR_PASS_V(nir, nir_lower_readonly_images_to_tex, false);
-      NIR_PASS_V(nir, nir_lower_cl_images);
+      NIR_PASS_V(nir, nir_lower_cl_images, true);
       NIR_PASS_V(nir, nir_lower_memcpy);
 
       /* use offsets for kernel inputs (uniform) */
-      NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_uniform,
+      NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_uniform, false,
                  nir->info.cs.ptr_size == 64 ?
                  nir_address_format_32bit_offset_as_64bit :
                  nir_address_format_32bit_offset);
 
-      NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_mem_constant,
+      NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_mem_constant, false,
                  spirv_options.constant_addr_format);
-      NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_mem_shared,
+      NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_mem_shared, false,
                  spirv_options.shared_addr_format);
 
-      NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_function_temp,
+      NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_function_temp, false,
                  spirv_options.temp_addr_format);
 
-      NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_mem_global,
+      NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_mem_global, false,
                  spirv_options.global_addr_format);
 
       struct nir_remove_dead_variables_options remove_dead_variables_options = {};
diff --git a/src/gallium/frontends/lavapipe/lvp_pipeline.c b/src/gallium/frontends/lavapipe/lvp_pipeline.c
index 87d9da57764..22cad864c76 100644
--- a/src/gallium/frontends/lavapipe/lvp_pipeline.c
+++ b/src/gallium/frontends/lavapipe/lvp_pipeline.c
@@ -460,20 +460,20 @@ lvp_shader_compile_to_ir(struct lvp_pipeline *pipeline,
    NIR_PASS_V(nir, nir_split_var_copies);
    NIR_PASS_V(nir, nir_lower_global_vars_to_local);
 
-   NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_mem_push_const,
+   NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_mem_push_const, false,
               nir_address_format_32bit_offset);
 
    NIR_PASS_V(nir, nir_lower_explicit_io,
-              nir_var_mem_ubo | nir_var_mem_ssbo,
+              nir_var_mem_ubo | nir_var_mem_ssbo, false,
               nir_address_format_32bit_index_offset);
 
    NIR_PASS_V(nir, nir_lower_explicit_io,
-              nir_var_mem_global,
+              nir_var_mem_global, false,
               nir_address_format_64bit_global);
 
    if (nir->info.stage == MESA_SHADER_COMPUTE) {
       NIR_PASS_V(nir, nir_lower_vars_to_explicit_types, nir_var_mem_shared, shared_var_info);
-      NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_mem_shared, nir_address_format_32bit_offset);
+      NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_mem_shared, false, nir_address_format_32bit_offset);
    }
 
    NIR_PASS_V(nir, nir_remove_dead_variables, nir_var_shader_temp, NULL);
@@ -601,7 +601,7 @@ lvp_pipeline_compile_stage(struct lvp_pipeline *pipeline, nir_shader *nir)
       struct pipe_compute_state shstate = {0};
       shstate.prog = nir;
       shstate.ir_type = PIPE_SHADER_IR_NIR;
-      shstate.req_local_mem = nir->info.shared_size;
+      shstate.static_shared_mem = nir->info.shared_size;
       return device->queue.ctx->create_compute_state(device->queue.ctx, &shstate);
    } else {
       struct pipe_shader_state shstate = {0};
diff --git a/src/gallium/frontends/rusticl/core/device.rs b/src/gallium/frontends/rusticl/core/device.rs
index 88c21e95000..92aa6938801 100644
--- a/src/gallium/frontends/rusticl/core/device.rs
+++ b/src/gallium/frontends/rusticl/core/device.rs
@@ -73,6 +73,9 @@ pub trait HelperContextWrapper {
 
     fn texture_map_coherent(&self, res: &PipeResource, bx: &pipe_box, rw: RWFlags) -> PipeTransfer;
 
+    fn create_compute_state(&self, nir: &NirShader, static_local_mem: u32) -> *mut c_void;
+    fn delete_compute_state(&self, cso: *mut c_void);
+
     fn unmap(&self, tx: PipeTransfer);
 }
 
@@ -148,6 +151,14 @@ impl<'a> HelperContextWrapper for HelperContext<'a> {
             .texture_map(res, bx, rw, ResourceMapType::Coherent)
     }
 
+    fn create_compute_state(&self, nir: &NirShader, static_local_mem: u32) -> *mut c_void {
+        self.lock.create_compute_state(nir, static_local_mem)
+    }
+
+    fn delete_compute_state(&self, cso: *mut c_void) {
+        self.lock.delete_compute_state(cso)
+    }
+
     fn unmap(&self, tx: PipeTransfer) {
         tx.with_ctx(&self.lock);
     }
@@ -525,8 +536,7 @@ impl Device {
     }
 
     pub fn const_max_size(&self) -> cl_ulong {
-        self.screen
-            .param(pipe_cap::PIPE_CAP_MAX_SHADER_BUFFER_SIZE_UINT) as u64
+        self.shader_param(pipe_shader_cap::PIPE_SHADER_CAP_MAX_CONST_BUFFER0_SIZE) as cl_ulong
     }
 
     pub fn device_type(&self, internal: bool) -> cl_device_type {
@@ -727,6 +737,15 @@ impl Device {
         id as u32
     }
 
+    pub fn shareable_shaders(&self) -> bool {
+        self.screen.param(pipe_cap::PIPE_CAP_SHAREABLE_SHADERS) == 1
+    }
+
+    pub fn images_as_deref(&self) -> bool {
+        self.screen.param(pipe_cap::PIPE_CAP_NIR_IMAGES_AS_DEREF) == 1
+            && self.screen.param(pipe_cap::PIPE_CAP_NIR_SAMPLERS_AS_DEREF) == 1
+    }
+
     pub fn helper_ctx(&self) -> impl HelperContextWrapper + '_ {
         HelperContext {
             lock: self.helper_ctx.lock().unwrap(),
diff --git a/src/gallium/frontends/rusticl/core/kernel.rs b/src/gallium/frontends/rusticl/core/kernel.rs
index 927b1592e1d..b952422dc22 100644
--- a/src/gallium/frontends/rusticl/core/kernel.rs
+++ b/src/gallium/frontends/rusticl/core/kernel.rs
@@ -12,6 +12,7 @@ use mesa_rust::compiler::clc::*;
 use mesa_rust::compiler::nir::*;
 use mesa_rust::pipe::context::RWFlags;
 use mesa_rust::pipe::context::ResourceMapType;
+use mesa_rust::pipe::resource::*;
 use mesa_rust::pipe::screen::ResourceType;
 use mesa_rust_gen::*;
 use mesa_rust_util::math::*;
@@ -59,6 +60,7 @@ pub enum InternalKernelArgType {
     InlineSampler((cl_addressing_mode, cl_filter_mode, bool)),
     FormatArray,
     OrderArray,
+    WorkDim,
 }
 
 #[derive(Hash, PartialEq, Eq, Clone)]
@@ -210,6 +212,7 @@ impl InternalKernelArg {
             }
             InternalKernelArgType::FormatArray => bin.push(4),
             InternalKernelArgType::OrderArray => bin.push(5),
+            InternalKernelArgType::WorkDim => bin.push(6),
         }
 
         bin
@@ -231,6 +234,7 @@ impl InternalKernelArg {
             }
             4 => InternalKernelArgType::FormatArray,
             5 => InternalKernelArgType::OrderArray,
+            6 => InternalKernelArgType::WorkDim,
             _ => return None,
         };
 
@@ -242,6 +246,79 @@ impl InternalKernelArg {
     }
 }
 
+struct KernelDevStateInner {
+    nir: NirShader,
+    constant_buffer: Option<Arc<PipeResource>>,
+    cso: *mut c_void,
+}
+
+struct KernelDevState {
+    states: HashMap<Arc<Device>, KernelDevStateInner>,
+}
+
+impl Drop for KernelDevState {
+    fn drop(&mut self) {
+        self.states.iter().for_each(|(dev, dev_state)| {
+            if !dev_state.cso.is_null() {
+                dev.helper_ctx().delete_compute_state(dev_state.cso);
+            }
+        })
+    }
+}
+
+impl KernelDevState {
+    fn new(nirs: HashMap<Arc<Device>, NirShader>) -> Arc<Self> {
+        let states = nirs
+            .into_iter()
+            .map(|(dev, nir)| {
+                let cso = if dev.shareable_shaders() {
+                    dev.helper_ctx()
+                        .create_compute_state(&nir, nir.shared_size())
+                } else {
+                    ptr::null_mut()
+                };
+
+                let cb = Self::create_nir_constant_buffer(&dev, &nir);
+
+                (
+                    dev,
+                    KernelDevStateInner {
+                        nir: nir,
+                        constant_buffer: cb,
+                        cso: cso,
+                    },
+                )
+            })
+            .collect();
+
+        Arc::new(Self { states: states })
+    }
+
+    fn create_nir_constant_buffer(dev: &Device, nir: &NirShader) -> Option<Arc<PipeResource>> {
+        let buf = nir.get_constant_buffer();
+        let len = buf.len() as u32;
+
+        if len > 0 {
+            let res = dev
+                .screen()
+                .resource_create_buffer(len, ResourceType::Normal)
+                .unwrap();
+
+            dev.helper_ctx()
+                .exec(|ctx| ctx.buffer_subdata(&res, 0, buf.as_ptr().cast(), len))
+                .wait();
+
+            Some(Arc::new(res))
+        } else {
+            None
+        }
+    }
+
+    fn get(&self, dev: &Device) -> &KernelDevStateInner {
+        self.states.get(dev).unwrap()
+    }
+}
+
 #[repr(C)]
 pub struct Kernel {
     pub base: CLObjectBase<CL_INVALID_KERNEL>,
@@ -252,7 +329,7 @@ pub struct Kernel {
     pub work_group_size: [usize; 3],
     pub attributes_string: String,
     internal_args: Vec<InternalKernelArg>,
-    nirs: HashMap<Arc<Device>, NirShader>,
+    dev_state: Arc<KernelDevState>,
 }
 
 impl_cl_type_trait!(cl_kernel, Kernel, CL_INVALID_KERNEL);
@@ -436,7 +513,7 @@ fn lower_and_optimize_nir_late(
     }
 
     nir.pass1(nir_lower_readonly_images_to_tex, false);
-    nir.pass0(nir_lower_cl_images);
+    nir.pass1(nir_lower_cl_images, !dev.images_as_deref());
 
     nir.reset_scratch_size();
     nir.pass2(
@@ -514,6 +591,17 @@ fn lower_and_optimize_nir_late(
             "image_orders",
         );
     }
+    res.push(InternalKernelArg {
+        kind: InternalKernelArgType::WorkDim,
+        size: 1,
+        offset: 0,
+    });
+    lower_state.work_dim = nir.add_var(
+        nir_variable_mode::nir_var_uniform,
+        unsafe { glsl_uint8_t_type() },
+        args.len() + res.len() - 1,
+        "work_dim",
+    );
 
     nir.pass2(
         nir_lower_vars_to_explicit_types,
@@ -534,9 +622,10 @@ fn lower_and_optimize_nir_late(
         shared_address_format = nir_address_format::nir_address_format_32bit_offset_as_64bit;
     }
 
-    nir.pass2(
+    nir.pass3(
         nir_lower_explicit_io,
         nir_variable_mode::nir_var_mem_global | nir_variable_mode::nir_var_mem_constant,
+        false,
         global_address_format,
     );
     nir.pass0(nir_lower_system_values);
@@ -545,11 +634,12 @@ fn lower_and_optimize_nir_late(
     nir.pass1(nir_lower_compute_system_values, &compute_options);
 
     nir.pass1(rusticl_lower_intrinsics, &mut lower_state);
-    nir.pass2(
+    nir.pass3(
         nir_lower_explicit_io,
         nir_variable_mode::nir_var_mem_shared
             | nir_variable_mode::nir_var_function_temp
             | nir_variable_mode::nir_var_uniform,
+        dev.images_as_deref(),
         shared_address_format,
     );
 
@@ -557,6 +647,10 @@ fn lower_and_optimize_nir_late(
         nir.pass0(nir_lower_int64);
     }
 
+    if nir_options.lower_uniforms_to_ubo {
+        nir.pass0(rusticl_lower_inputs);
+    }
+
     nir.pass1(nir_lower_convert_alu_types, None);
 
     opt_nir(nir, dev);
@@ -694,7 +788,7 @@ fn extract<'a, const S: usize>(buf: &'a mut &[u8]) -> &'a [u8; S] {
 }
 
 fn optimize_local_size(d: &Device, grid: &mut [u32; 3], block: &mut [u32; 3]) {
-    let mut threads = d.max_threads_per_block() as u32;
+    let mut threads = d.max_threads_per_block() as u32 / 4;
     let dim_threads = d.max_block_sizes();
     let subgroups = d.subgroups();
 
@@ -755,8 +849,7 @@ impl Kernel {
             attributes_string: attributes_string,
             values: values,
             internal_args: internal_args,
-            // caller has to verify all kernels have the same sig
-            nirs: nirs,
+            dev_state: KernelDevState::new(nirs),
         })
     }
 
@@ -770,13 +863,15 @@ impl Kernel {
         grid: &[usize],
         offsets: &[usize],
     ) -> CLResult<EventSig> {
-        let nir = self.nirs.get(&q.device).unwrap();
+        let dev_state = self.dev_state.get(&q.device);
         let mut block = create_kernel_arr::<u32>(block, 1);
         let mut grid = create_kernel_arr::<u32>(grid, 1);
         let offsets = create_kernel_arr::<u64>(offsets, 0);
         let mut input: Vec<u8> = Vec::new();
         let mut resource_info = Vec::new();
-        let mut local_size: u64 = nir.shared_size() as u64;
+        // Set it once so we get the alignment padding right
+        let static_local_size: u64 = dev_state.nir.shared_size() as u64;
+        let mut variable_local_size: u64 = static_local_size;
         let printf_size = q.device.printf_buffer_size() as u32;
         let mut samplers = Vec::new();
         let mut iviews = Vec::new();
@@ -806,7 +901,7 @@ impl Kernel {
                     let res = mem.get_res_of_dev(&q.device)?;
                     if mem.is_buffer() {
                         input.extend_from_slice(&mem.offset.to_ne_bytes());
-                        resource_info.push((Some(res.clone()), arg.offset));
+                        resource_info.push((res.clone(), arg.offset));
                     } else {
                         let format = mem.image_format.to_pipe_format().unwrap();
                         let (formats, orders) = if arg.kind == KernelArgType::Image {
@@ -832,9 +927,10 @@ impl Kernel {
                 KernelArgValue::LocalMem(size) => {
                     // TODO 32 bit
                     let pot = cmp::min(*size, 0x80);
-                    local_size = align(local_size, pot.next_power_of_two() as u64);
-                    input.extend_from_slice(&local_size.to_ne_bytes());
-                    local_size += *size as u64;
+                    variable_local_size =
+                        align(variable_local_size, pot.next_power_of_two() as u64);
+                    input.extend_from_slice(&variable_local_size.to_ne_bytes());
+                    variable_local_size += *size as u64;
                 }
                 KernelArgValue::Sampler(sampler) => {
                     samplers.push(sampler.pipe());
@@ -849,6 +945,9 @@ impl Kernel {
             }
         }
 
+        // subtract the shader local_size as we only request something on top of that.
+        variable_local_size -= dev_state.nir.shared_size() as u64;
+
         let mut printf_buf = None;
         for arg in &self.internal_args {
             if arg.offset > input.len() {
@@ -856,21 +955,9 @@ impl Kernel {
             }
             match arg.kind {
                 InternalKernelArgType::ConstantBuffer => {
+                    assert!(dev_state.constant_buffer.is_some());
                     input.extend_from_slice(&[0; 8]);
-                    let buf = nir.get_constant_buffer();
-                    let res = Arc::new(
-                        q.device
-                            .screen()
-                            .resource_create_buffer(buf.len() as u32, ResourceType::Normal)
-                            .unwrap(),
-                    );
-                    q.device
-                        .helper_ctx()
-                        .exec(|ctx| {
-                            ctx.buffer_subdata(&res, 0, buf.as_ptr().cast(), buf.len() as u32)
-                        })
-                        .wait();
-                    resource_info.push((Some(res), arg.offset));
+                    resource_info.push((dev_state.constant_buffer.clone().unwrap(), arg.offset));
                 }
                 InternalKernelArgType::GlobalWorkOffsets => {
                     input.extend_from_slice(&cl_prop::<[u64; 3]>(offsets));
@@ -879,12 +966,12 @@ impl Kernel {
                     let buf = Arc::new(
                         q.device
                             .screen
-                            .resource_create_buffer(printf_size, ResourceType::Normal)
+                            .resource_create_buffer(printf_size, ResourceType::Staging)
                             .unwrap(),
                     );
 
                     input.extend_from_slice(&[0; 8]);
-                    resource_info.push((Some(buf.clone()), arg.offset));
+                    resource_info.push((buf.clone(), arg.offset));
 
                     printf_buf = Some(buf);
                 }
@@ -899,16 +986,19 @@ impl Kernel {
                     input.extend_from_slice(&cl_prop::<&Vec<u16>>(&tex_orders));
                     input.extend_from_slice(&cl_prop::<&Vec<u16>>(&img_orders));
                 }
+                InternalKernelArgType::WorkDim => {
+                    input.extend_from_slice(&[work_dim as u8; 1]);
+                }
             }
         }
 
         let k = Arc::clone(self);
         Ok(Box::new(move |q, ctx| {
-            let nir = k.nirs.get(&q.device).unwrap();
+            let dev_state = k.dev_state.get(&q.device);
             let mut input = input.clone();
             let mut resources = Vec::with_capacity(resource_info.len());
             let mut globals: Vec<*mut u32> = Vec::new();
-            let printf_format = nir.printf_format();
+            let printf_format = dev_state.nir.printf_format();
 
             let mut sviews: Vec<_> = sviews
                 .iter()
@@ -933,21 +1023,32 @@ impl Kernel {
                     init_data.len() as u32,
                 );
             }
-            let cso = ctx.create_compute_state(nir, input.len() as u32, local_size as u32);
+
+            let cso = if dev_state.cso.is_null() {
+                ctx.create_compute_state(&dev_state.nir, static_local_size as u32)
+            } else {
+                dev_state.cso
+            };
 
             ctx.bind_compute_state(cso);
             ctx.bind_sampler_states(&samplers);
             ctx.set_sampler_views(&mut sviews);
             ctx.set_shader_images(&iviews);
             ctx.set_global_binding(resources.as_slice(), &mut globals);
+            ctx.set_constant_buffer(0, &input);
 
-            ctx.launch_grid(work_dim, block, grid, &input);
+            ctx.launch_grid(work_dim, block, grid, variable_local_size as u32);
 
             ctx.clear_global_binding(globals.len() as u32);
             ctx.clear_shader_images(iviews.len() as u32);
             ctx.clear_sampler_views(sviews.len() as u32);
             ctx.clear_sampler_states(samplers.len() as u32);
-            ctx.delete_compute_state(cso);
+
+            ctx.bind_compute_state(ptr::null_mut());
+            if dev_state.cso.is_null() {
+                ctx.delete_compute_state(cso);
+            }
+
             ctx.memory_barrier(PIPE_BARRIER_GLOBAL_BUFFER);
 
             samplers.iter().for_each(|s| ctx.delete_sampler_state(*s));
@@ -1048,12 +1149,12 @@ impl Kernel {
     }
 
     pub fn priv_mem_size(&self, dev: &Arc<Device>) -> cl_ulong {
-        self.nirs.get(dev).unwrap().scratch_size() as cl_ulong
+        self.dev_state.get(dev).nir.scratch_size() as cl_ulong
     }
 
     pub fn local_mem_size(&self, dev: &Arc<Device>) -> cl_ulong {
         // TODO include args
-        self.nirs.get(dev).unwrap().shared_size() as cl_ulong
+        self.dev_state.get(dev).nir.shared_size() as cl_ulong
     }
 }
 
@@ -1068,7 +1169,7 @@ impl Clone for Kernel {
             work_group_size: self.work_group_size,
             attributes_string: self.attributes_string.clone(),
             internal_args: self.internal_args.clone(),
-            nirs: self.nirs.clone(),
+            dev_state: self.dev_state.clone(),
         }
     }
 }
diff --git a/src/gallium/frontends/rusticl/mesa/pipe/context.rs b/src/gallium/frontends/rusticl/mesa/pipe/context.rs
index 234874fcf0c..0df09a25f1a 100644
--- a/src/gallium/frontends/rusticl/mesa/pipe/context.rs
+++ b/src/gallium/frontends/rusticl/mesa/pipe/context.rs
@@ -265,18 +265,12 @@ impl PipeContext {
         unsafe { self.pipe.as_ref().texture_unmap.unwrap()(self.pipe.as_ptr(), tx) };
     }
 
-    pub fn create_compute_state(
-        &self,
-        nir: &NirShader,
-        input_mem: u32,
-        local_mem: u32,
-    ) -> *mut c_void {
+    pub fn create_compute_state(&self, nir: &NirShader, static_local_mem: u32) -> *mut c_void {
         let state = pipe_compute_state {
             ir_type: pipe_shader_ir::PIPE_SHADER_IR_NIR,
             prog: nir.dup_for_driver().cast(),
-            req_input_mem: input_mem,
-            req_local_mem: local_mem,
-            req_private_mem: 0,
+            req_input_mem: 0,
+            static_shared_mem: static_local_mem,
         };
         unsafe { self.pipe.as_ref().create_compute_state.unwrap()(self.pipe.as_ptr(), &state) }
     }
@@ -322,10 +316,35 @@ impl PipeContext {
         unsafe { self.pipe.as_ref().delete_sampler_state.unwrap()(self.pipe.as_ptr(), ptr) }
     }
 
-    pub fn launch_grid(&self, work_dim: u32, block: [u32; 3], grid: [u32; 3], input: &[u8]) {
+    pub fn set_constant_buffer(&self, idx: u32, data: &[u8]) {
+        let cb = pipe_constant_buffer {
+            buffer: ptr::null_mut(),
+            buffer_offset: 0,
+            buffer_size: data.len() as u32,
+            user_buffer: data.as_ptr().cast(),
+        };
+        unsafe {
+            self.pipe.as_ref().set_constant_buffer.unwrap()(
+                self.pipe.as_ptr(),
+                pipe_shader_type::PIPE_SHADER_COMPUTE,
+                idx,
+                false,
+                &cb,
+            )
+        }
+    }
+
+    pub fn launch_grid(
+        &self,
+        work_dim: u32,
+        block: [u32; 3],
+        grid: [u32; 3],
+        variable_local_mem: u32,
+    ) {
         let info = pipe_grid_info {
             pc: 0,
-            input: input.as_ptr().cast(),
+            input: ptr::null(),
+            variable_shared_mem: variable_local_mem,
             work_dim: work_dim,
             block: block,
             last_block: [0; 3],
@@ -337,11 +356,8 @@ impl PipeContext {
         unsafe { self.pipe.as_ref().launch_grid.unwrap()(self.pipe.as_ptr(), &info) }
     }
 
-    pub fn set_global_binding(&self, res: &[Option<Arc<PipeResource>>], out: &mut [*mut u32]) {
-        let mut res: Vec<_> = res
-            .iter()
-            .map(|o| o.as_ref().map_or(ptr::null_mut(), |r| r.pipe()))
-            .collect();
+    pub fn set_global_binding(&self, res: &[Arc<PipeResource>], out: &mut [*mut u32]) {
+        let mut res: Vec<_> = res.iter().map(|r| r.pipe()).collect();
         unsafe {
             self.pipe.as_ref().set_global_binding.unwrap()(
                 self.pipe.as_ptr(),
@@ -476,6 +492,7 @@ fn has_required_cbs(c: &pipe_context) -> bool {
         && c.memory_barrier.is_some()
         && c.resource_copy_region.is_some()
         && c.sampler_view_destroy.is_some()
+        && c.set_constant_buffer.is_some()
         && c.set_global_binding.is_some()
         && c.set_sampler_views.is_some()
         && c.set_shader_images.is_some()
diff --git a/src/gallium/frontends/rusticl/mesa/pipe/screen.rs b/src/gallium/frontends/rusticl/mesa/pipe/screen.rs
index 37bd1b88dbb..c8b9a19f18f 100644
--- a/src/gallium/frontends/rusticl/mesa/pipe/screen.rs
+++ b/src/gallium/frontends/rusticl/mesa/pipe/screen.rs
@@ -93,7 +93,7 @@ impl PipeScreen {
                 (*self.screen).context_create.unwrap()(
                     self.screen,
                     ptr::null_mut(),
-                    PIPE_CONTEXT_COMPUTE_ONLY,
+                    0, //PIPE_CONTEXT_COMPUTE_ONLY,
                 )
             },
             self,
diff --git a/src/gallium/frontends/rusticl/rusticl_nir.c b/src/gallium/frontends/rusticl/rusticl_nir.c
index 542f735612c..69cd1679ca7 100644
--- a/src/gallium/frontends/rusticl/rusticl_nir.c
+++ b/src/gallium/frontends/rusticl/rusticl_nir.c
@@ -39,6 +39,12 @@ rusticl_lower_intrinsics_instr(
         }
 
         val = intrins->src[0].ssa;
+
+        if (val->parent_instr->type == nir_instr_type_deref) {
+            nir_deref_instr *deref = nir_instr_as_deref(val->parent_instr);
+            val = nir_explicit_io_address_from_deref(b, deref, NULL, nir_address_format_32bit_offset_as_64bit);
+        }
+
         // we put write images after read images
         if (nir_intrinsic_access(intrins) & ACCESS_NON_WRITEABLE) {
             val = nir_iadd_imm(b, val, b->shader->info.num_textures);
@@ -59,6 +65,8 @@ rusticl_lower_intrinsics_instr(
         return nir_load_var(b, state->const_buf);
     case nir_intrinsic_load_printf_buffer_address:
         return nir_load_var(b, state->printf_buf);
+    case nir_intrinsic_load_work_dim:
+        return nir_u2u(b, nir_load_var(b, state->work_dim), nir_dest_bit_size(intrins->dest));
     default:
         return NULL;
     }
@@ -74,3 +82,73 @@ rusticl_lower_intrinsics(nir_shader *nir, struct rusticl_lower_state* state)
         state
     );
 }
+
+static nir_ssa_def*
+rusticl_lower_input_instr(struct nir_builder *b, nir_instr *instr, void *_)
+{
+   nir_intrinsic_instr *intrins = nir_instr_as_intrinsic(instr);
+   if (intrins->intrinsic != nir_intrinsic_load_kernel_input)
+      return NULL;
+
+   nir_ssa_def *ubo_idx = nir_imm_int(b, 0);
+   nir_ssa_def *uniform_offset = nir_ssa_for_src(b, intrins->src[0], 1);
+
+   assert(intrins->dest.ssa.bit_size >= 8);
+   nir_ssa_def *load_result =
+      nir_load_ubo(b, intrins->num_components, intrins->dest.ssa.bit_size,
+                   ubo_idx, nir_iadd_imm(b, uniform_offset, nir_intrinsic_base(intrins)));
+
+   nir_intrinsic_instr *load = nir_instr_as_intrinsic(load_result->parent_instr);
+
+   /* If it's const, set the alignment to our known constant offset.  If
+    * not, set it to a pessimistic value based on the multiplier (or the
+    * scalar size, for qword loads).
+    *
+    * We could potentially set up stricter alignments for indirects by
+    * knowing what features are enabled in the APIs (see comment in
+    * nir_lower_ubo_vec4.c)
+    */
+   if (nir_src_is_const(intrins->src[0])) {
+      nir_intrinsic_set_align(load, NIR_ALIGN_MUL_MAX,
+                              (nir_src_as_uint(intrins->src[0]) +
+                              nir_intrinsic_base(intrins) * 1) %
+                              NIR_ALIGN_MUL_MAX);
+   } else {
+      nir_intrinsic_set_align(load, intrins->dest.ssa.bit_size / 8, 0);
+   }
+
+   nir_intrinsic_set_range_base(load, nir_intrinsic_base(intrins));
+   nir_intrinsic_set_range(load, nir_intrinsic_range(intrins));
+   return load_result;
+}
+
+bool
+rusticl_lower_inputs(nir_shader *shader)
+{
+   bool progress = false;
+
+   assert(!shader->info.first_ubo_is_default_ubo);
+
+   progress = nir_shader_lower_instructions(
+      shader,
+      rusticl_lower_intrinsics_filter,
+      rusticl_lower_input_instr,
+      NULL
+   );
+
+   nir_foreach_variable_with_modes(var, shader, nir_var_mem_ubo) {
+      var->data.binding++;
+      var->data.driver_location++;
+   }
+   shader->info.num_ubos++;
+
+   if (shader->num_uniforms > 0) {
+      const struct glsl_type *type = glsl_array_type(glsl_uint8_t_type(), shader->num_uniforms, 1);
+      nir_variable *ubo = nir_variable_create(shader, nir_var_mem_ubo, type, "kernel_input");
+      ubo->data.binding = 0;
+      ubo->data.explicit_binding = 1;
+   }
+
+   shader->info.first_ubo_is_default_ubo = true;
+   return progress;
+}
diff --git a/src/gallium/frontends/rusticl/rusticl_nir.h b/src/gallium/frontends/rusticl/rusticl_nir.h
index fefd0b3bcf7..227ffe54e16 100644
--- a/src/gallium/frontends/rusticl/rusticl_nir.h
+++ b/src/gallium/frontends/rusticl/rusticl_nir.h
@@ -4,6 +4,8 @@ struct rusticl_lower_state {
     nir_variable *printf_buf;
     nir_variable *format_arr;
     nir_variable *order_arr;
+    nir_variable *work_dim;
 };
 
 bool rusticl_lower_intrinsics(nir_shader *nir, struct rusticl_lower_state *state);
+bool rusticl_lower_inputs(nir_shader *nir);
diff --git a/src/gallium/include/pipe/p_state.h b/src/gallium/include/pipe/p_state.h
index 0155eecb3f9..4fe3db90794 100644
--- a/src/gallium/include/pipe/p_state.h
+++ b/src/gallium/include/pipe/p_state.h
@@ -936,6 +936,13 @@ struct pipe_grid_info
     */
    const void *input;
 
+   /**
+    * Variable shared memory used by this invocation.
+    *
+    * This comes on top of shader declared shared memory.
+    */
+   uint32_t variable_shared_mem;
+
    /**
     * Grid number of dimensions, 1-3, e.g. the work_dim parameter passed to
     * clEnqueueNDRangeKernel. Note block[] and grid[] must be padded with
@@ -1005,8 +1012,7 @@ struct pipe_compute_state
 {
    enum pipe_shader_ir ir_type; /**< IR type contained in prog. */
    const void *prog; /**< Compute program to be executed. */
-   unsigned req_local_mem; /**< Required size of the LOCAL resource. */
-   unsigned req_private_mem; /**< Required size of the PRIVATE resource. */
+   unsigned static_shared_mem; /**< equal to info.shared_size, used for shaders passed as TGSI */
    unsigned req_input_mem; /**< Required size of the INPUT resource. */
 };
 
diff --git a/src/gallium/targets/rusticl/meson.build b/src/gallium/targets/rusticl/meson.build
index babc63ba3ac..938ff9d0efd 100644
--- a/src/gallium/targets/rusticl/meson.build
+++ b/src/gallium/targets/rusticl/meson.build
@@ -45,6 +45,7 @@ librusticl = shared_library(
     driver_iris,
     driver_nouveau,
     driver_panfrost,
+    driver_radeonsi,
     driver_swrast,
     idep_nir,
   ],
diff --git a/src/gallium/tests/trivial/compute.c b/src/gallium/tests/trivial/compute.c
deleted file mode 100644
index 1def2182fd8..00000000000
--- a/src/gallium/tests/trivial/compute.c
+++ /dev/null
@@ -1,1693 +0,0 @@
-/*
- * Copyright (C) 2011 Francisco Jerez.
- * All Rights Reserved.
- *
- * Permission is hereby granted, free of charge, to any person obtaining
- * a copy of this software and associated documentation files (the
- * "Software"), to deal in the Software without restriction, including
- * without limitation the rights to use, copy, modify, merge, publish,
- * distribute, sublicense, and/or sell copies of the Software, and to
- * permit persons to whom the Software is furnished to do so, subject to
- * the following conditions:
- *
- * The above copyright notice and this permission notice (including the
- * next paragraph) shall be included in all copies or substantial
- * portions of the Software.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
- * IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
- * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
- * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
- * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
- *
- */
-
-#include <fcntl.h>
-#include <stdio.h>
-#include <sys/stat.h>
-#include <inttypes.h>
-#include "pipe/p_state.h"
-#include "pipe/p_context.h"
-#include "pipe/p_screen.h"
-#include "pipe/p_defines.h"
-#include "pipe/p_shader_tokens.h"
-#include "util/u_memory.h"
-#include "util/u_inlines.h"
-#include "util/u_sampler.h"
-#include "util/format/u_format.h"
-#include "tgsi/tgsi_text.h"
-#include "pipe-loader/pipe_loader.h"
-
-#define MAX_RESOURCES 4
-
-struct context {
-        struct pipe_loader_device *dev;
-        struct pipe_screen *screen;
-        struct pipe_context *pipe;
-        void *hwcs;
-        void *hwsmp[MAX_RESOURCES];
-        struct pipe_resource *tex[MAX_RESOURCES];
-        bool tex_rw[MAX_RESOURCES];
-        struct pipe_sampler_view *view[MAX_RESOURCES];
-        struct pipe_surface *surf[MAX_RESOURCES];
-};
-
-#define DUMP_COMPUTE_PARAM(p, c) do {                                   \
-                uint64_t __v[4];                                        \
-                int __i, __n;                                           \
-                                                                        \
-                __n = ctx->screen->get_compute_param(ctx->screen,       \
-                                                     PIPE_SHADER_IR_TGSI, \
-                                                     c, __v);           \
-                printf("%s: {", #c);                                    \
-                                                                        \
-                for (__i = 0; __i < __n / sizeof(*__v); ++__i)          \
-                        printf(" %"PRIu64, __v[__i]);                   \
-                                                                        \
-                printf(" }\n");                                         \
-        } while (0)
-
-static void init_ctx(struct context *ctx)
-{
-        ASSERTED int ret;
-
-        ret = pipe_loader_probe(&ctx->dev, 1);
-        assert(ret);
-
-        ctx->screen = pipe_loader_create_screen(ctx->dev);
-        assert(ctx->screen);
-
-        ctx->pipe = ctx->screen->context_create(ctx->screen, NULL, 0);
-        assert(ctx->pipe);
-
-        DUMP_COMPUTE_PARAM(p, PIPE_COMPUTE_CAP_GRID_DIMENSION);
-        DUMP_COMPUTE_PARAM(p, PIPE_COMPUTE_CAP_MAX_GRID_SIZE);
-        DUMP_COMPUTE_PARAM(p, PIPE_COMPUTE_CAP_MAX_BLOCK_SIZE);
-}
-
-static void destroy_ctx(struct context *ctx)
-{
-        ctx->pipe->destroy(ctx->pipe);
-        ctx->screen->destroy(ctx->screen);
-        pipe_loader_release(&ctx->dev, 1);
-        FREE(ctx);
-}
-
-static char *
-preprocess_prog(struct context *ctx, const char *src, const char *defs)
-{
-        const char header[] =
-                "#define RGLOBAL        RES[32767]\n"
-                "#define RLOCAL         RES[32766]\n"
-                "#define RPRIVATE       RES[32765]\n"
-                "#define RINPUT         RES[32764]\n";
-        char cmd[512];
-        char tmp[] = "/tmp/test-compute.tgsi-XXXXXX";
-        char *buf;
-        int fd, ret;
-        struct stat st;
-        FILE *p;
-
-        /* Open a temporary file */
-        fd = mkstemp(tmp);
-        assert(fd >= 0);
-        snprintf(cmd, sizeof(cmd), "cpp -P -nostdinc -undef %s > %s",
-                 defs ? defs : "", tmp);
-
-        /* Preprocess */
-        p = popen(cmd, "w");
-        fwrite(header, strlen(header), 1, p);
-        fwrite(src, strlen(src), 1, p);
-        ret = pclose(p);
-        assert(!ret);
-
-        /* Read back */
-        ret = fstat(fd, &st);
-        assert(!ret);
-
-        buf = malloc(st.st_size + 1);
-        ret = read(fd, buf, st.st_size);
-        assert(ret == st.st_size);
-        buf[ret] = 0;
-
-        /* Clean up */
-        close(fd);
-        unlink(tmp);
-
-        return buf;
-}
-
-static void init_prog(struct context *ctx, unsigned local_sz,
-                      unsigned private_sz, unsigned input_sz,
-                      const char *src, const char *defs)
-{
-        struct pipe_context *pipe = ctx->pipe;
-        struct tgsi_token prog[1024];
-        struct pipe_compute_state cs = {
-                .ir_type = PIPE_SHADER_IR_TGSI,
-                .prog = prog,
-                .req_local_mem = local_sz,
-                .req_private_mem = private_sz,
-                .req_input_mem = input_sz
-        };
-        char *psrc = preprocess_prog(ctx, src, defs);
-        ASSERTED int ret;
-
-        ret = tgsi_text_translate(psrc, prog, ARRAY_SIZE(prog));
-        assert(ret);
-        free(psrc);
-
-        ctx->hwcs = pipe->create_compute_state(pipe, &cs);
-        assert(ctx->hwcs);
-
-        pipe->bind_compute_state(pipe, ctx->hwcs);
-}
-
-static void destroy_prog(struct context *ctx)
-{
-        struct pipe_context *pipe = ctx->pipe;
-
-        pipe->delete_compute_state(pipe, ctx->hwcs);
-        ctx->hwcs = NULL;
-}
-
-static void init_tex(struct context *ctx, int slot,
-                     enum pipe_texture_target target, bool rw,
-                     enum pipe_format format, int w, int h,
-                     void (*init)(void *, int, int, int))
-{
-        struct pipe_context *pipe = ctx->pipe;
-        struct pipe_resource **tex = &ctx->tex[slot];
-        struct pipe_resource ttex = {
-                .target = target,
-                .format = format,
-                .width0 = w,
-                .height0 = h,
-                .depth0 = 1,
-                .array_size = 1,
-                .bind = (PIPE_BIND_SAMPLER_VIEW |
-                         PIPE_BIND_COMPUTE_RESOURCE |
-                         PIPE_BIND_GLOBAL)
-        };
-        int dx = util_format_get_blocksize(format);
-        int dy = util_format_get_stride(format, w);
-        int nx = (target == PIPE_BUFFER ? (w / dx) :
-                  util_format_get_nblocksx(format, w));
-        int ny = (target == PIPE_BUFFER ? 1 :
-                  util_format_get_nblocksy(format, h));
-        struct pipe_transfer *xfer;
-        char *map;
-        int x, y;
-
-        *tex = ctx->screen->resource_create(ctx->screen, &ttex);
-        assert(*tex);
-
-        map = pipe->texture_map(pipe, *tex, 0, PIPE_MAP_WRITE,
-                                  &(struct pipe_box) { .width = w,
-                                                  .height = h,
-                                                  .depth = 1 }, &xfer);
-        assert(xfer);
-        assert(map);
-
-        for (y = 0; y < ny; ++y) {
-                for (x = 0; x < nx; ++x) {
-                        init(map + y * dy + x * dx, slot, x, y);
-                }
-        }
-
-        pipe->texture_unmap(pipe, xfer);
-
-        ctx->tex_rw[slot] = rw;
-}
-
-static bool default_check(void *x, void *y, int sz) {
-        return !memcmp(x, y, sz);
-}
-
-static void check_tex(struct context *ctx, int slot,
-                      void (*expect)(void *, int, int, int),
-                      bool (*check)(void *, void *, int))
-{
-        struct pipe_context *pipe = ctx->pipe;
-        struct pipe_resource *tex = ctx->tex[slot];
-        int dx = util_format_get_blocksize(tex->format);
-        int dy = util_format_get_stride(tex->format, tex->width0);
-        int nx = (tex->target == PIPE_BUFFER ? (tex->width0 / dx) :
-                  util_format_get_nblocksx(tex->format, tex->width0));
-        int ny = (tex->target == PIPE_BUFFER ? 1 :
-                  util_format_get_nblocksy(tex->format, tex->height0));
-        struct pipe_transfer *xfer;
-        char *map;
-        int x = 0, y, i;
-        int err = 0;
-
-        if (!check)
-                check = default_check;
-
-        map = pipe->texture_map(pipe, tex, 0, PIPE_MAP_READ,
-                                  &(struct pipe_box) { .width = tex->width0,
-                                        .height = tex->height0,
-                                        .depth = 1 }, &xfer);
-        assert(xfer);
-        assert(map);
-
-        for (y = 0; y < ny; ++y) {
-                for (x = 0; x < nx; ++x) {
-                        uint32_t exp[4];
-                        uint32_t *res = (uint32_t *)(map + y * dy + x * dx);
-
-                        expect(exp, slot, x, y);
-                        if (check(res, exp, dx) || (++err) > 20)
-                                continue;
-
-                        if (dx < 4) {
-                                uint32_t u = 0, v = 0;
-
-                                for (i = 0; i < dx; i++) {
-                                        u |= ((uint8_t *)exp)[i] << (8 * i);
-                                        v |= ((uint8_t *)res)[i] << (8 * i);
-                                }
-                                printf("(%d, %d): got 0x%x, expected 0x%x\n",
-                                       x, y, v, u);
-                        } else {
-                                for (i = 0; i < dx / 4; i++) {
-                                        printf("(%d, %d)[%d]: got 0x%x/%f,"
-                                               " expected 0x%x/%f\n", x, y, i,
-                                               res[i], ((float *)res)[i],
-                                               exp[i], ((float *)exp)[i]);
-                                }
-                        }
-                }
-        }
-
-        pipe->texture_unmap(pipe, xfer);
-
-        if (err)
-                printf("(%d, %d): \x1b[31mFAIL\x1b[0m (%d)\n", x, y, err);
-        else
-                printf("(%d, %d): \x1b[32mOK\x1b[0m\n", x, y);
-}
-
-static void destroy_tex(struct context *ctx)
-{
-        int i;
-
-        for (i = 0; i < MAX_RESOURCES; ++i) {
-                if (ctx->tex[i])
-                        pipe_resource_reference(&ctx->tex[i], NULL);
-        }
-}
-
-static void init_sampler_views(struct context *ctx, const int *slots)
-{
-        struct pipe_context *pipe = ctx->pipe;
-        struct pipe_sampler_view tview;
-        int i;
-
-        for (i = 0; *slots >= 0; ++i, ++slots) {
-                u_sampler_view_default_template(&tview, ctx->tex[*slots],
-                                                ctx->tex[*slots]->format);
-
-                ctx->view[i] = pipe->create_sampler_view(pipe, ctx->tex[*slots],
-                                                         &tview);
-                assert(ctx->view[i]);
-        }
-
-        pipe->set_sampler_views(pipe, PIPE_SHADER_COMPUTE, 0, i, 0, false, ctx->view);
-}
-
-static void destroy_sampler_views(struct context *ctx)
-{
-        struct pipe_context *pipe = ctx->pipe;
-        int i;
-
-        pipe->set_sampler_views(pipe, PIPE_SHADER_COMPUTE, 0, 0, MAX_RESOURCES, false, NULL);
-
-        for (i = 0; i < MAX_RESOURCES; ++i) {
-                if (ctx->view[i]) {
-                        pipe->sampler_view_destroy(pipe, ctx->view[i]);
-                        ctx->view[i] = NULL;
-                }
-        }
-}
-
-static void init_compute_resources(struct context *ctx, const int *slots)
-{
-        struct pipe_context *pipe = ctx->pipe;
-        int i;
-
-        for (i = 0; *slots >= 0; ++i, ++slots) {
-                struct pipe_surface tsurf = {
-                        .format = ctx->tex[*slots]->format,
-                        .writable = ctx->tex_rw[*slots]
-                };
-
-                if (ctx->tex[*slots]->target == PIPE_BUFFER)
-                        tsurf.u.buf.last_element = ctx->tex[*slots]->width0 - 1;
-
-                ctx->surf[i] = pipe->create_surface(pipe, ctx->tex[*slots],
-                                                    &tsurf);
-                assert(ctx->surf[i]);
-        }
-
-        pipe->set_compute_resources(pipe, 0, i, ctx->surf);
-}
-
-static void destroy_compute_resources(struct context *ctx)
-{
-        struct pipe_context *pipe = ctx->pipe;
-        int i;
-
-        pipe->set_compute_resources(pipe, 0, MAX_RESOURCES, NULL);
-
-        for (i = 0; i < MAX_RESOURCES; ++i) {
-                if (ctx->surf[i]) {
-                        pipe->surface_destroy(pipe, ctx->surf[i]);
-                        ctx->surf[i] = NULL;
-                }
-        }
-}
-
-static void init_sampler_states(struct context *ctx, int n)
-{
-        struct pipe_context *pipe = ctx->pipe;
-        struct pipe_sampler_state smp = {0};
-        int i;
-
-        for (i = 0; i < n; ++i) {
-                ctx->hwsmp[i] = pipe->create_sampler_state(pipe, &smp);
-                assert(ctx->hwsmp[i]);
-        }
-
-        pipe->bind_sampler_states(pipe, PIPE_SHADER_COMPUTE, 0, i, ctx->hwsmp);
-}
-
-static void destroy_sampler_states(struct context *ctx)
-{
-        struct pipe_context *pipe = ctx->pipe;
-        int i;
-
-        pipe->bind_sampler_states(pipe, PIPE_SHADER_COMPUTE,
-				  0, MAX_RESOURCES, NULL);
-
-        for (i = 0; i < MAX_RESOURCES; ++i) {
-                if (ctx->hwsmp[i]) {
-                        pipe->delete_sampler_state(pipe, ctx->hwsmp[i]);
-                        ctx->hwsmp[i] = NULL;
-                }
-        }
-}
-
-static void init_globals(struct context *ctx, const int *slots,
-                         uint32_t **handles)
-{
-        struct pipe_context *pipe = ctx->pipe;
-        struct pipe_resource *res[MAX_RESOURCES];
-        int i;
-
-        for (i = 0; *slots >= 0; ++i, ++slots)
-                res[i] = ctx->tex[*slots];
-
-        pipe->set_global_binding(pipe, 0, i, res, handles);
-}
-
-static void destroy_globals(struct context *ctx)
-{
-        struct pipe_context *pipe = ctx->pipe;
-
-        pipe->set_global_binding(pipe, 0, MAX_RESOURCES, NULL, NULL);
-}
-
-static void launch_grid(struct context *ctx, const uint *block_layout,
-                        const uint *grid_layout, uint32_t pc,
-                        void *input)
-{
-        struct pipe_context *pipe = ctx->pipe;
-        struct pipe_grid_info info;
-        int i;
-
-        for (i = 0; i < 3; i++) {
-                info.block[i] = block_layout[i];
-                info.grid[i] = grid_layout[i];
-        }
-        info.pc = pc;
-        info.input = input;
-
-        pipe->launch_grid(pipe, &info);
-}
-
-static void test_default_init(void *p, int s, int x, int y)
-{
-        *(uint32_t *)p = 0xdeadbeef;
-}
-
-/* test_system_values */
-static void test_system_values_expect(void *p, int s, int x, int y)
-{
-        int id = x / 16, sv = (x % 16) / 4, c = x % 4;
-        int tid[] = { id % 20, (id % 240) / 20, id / 240, 0 };
-        int bsz[] = { 4, 3, 5, 1};
-        int gsz[] = { 5, 4, 1, 1};
-
-        switch (sv) {
-        case 0:
-                *(uint32_t *)p = tid[c] / bsz[c];
-                break;
-        case 1:
-                *(uint32_t *)p = bsz[c];
-                break;
-        case 2:
-                *(uint32_t *)p = gsz[c];
-                break;
-        case 3:
-                *(uint32_t *)p = tid[c] % bsz[c];
-                break;
-        }
-}
-
-static void test_system_values(struct context *ctx)
-{
-        const char *src = "COMP\n"
-                "DCL RES[0], BUFFER, RAW, WR\n"
-                "DCL SV[0], BLOCK_ID[0]\n"
-                "DCL SV[1], BLOCK_SIZE[0]\n"
-                "DCL SV[2], GRID_SIZE[0]\n"
-                "DCL SV[3], THREAD_ID[0]\n"
-                "DCL TEMP[0], LOCAL\n"
-                "DCL TEMP[1], LOCAL\n"
-                "IMM UINT32 { 64, 0, 0, 0 }\n"
-                "IMM UINT32 { 16, 0, 0, 0 }\n"
-                "IMM UINT32 { 0, 0, 0, 0 }\n"
-                "\n"
-                "BGNSUB"
-                "  UMUL TEMP[0], SV[0], SV[1]\n"
-                "  UADD TEMP[0], TEMP[0], SV[3]\n"
-                "  UMUL TEMP[1], SV[1], SV[2]\n"
-                "  UMUL TEMP[0].w, TEMP[0], TEMP[1].zzzz\n"
-                "  UMUL TEMP[0].zw, TEMP[0], TEMP[1].yyyy\n"
-                "  UMUL TEMP[0].yzw, TEMP[0], TEMP[1].xxxx\n"
-                "  UADD TEMP[0].xy, TEMP[0].xyxy, TEMP[0].zwzw\n"
-                "  UADD TEMP[0].x, TEMP[0].xxxx, TEMP[0].yyyy\n"
-                "  UMUL TEMP[0].x, TEMP[0], IMM[0]\n"
-                "  STORE RES[0].xyzw, TEMP[0], SV[0]\n"
-                "  UADD TEMP[0].x, TEMP[0], IMM[1]\n"
-                "  STORE RES[0].xyzw, TEMP[0], SV[1]\n"
-                "  UADD TEMP[0].x, TEMP[0], IMM[1]\n"
-                "  STORE RES[0].xyzw, TEMP[0], SV[2]\n"
-                "  UADD TEMP[0].x, TEMP[0], IMM[1]\n"
-                "  STORE RES[0].xyzw, TEMP[0], SV[3]\n"
-                "  RET\n"
-                "ENDSUB\n";
-
-        printf("- %s\n", __func__);
-
-        init_prog(ctx, 0, 0, 0, src, NULL);
-        init_tex(ctx, 0, PIPE_BUFFER, true, PIPE_FORMAT_R32_FLOAT,
-                 76800, 0, test_default_init);
-        init_compute_resources(ctx, (int []) { 0, -1 });
-        launch_grid(ctx, (uint []){4, 3, 5}, (uint []){5, 4, 1}, 0, NULL);
-        check_tex(ctx, 0, test_system_values_expect, NULL);
-        destroy_compute_resources(ctx);
-        destroy_tex(ctx);
-        destroy_prog(ctx);
-}
-
-/* test_resource_access */
-static void test_resource_access_init0(void *p, int s, int x, int y)
-{
-        *(float *)p = 8.0 - (float)x;
-}
-
-static void test_resource_access_expect(void *p, int s, int x, int y)
-{
-        *(float *)p = 8.0 - (float)((x + 4 * y) & 0x3f);
-}
-
-static void test_resource_access(struct context *ctx)
-{
-        const char *src = "COMP\n"
-                "DCL RES[0], BUFFER, RAW, WR\n"
-                "DCL RES[1], 2D, RAW, WR\n"
-                "DCL SV[0], BLOCK_ID[0]\n"
-                "DCL TEMP[0], LOCAL\n"
-                "DCL TEMP[1], LOCAL\n"
-                "IMM UINT32 { 15, 0, 0, 0 }\n"
-                "IMM UINT32 { 16, 1, 0, 0 }\n"
-                "\n"
-                "    BGNSUB\n"
-                "       UADD TEMP[0].x, SV[0].xxxx, SV[0].yyyy\n"
-                "       AND TEMP[0].x, TEMP[0], IMM[0]\n"
-                "       UMUL TEMP[0].x, TEMP[0], IMM[1]\n"
-                "       LOAD TEMP[0].xyzw, RES[0], TEMP[0]\n"
-                "       UMUL TEMP[1], SV[0], IMM[1]\n"
-                "       STORE RES[1].xyzw, TEMP[1], TEMP[0]\n"
-                "       RET\n"
-                "    ENDSUB\n";
-
-        printf("- %s\n", __func__);
-
-        init_prog(ctx, 0, 0, 0, src, NULL);
-        init_tex(ctx, 0, PIPE_BUFFER, true, PIPE_FORMAT_R32_FLOAT,
-                 256, 0, test_resource_access_init0);
-        init_tex(ctx, 1, PIPE_TEXTURE_2D, true, PIPE_FORMAT_R32_FLOAT,
-                 60, 12, test_default_init);
-        init_compute_resources(ctx, (int []) { 0, 1, -1 });
-        launch_grid(ctx, (uint []){1, 1, 1}, (uint []){15, 12, 1}, 0, NULL);
-        check_tex(ctx, 1, test_resource_access_expect, NULL);
-        destroy_compute_resources(ctx);
-        destroy_tex(ctx);
-        destroy_prog(ctx);
-}
-
-/* test_function_calls */
-static void test_function_calls_init(void *p, int s, int x, int y)
-{
-        *(uint32_t *)p = 15 * y + x;
-}
-
-static void test_function_calls_expect(void *p, int s, int x, int y)
-{
-        *(uint32_t *)p = (15 * y + x) < 4 ? 2 : 1 ;
-}
-
-static void test_function_calls(struct context *ctx)
-{
-        const char *src = "COMP\n"
-                "DCL RES[0], 2D, RAW, WR\n"
-                "DCL SV[0], BLOCK_ID[0]\n"
-                "DCL SV[1], BLOCK_SIZE[0]\n"
-                "DCL SV[2], GRID_SIZE[0]\n"
-                "DCL SV[3], THREAD_ID[0]\n"
-                "DCL TEMP[0]\n"
-                "DCL TEMP[1]\n"
-                "DCL TEMP[2], LOCAL\n"
-                "IMM UINT32 { 0, 11, 22, 33 }\n"
-                "IMM FLT32 { 11, 33, 55, 99 }\n"
-                "IMM UINT32 { 4, 1, 0, 0 }\n"
-                "IMM UINT32 { 12, 0, 0, 0 }\n"
-                "\n"
-                "00: BGNSUB\n"
-                "01:  UMUL TEMP[0].x, TEMP[0], TEMP[0]\n"
-                "02:  UADD TEMP[1].x, TEMP[1], IMM[2].yyyy\n"
-                "03:  USLT TEMP[0].x, TEMP[0], IMM[0]\n"
-                "04:  RET\n"
-                "05: ENDSUB\n"
-                "06: BGNSUB\n"
-                "07:  UMUL TEMP[0].x, TEMP[0], TEMP[0]\n"
-                "08:  UADD TEMP[1].x, TEMP[1], IMM[2].yyyy\n"
-                "09:  USLT TEMP[0].x, TEMP[0], IMM[0].yyyy\n"
-                "10:  IF TEMP[0].xxxx\n"
-                "11:   CAL :0\n"
-                "12:  ENDIF\n"
-                "13:  RET\n"
-                "14: ENDSUB\n"
-                "15: BGNSUB\n"
-                "16:  UMUL TEMP[2], SV[0], SV[1]\n"
-                "17:  UADD TEMP[2], TEMP[2], SV[3]\n"
-                "18:  UMUL TEMP[2], TEMP[2], IMM[2]\n"
-                "00:  MOV TEMP[1].x, IMM[2].wwww\n"
-                "19:  LOAD TEMP[0].x, RES[0].xxxx, TEMP[2]\n"
-                "20:  CAL :6\n"
-                "21:  STORE RES[0].x, TEMP[2], TEMP[1].xxxx\n"
-                "22:  RET\n"
-                "23: ENDSUB\n";
-
-        printf("- %s\n", __func__);
-
-        init_prog(ctx, 0, 0, 0, src, NULL);
-        init_tex(ctx, 0, PIPE_TEXTURE_2D, true, PIPE_FORMAT_R32_FLOAT,
-                 15, 12, test_function_calls_init);
-        init_compute_resources(ctx, (int []) { 0, -1 });
-        launch_grid(ctx, (uint []){3, 3, 3}, (uint []){5, 4, 1}, 15, NULL);
-        check_tex(ctx, 0, test_function_calls_expect, NULL);
-        destroy_compute_resources(ctx);
-        destroy_tex(ctx);
-        destroy_prog(ctx);
-}
-
-/* test_input_global */
-static void test_input_global_expect(void *p, int s, int x, int y)
-{
-        *(uint32_t *)p = 0xdeadbeef - (x == 0 ? 0x10001 + 2 * s : 0);
-}
-
-static void test_input_global(struct context *ctx)
-{
-        const char *src = "COMP\n"
-                "DCL SV[0], THREAD_ID[0]\n"
-                "DCL TEMP[0], LOCAL\n"
-                "DCL TEMP[1], LOCAL\n"
-                "IMM UINT32 { 8, 0, 0, 0 }\n"
-                "\n"
-                "    BGNSUB\n"
-                "       UMUL TEMP[0], SV[0], IMM[0]\n"
-                "       LOAD TEMP[1].xy, RINPUT, TEMP[0]\n"
-                "       LOAD TEMP[0].x, RGLOBAL, TEMP[1].yyyy\n"
-                "       UADD TEMP[1].x, TEMP[0], -TEMP[1]\n"
-                "       STORE RGLOBAL.x, TEMP[1].yyyy, TEMP[1]\n"
-                "       RET\n"
-                "    ENDSUB\n";
-        uint32_t input[8] = { 0x10001, 0x10002, 0x10003, 0x10004,
-                              0x10005, 0x10006, 0x10007, 0x10008 };
-
-        printf("- %s\n", __func__);
-
-        init_prog(ctx, 0, 0, 32, src, NULL);
-        init_tex(ctx, 0, PIPE_BUFFER, true, PIPE_FORMAT_R32_FLOAT, 32, 0,
-                 test_default_init);
-        init_tex(ctx, 1, PIPE_BUFFER, true, PIPE_FORMAT_R32_FLOAT, 32, 0,
-                 test_default_init);
-        init_tex(ctx, 2, PIPE_BUFFER, true, PIPE_FORMAT_R32_FLOAT, 32, 0,
-                 test_default_init);
-        init_tex(ctx, 3, PIPE_BUFFER, true, PIPE_FORMAT_R32_FLOAT, 32, 0,
-                 test_default_init);
-        init_globals(ctx, (int []){ 0, 1, 2, 3, -1 },
-                     (uint32_t *[]){ &input[1], &input[3],
-                                     &input[5], &input[7] });
-        launch_grid(ctx, (uint []){4, 1, 1}, (uint []){1, 1, 1}, 0, input);
-        check_tex(ctx, 0, test_input_global_expect, NULL);
-        check_tex(ctx, 1, test_input_global_expect, NULL);
-        check_tex(ctx, 2, test_input_global_expect, NULL);
-        check_tex(ctx, 3, test_input_global_expect, NULL);
-        destroy_globals(ctx);
-        destroy_tex(ctx);
-        destroy_prog(ctx);
-}
-
-/* test_private */
-static void test_private_expect(void *p, int s, int x, int y)
-{
-        *(uint32_t *)p = (x / 32) + x % 32;
-}
-
-static void test_private(struct context *ctx)
-{
-        const char *src = "COMP\n"
-                "DCL RES[0], BUFFER, RAW, WR\n"
-                "DCL SV[0], BLOCK_ID[0]\n"
-                "DCL SV[1], BLOCK_SIZE[0]\n"
-                "DCL SV[2], THREAD_ID[0]\n"
-                "DCL TEMP[0], LOCAL\n"
-                "DCL TEMP[1], LOCAL\n"
-                "DCL TEMP[2], LOCAL\n"
-                "IMM UINT32 { 128, 0, 0, 0 }\n"
-                "IMM UINT32 { 4, 0, 0, 0 }\n"
-                "\n"
-                "    BGNSUB\n"
-                "       UMUL TEMP[0].x, SV[0], SV[1]\n"
-                "       UADD TEMP[0].x, TEMP[0], SV[2]\n"
-                "       MOV TEMP[1].x, IMM[0].wwww\n"
-                "       BGNLOOP\n"
-                "               USEQ TEMP[2].x, TEMP[1], IMM[0]\n"
-                "               IF TEMP[2]\n"
-                "                       BRK\n"
-                "               ENDIF\n"
-                "               UDIV TEMP[2].x, TEMP[1], IMM[1]\n"
-                "               UADD TEMP[2].x, TEMP[2], TEMP[0]\n"
-                "               STORE RPRIVATE.x, TEMP[1], TEMP[2]\n"
-                "               UADD TEMP[1].x, TEMP[1], IMM[1]\n"
-                "       ENDLOOP\n"
-                "       MOV TEMP[1].x, IMM[0].wwww\n"
-                "       UMUL TEMP[0].x, TEMP[0], IMM[0]\n"
-                "       BGNLOOP\n"
-                "               USEQ TEMP[2].x, TEMP[1], IMM[0]\n"
-                "               IF TEMP[2]\n"
-                "                       BRK\n"
-                "               ENDIF\n"
-                "               LOAD TEMP[2].x, RPRIVATE, TEMP[1]\n"
-                "               STORE RES[0].x, TEMP[0], TEMP[2]\n"
-                "               UADD TEMP[0].x, TEMP[0], IMM[1]\n"
-                "               UADD TEMP[1].x, TEMP[1], IMM[1]\n"
-                "       ENDLOOP\n"
-                "       RET\n"
-                "    ENDSUB\n";
-
-        printf("- %s\n", __func__);
-
-        init_prog(ctx, 0, 128, 0, src, NULL);
-        init_tex(ctx, 0, PIPE_BUFFER, true, PIPE_FORMAT_R32_FLOAT,
-                 32768, 0, test_default_init);
-        init_compute_resources(ctx, (int []) { 0, -1 });
-        launch_grid(ctx, (uint []){16, 1, 1}, (uint []){16, 1, 1}, 0, NULL);
-        check_tex(ctx, 0, test_private_expect, NULL);
-        destroy_compute_resources(ctx);
-        destroy_tex(ctx);
-        destroy_prog(ctx);
-}
-
-/* test_local */
-static void test_local_expect(void *p, int s, int x, int y)
-{
-        *(uint32_t *)p = x & 0x20 ? 2 : 1;
-}
-
-static void test_local(struct context *ctx)
-{
-        const char *src = "COMP\n"
-                "DCL RES[0], BUFFER, RAW, WR\n"
-                "DCL SV[0], BLOCK_ID[0]\n"
-                "DCL SV[1], BLOCK_SIZE[0]\n"
-                "DCL SV[2], THREAD_ID[0]\n"
-                "DCL TEMP[0], LOCAL\n"
-                "DCL TEMP[1], LOCAL\n"
-                "DCL TEMP[2], LOCAL\n"
-                "IMM UINT32 { 1, 0, 0, 0 }\n"
-                "IMM UINT32 { 2, 0, 0, 0 }\n"
-                "IMM UINT32 { 4, 0, 0, 0 }\n"
-                "IMM UINT32 { 32, 0, 0, 0 }\n"
-                "IMM UINT32 { 128, 0, 0, 0 }\n"
-                "\n"
-                "    BGNSUB\n"
-                "       UMUL TEMP[0].x, SV[2], IMM[2]\n"
-                "       STORE RLOCAL.x, TEMP[0], IMM[0].wwww\n"
-                "       MFENCE RLOCAL\n"
-                "       USLT TEMP[1].x, SV[2], IMM[3]\n"
-                "       IF TEMP[1]\n"
-                "               UADD TEMP[1].x, TEMP[0], IMM[4]\n"
-                "               BGNLOOP\n"
-                "                       LOAD TEMP[2].x, RLOCAL, TEMP[1]\n"
-                "                       USEQ TEMP[2].x, TEMP[2], IMM[0]\n"
-                "                       IF TEMP[2]\n"
-                "                               BRK\n"
-                "                       ENDIF\n"
-                "               ENDLOOP\n"
-                "               STORE RLOCAL.x, TEMP[0], IMM[0]\n"
-                "               MFENCE RLOCAL\n"
-                "               BGNLOOP\n"
-                "                       LOAD TEMP[2].x, RLOCAL, TEMP[1]\n"
-                "                       USEQ TEMP[2].x, TEMP[2], IMM[1]\n"
-                "                       IF TEMP[2]\n"
-                "                               BRK\n"
-                "                       ENDIF\n"
-                "               ENDLOOP\n"
-                "       ELSE\n"
-                "               UADD TEMP[1].x, TEMP[0], -IMM[4]\n"
-                "               BGNLOOP\n"
-                "                       LOAD TEMP[2].x, RLOCAL, TEMP[1]\n"
-                "                       USEQ TEMP[2].x, TEMP[2], IMM[0].wwww\n"
-                "                       IF TEMP[2]\n"
-                "                               BRK\n"
-                "                       ENDIF\n"
-                "               ENDLOOP\n"
-                "               STORE RLOCAL.x, TEMP[0], IMM[0]\n"
-                "               MFENCE RLOCAL\n"
-                "               BGNLOOP\n"
-                "                       LOAD TEMP[2].x, RLOCAL, TEMP[1]\n"
-                "                       USEQ TEMP[2].x, TEMP[2], IMM[0]\n"
-                "                       IF TEMP[2]\n"
-                "                               BRK\n"
-                "                       ENDIF\n"
-                "               ENDLOOP\n"
-                "               STORE RLOCAL.x, TEMP[0], IMM[1]\n"
-                "               MFENCE RLOCAL\n"
-                "       ENDIF\n"
-                "       UMUL TEMP[1].x, SV[0], SV[1]\n"
-                "       UMUL TEMP[1].x, TEMP[1], IMM[2]\n"
-                "       UADD TEMP[1].x, TEMP[1], TEMP[0]\n"
-                "       LOAD TEMP[0].x, RLOCAL, TEMP[0]\n"
-                "       STORE RES[0].x, TEMP[1], TEMP[0]\n"
-                "       RET\n"
-                "    ENDSUB\n";
-
-        printf("- %s\n", __func__);
-
-        init_prog(ctx, 256, 0, 0, src, NULL);
-        init_tex(ctx, 0, PIPE_BUFFER, true, PIPE_FORMAT_R32_FLOAT,
-                 4096, 0, test_default_init);
-        init_compute_resources(ctx, (int []) { 0, -1 });
-        launch_grid(ctx, (uint []){64, 1, 1}, (uint []){16, 1, 1}, 0, NULL);
-        check_tex(ctx, 0, test_local_expect, NULL);
-        destroy_compute_resources(ctx);
-        destroy_tex(ctx);
-        destroy_prog(ctx);
-}
-
-/* test_sample */
-static void test_sample_init(void *p, int s, int x, int y)
-{
-        *(float *)p = s ? 1 : x * y;
-}
-
-static void test_sample_expect(void *p, int s, int x, int y)
-{
-        switch (x % 4) {
-        case 0:
-                *(float *)p = x / 4 * y;
-                break;
-        case 1:
-        case 2:
-                *(float *)p = 0;
-                break;
-        case 3:
-                *(float *)p = 1;
-                break;
-        }
-}
-
-static void test_sample(struct context *ctx)
-{
-        const char *src = "COMP\n"
-                "DCL SVIEW[0], 2D, FLOAT\n"
-                "DCL RES[0], 2D, RAW, WR\n"
-                "DCL SAMP[0]\n"
-                "DCL SV[0], BLOCK_ID[0]\n"
-                "DCL TEMP[0], LOCAL\n"
-                "DCL TEMP[1], LOCAL\n"
-                "IMM UINT32 { 16, 1, 0, 0 }\n"
-                "IMM FLT32 { 128, 32, 0, 0 }\n"
-                "\n"
-                "    BGNSUB\n"
-                "       I2F TEMP[1], SV[0]\n"
-                "       DIV TEMP[1], TEMP[1], IMM[1]\n"
-                "       SAMPLE TEMP[1], TEMP[1], SVIEW[0], SAMP[0]\n"
-                "       UMUL TEMP[0], SV[0], IMM[0]\n"
-                "       STORE RES[0].xyzw, TEMP[0], TEMP[1]\n"
-                "       RET\n"
-                "    ENDSUB\n";
-
-        printf("- %s\n", __func__);
-
-        init_prog(ctx, 0, 0, 0, src, NULL);
-        init_tex(ctx, 0, PIPE_TEXTURE_2D, true, PIPE_FORMAT_R32_FLOAT,
-                 128, 32, test_sample_init);
-        init_tex(ctx, 1, PIPE_TEXTURE_2D, true, PIPE_FORMAT_R32_FLOAT,
-                 512, 32, test_sample_init);
-        init_compute_resources(ctx, (int []) { 1, -1 });
-        init_sampler_views(ctx, (int []) { 0, -1 });
-        init_sampler_states(ctx, 2);
-        launch_grid(ctx, (uint []){1, 1, 1}, (uint []){128, 32, 1}, 0, NULL);
-        check_tex(ctx, 1, test_sample_expect, NULL);
-        destroy_sampler_states(ctx);
-        destroy_sampler_views(ctx);
-        destroy_compute_resources(ctx);
-        destroy_tex(ctx);
-        destroy_prog(ctx);
-}
-
-/* test_many_kern */
-static void test_many_kern_expect(void *p, int s, int x, int y)
-{
-        *(uint32_t *)p = x;
-}
-
-static void test_many_kern(struct context *ctx)
-{
-        const char *src = "COMP\n"
-                "DCL RES[0], BUFFER, RAW, WR\n"
-                "DCL TEMP[0], LOCAL\n"
-                "IMM UINT32 { 0, 1, 2, 3 }\n"
-                "IMM UINT32 { 4, 0, 0, 0 }\n"
-                "\n"
-                "    BGNSUB\n"
-                "       UMUL TEMP[0].x, IMM[0].xxxx, IMM[1].xxxx\n"
-                "       STORE RES[0].x, TEMP[0], IMM[0].xxxx\n"
-                "       RET\n"
-                "    ENDSUB\n"
-                "    BGNSUB\n"
-                "       UMUL TEMP[0].x, IMM[0].yyyy, IMM[1].xxxx\n"
-                "       STORE RES[0].x, TEMP[0], IMM[0].yyyy\n"
-                "       RET\n"
-                "    ENDSUB\n"
-                "    BGNSUB\n"
-                "       UMUL TEMP[0].x, IMM[0].zzzz, IMM[1].xxxx\n"
-                "       STORE RES[0].x, TEMP[0], IMM[0].zzzz\n"
-                "       RET\n"
-                "    ENDSUB\n"
-                "    BGNSUB\n"
-                "       UMUL TEMP[0].x, IMM[0].wwww, IMM[1].xxxx\n"
-                "       STORE RES[0].x, TEMP[0], IMM[0].wwww\n"
-                "       RET\n"
-                "    ENDSUB\n";
-
-        printf("- %s\n", __func__);
-
-        init_prog(ctx, 0, 0, 0, src, NULL);
-        init_tex(ctx, 0, PIPE_BUFFER, true, PIPE_FORMAT_R32_FLOAT,
-                 16, 0, test_default_init);
-        init_compute_resources(ctx, (int []) { 0, -1 });
-        launch_grid(ctx, (uint []){1, 1, 1}, (uint []){1, 1, 1}, 0, NULL);
-        launch_grid(ctx, (uint []){1, 1, 1}, (uint []){1, 1, 1}, 5, NULL);
-        launch_grid(ctx, (uint []){1, 1, 1}, (uint []){1, 1, 1}, 10, NULL);
-        launch_grid(ctx, (uint []){1, 1, 1}, (uint []){1, 1, 1}, 15, NULL);
-        check_tex(ctx, 0, test_many_kern_expect, NULL);
-        destroy_compute_resources(ctx);
-        destroy_tex(ctx);
-        destroy_prog(ctx);
-}
-
-/* test_constant */
-static void test_constant_init(void *p, int s, int x, int y)
-{
-        *(float *)p = s ? 0xdeadbeef : 8.0 - (float)x;
-}
-
-static void test_constant_expect(void *p, int s, int x, int y)
-{
-        *(float *)p = 8.0 - (float)x;
-}
-
-static void test_constant(struct context *ctx)
-{
-        const char *src = "COMP\n"
-                "DCL RES[0], BUFFER, RAW\n"
-                "DCL RES[1], BUFFER, RAW, WR\n"
-                "DCL SV[0], BLOCK_ID[0]\n"
-                "DCL TEMP[0], LOCAL\n"
-                "DCL TEMP[1], LOCAL\n"
-                "IMM UINT32 { 4, 0, 0, 0 }\n"
-                "\n"
-                "    BGNSUB\n"
-                "       UMUL TEMP[0].x, SV[0], IMM[0]\n"
-                "       LOAD TEMP[1].x, RES[0], TEMP[0]\n"
-                "       STORE RES[1].x, TEMP[0], TEMP[1]\n"
-                "       RET\n"
-                "    ENDSUB\n";
-
-        printf("- %s\n", __func__);
-
-        init_prog(ctx, 0, 0, 0, src, NULL);
-        init_tex(ctx, 0, PIPE_BUFFER, false, PIPE_FORMAT_R32_FLOAT,
-                 256, 0, test_constant_init);
-        init_tex(ctx, 1, PIPE_BUFFER, true, PIPE_FORMAT_R32_FLOAT,
-                 256, 0, test_constant_init);
-        init_compute_resources(ctx, (int []) { 0, 1, -1 });
-        launch_grid(ctx, (uint []){1, 1, 1}, (uint []){64, 1, 1}, 0, NULL);
-        check_tex(ctx, 1, test_constant_expect, NULL);
-        destroy_compute_resources(ctx);
-        destroy_tex(ctx);
-        destroy_prog(ctx);
-}
-
-/* test_resource_indirect */
-static void test_resource_indirect_init(void *p, int s, int x, int y)
-{
-        *(uint32_t *)p = s == 0 ? 0xdeadbeef :
-                s == 1 ? x % 2 :
-                s == 2 ? 2 * x :
-                2 * x + 1;
-}
-
-static void test_resource_indirect_expect(void *p, int s, int x, int y)
-{
-        *(uint32_t *)p = 2 * x + (x % 2 ? 1 : 0);
-}
-
-static void test_resource_indirect(struct context *ctx)
-{
-        const char *src = "COMP\n"
-                "DCL RES[0], BUFFER, RAW, WR\n"
-                "DCL RES[1..3], BUFFER, RAW\n"
-                "DCL SV[0], BLOCK_ID[0]\n"
-                "DCL TEMP[0], LOCAL\n"
-                "DCL TEMP[1], LOCAL\n"
-                "IMM UINT32 { 4, 0, 0, 0 }\n"
-                "\n"
-                "    BGNSUB\n"
-                "       UMUL TEMP[0].x, SV[0], IMM[0]\n"
-                "       LOAD TEMP[1].x, RES[1], TEMP[0]\n"
-                "       LOAD TEMP[1].x, RES[TEMP[1].x+2], TEMP[0]\n"
-                "       STORE RES[0].x, TEMP[0], TEMP[1]\n"
-                "       RET\n"
-                "    ENDSUB\n";
-
-        printf("- %s\n", __func__);
-
-        init_prog(ctx, 0, 0, 0, src, NULL);
-        init_tex(ctx, 0, PIPE_BUFFER, true, PIPE_FORMAT_R32_FLOAT,
-                 256, 0, test_resource_indirect_init);
-        init_tex(ctx, 1, PIPE_BUFFER, false, PIPE_FORMAT_R32_FLOAT,
-                 256, 0, test_resource_indirect_init);
-        init_tex(ctx, 2, PIPE_BUFFER, false, PIPE_FORMAT_R32_FLOAT,
-                 256, 0, test_resource_indirect_init);
-        init_tex(ctx, 3, PIPE_BUFFER, false, PIPE_FORMAT_R32_FLOAT,
-                 256, 0, test_resource_indirect_init);
-        init_compute_resources(ctx, (int []) { 0, 1, 2, 3, -1 });
-        launch_grid(ctx, (uint []){1, 1, 1}, (uint []){64, 1, 1}, 0, NULL);
-        check_tex(ctx, 0, test_resource_indirect_expect, NULL);
-        destroy_compute_resources(ctx);
-        destroy_tex(ctx);
-        destroy_prog(ctx);
-}
-
-/* test_surface_ld */
-enum pipe_format surface_fmts[] = {
-        PIPE_FORMAT_B8G8R8A8_UNORM,
-        PIPE_FORMAT_B8G8R8X8_UNORM,
-        PIPE_FORMAT_A8R8G8B8_UNORM,
-        PIPE_FORMAT_X8R8G8B8_UNORM,
-        PIPE_FORMAT_X8R8G8B8_UNORM,
-        PIPE_FORMAT_L8_UNORM,
-        PIPE_FORMAT_A8_UNORM,
-        PIPE_FORMAT_I8_UNORM,
-        PIPE_FORMAT_L8A8_UNORM,
-        PIPE_FORMAT_R32_FLOAT,
-        PIPE_FORMAT_R32G32_FLOAT,
-        PIPE_FORMAT_R32G32B32A32_FLOAT,
-        PIPE_FORMAT_R32_UNORM,
-        PIPE_FORMAT_R32G32_UNORM,
-        PIPE_FORMAT_R32G32B32A32_UNORM,
-        PIPE_FORMAT_R32_SNORM,
-        PIPE_FORMAT_R32G32_SNORM,
-        PIPE_FORMAT_R32G32B32A32_SNORM,
-        PIPE_FORMAT_R8_UINT,
-        PIPE_FORMAT_R8G8_UINT,
-        PIPE_FORMAT_R8G8B8A8_UINT,
-        PIPE_FORMAT_R8_SINT,
-        PIPE_FORMAT_R8G8_SINT,
-        PIPE_FORMAT_R8G8B8A8_SINT,
-        PIPE_FORMAT_R32_UINT,
-        PIPE_FORMAT_R32G32_UINT,
-        PIPE_FORMAT_R32G32B32A32_UINT,
-        PIPE_FORMAT_R32_SINT,
-        PIPE_FORMAT_R32G32_SINT,
-        PIPE_FORMAT_R32G32B32A32_SINT
-};
-
-static void test_surface_ld_init0f(void *p, int s, int x, int y)
-{
-        float v[] = { 1.0, -.75, .50, -.25 };
-        int i = 0;
-
-        util_format_pack_rgba(surface_fmts[i], p, v, 1);
-}
-
-static void test_surface_ld_init0i(void *p, int s, int x, int y)
-{
-        int v[] = { 0xffffffff, 0xffff, 0xff, 0xf };
-        int i = 0;
-
-        util_format_pack_rgba(surface_fmts[i], p, v, 1);
-}
-
-static void test_surface_ld_expectf(void *p, int s, int x, int y)
-{
-        float v[4], w[4];
-        int i = 0;
-
-        test_surface_ld_init0f(v, s, x / 4, y);
-        util_format_unpack_rgba(surface_fmts[i], w, v, 1);
-        *(float *)p = w[x % 4];
-}
-
-static void test_surface_ld_expecti(void *p, int s, int x, int y)
-{
-        int32_t v[4], w[4];
-        int i = 0;
-
-        test_surface_ld_init0i(v, s, x / 4, y);
-        util_format_unpack_rgba(surface_fmts[i], w, v, 1);
-        *(uint32_t *)p = w[x % 4];
-}
-
-static void test_surface_ld(struct context *ctx)
-{
-        const char *src = "COMP\n"
-                "DCL RES[0], 2D\n"
-                "DCL RES[1], 2D, RAW, WR\n"
-                "DCL SV[0], BLOCK_ID[0]\n"
-                "DCL TEMP[0], LOCAL\n"
-                "DCL TEMP[1], LOCAL\n"
-                "IMM UINT32 { 16, 1, 0, 0 }\n"
-                "\n"
-                "    BGNSUB\n"
-                "       LOAD TEMP[1], RES[0], SV[0]\n"
-                "       UMUL TEMP[0], SV[0], IMM[0]\n"
-                "       STORE RES[1].xyzw, TEMP[0], TEMP[1]\n"
-                "       RET\n"
-                "    ENDSUB\n";
-        int i = 0;
-
-        printf("- %s\n", __func__);
-
-        init_prog(ctx, 0, 0, 0, src, NULL);
-
-        for (i = 0; i < ARRAY_SIZE(surface_fmts); i++) {
-                bool is_int = util_format_is_pure_integer(surface_fmts[i]);
-
-                printf("   - %s\n", util_format_name(surface_fmts[i]));
-
-                if (!ctx->screen->is_format_supported(ctx->screen,
-                       surface_fmts[i], PIPE_TEXTURE_2D, 1, 1,
-                       PIPE_BIND_COMPUTE_RESOURCE)) {
-                   printf("(unsupported)\n");
-                   continue;
-                }
-
-                init_tex(ctx, 0, PIPE_TEXTURE_2D, true, surface_fmts[i],
-                         128, 32, (is_int ? test_surface_ld_init0i : test_surface_ld_init0f));
-                init_tex(ctx, 1, PIPE_TEXTURE_2D, true, PIPE_FORMAT_R32_FLOAT,
-                         512, 32, test_default_init);
-                init_compute_resources(ctx, (int []) { 0, 1, -1 });
-                init_sampler_states(ctx, 2);
-                launch_grid(ctx, (uint []){1, 1, 1}, (uint []){128, 32, 1}, 0,
-                            NULL);
-                check_tex(ctx, 1, (is_int ? test_surface_ld_expecti : test_surface_ld_expectf), NULL);
-                destroy_sampler_states(ctx);
-                destroy_compute_resources(ctx);
-                destroy_tex(ctx);
-        }
-
-        destroy_prog(ctx);
-}
-
-/* test_surface_st */
-static void test_surface_st_init0f(void *p, int s, int x, int y)
-{
-        float v[] = { 1.0, -.75, 0.5, -.25 };
-        *(float *)p = v[x % 4];
-}
-
-static void test_surface_st_init0i(void *p, int s, int x, int y)
-{
-        int v[] = { 0xffffffff, 0xffff, 0xff, 0xf };
-        *(int32_t *)p = v[x % 4];
-}
-
-static void test_surface_st_init1(void *p, int s, int x, int y)
-{
-        int i = 0;
-        memset(p, 1, util_format_get_blocksize(surface_fmts[i]));
-}
-
-static void test_surface_st_expectf(void *p, int s, int x, int y)
-{
-        float vf[4];
-        int i = 0, j;
-
-        for (j = 0; j < 4; j++)
-                test_surface_st_init0f(&vf[j], s, 4 * x + j, y);
-        util_format_pack_rgba(surface_fmts[i], p, vf, 1);
-}
-
-static void test_surface_st_expects(void *p, int s, int x, int y)
-{
-        int32_t v[4];
-        int i = 0, j;
-
-        for (j = 0; j < 4; j++)
-                test_surface_st_init0i(&v[j], s, 4 * x + j, y);
-        util_format_pack_rgba(surface_fmts[i], p, v, 1);
-}
-
-static void test_surface_st_expectu(void *p, int s, int x, int y)
-{
-        uint32_t v[4];
-        int i = 0, j;
-
-        for (j = 0; j < 4; j++)
-                test_surface_st_init0i(&v[j], s, 4 * x + j, y);
-        util_format_pack_rgba(surface_fmts[i], p, v, 1);
-}
-
-static unsigned absdiff(uint32_t a, uint32_t b)
-{
-        return (a > b) ? (a - b) : (b - a);
-}
-
-static bool test_surface_st_check(void *x, void *y, int sz)
-{
-        int i = 0, j;
-
-        if (util_format_is_float(surface_fmts[i])) {
-                return fabs(*(float *)x - *(float *)y) < 3.92156863e-3;
-
-        } else if ((sz % 4) == 0) {
-                for (j = 0; j < sz / 4; j++)
-                        if (absdiff(((uint32_t *)x)[j],
-                                    ((uint32_t *)y)[j]) > 1)
-                                return false;
-                return true;
-        } else {
-                return !memcmp(x, y, sz);
-        }
-}
-
-static void test_surface_st(struct context *ctx)
-{
-        const char *src = "COMP\n"
-                "DCL RES[0], 2D, RAW\n"
-                "DCL RES[1], 2D, WR\n"
-                "DCL SV[0], BLOCK_ID[0]\n"
-                "DCL TEMP[0], LOCAL\n"
-                "DCL TEMP[1], LOCAL\n"
-                "IMM UINT32 { 16, 1, 0, 0 }\n"
-                "\n"
-                "    BGNSUB\n"
-                "       UMUL TEMP[0], SV[0], IMM[0]\n"
-                "       LOAD TEMP[1], RES[0], TEMP[0]\n"
-                "       STORE RES[1], SV[0], TEMP[1]\n"
-                "       RET\n"
-                "    ENDSUB\n";
-        int i = 0;
-
-        printf("- %s\n", __func__);
-
-        init_prog(ctx, 0, 0, 0, src, NULL);
-
-        for (i = 0; i < ARRAY_SIZE(surface_fmts); i++) {
-                bool is_signed = (util_format_description(surface_fmts[i])
-                                  ->channel[0].type == UTIL_FORMAT_TYPE_SIGNED);
-                bool is_int = util_format_is_pure_integer(surface_fmts[i]);
-
-                printf("   - %s\n", util_format_name(surface_fmts[i]));
-
-                if (!ctx->screen->is_format_supported(ctx->screen,
-                       surface_fmts[i], PIPE_TEXTURE_2D, 1, 1,
-                       PIPE_BIND_COMPUTE_RESOURCE)) {
-                   printf("(unsupported)\n");
-                   continue;
-                }
-
-                init_tex(ctx, 0, PIPE_TEXTURE_2D, true, PIPE_FORMAT_R32_FLOAT,
-                         512, 32, (is_int ? test_surface_st_init0i : test_surface_st_init0f));
-                init_tex(ctx, 1, PIPE_TEXTURE_2D, true, surface_fmts[i],
-                         128, 32, test_surface_st_init1);
-                init_compute_resources(ctx, (int []) { 0, 1, -1 });
-                init_sampler_states(ctx, 2);
-                launch_grid(ctx, (uint []){1, 1, 1}, (uint []){128, 32, 1}, 0,
-                            NULL);
-                check_tex(ctx, 1, (is_int && is_signed ? test_surface_st_expects :
-                                   is_int && !is_signed ? test_surface_st_expectu :
-                                   test_surface_st_expectf), test_surface_st_check);
-                destroy_sampler_states(ctx);
-                destroy_compute_resources(ctx);
-                destroy_tex(ctx);
-        }
-
-        destroy_prog(ctx);
-}
-
-/* test_barrier */
-static void test_barrier_expect(void *p, int s, int x, int y)
-{
-        *(uint32_t *)p = 31;
-}
-
-static void test_barrier(struct context *ctx)
-{
-        const char *src = "COMP\n"
-                "DCL RES[0], BUFFER, RAW, WR\n"
-                "DCL SV[0], BLOCK_ID[0]\n"
-                "DCL SV[1], BLOCK_SIZE[0]\n"
-                "DCL SV[2], THREAD_ID[0]\n"
-                "DCL TEMP[0], LOCAL\n"
-                "DCL TEMP[1], LOCAL\n"
-                "DCL TEMP[2], LOCAL\n"
-                "DCL TEMP[3], LOCAL\n"
-                "IMM UINT32 { 1, 0, 0, 0 }\n"
-                "IMM UINT32 { 4, 0, 0, 0 }\n"
-                "IMM UINT32 { 32, 0, 0, 0 }\n"
-                "\n"
-                "    BGNSUB\n"
-                "       UMUL TEMP[0].x, SV[2], IMM[1]\n"
-                "       MOV TEMP[1].x, IMM[0].wwww\n"
-                "       BGNLOOP\n"
-                "               BARRIER\n"
-                "               STORE RLOCAL.x, TEMP[0], TEMP[1]\n"
-                "               BARRIER\n"
-                "               MOV TEMP[2].x, IMM[0].wwww\n"
-                "               BGNLOOP\n"
-                "                       UMUL TEMP[3].x, TEMP[2], IMM[1]\n"
-                "                       LOAD TEMP[3].x, RLOCAL, TEMP[3]\n"
-                "                       USNE TEMP[3].x, TEMP[3], TEMP[1]\n"
-                "                       IF TEMP[3]\n"
-                "                               END\n"
-                "                       ENDIF\n"
-                "                       UADD TEMP[2].x, TEMP[2], IMM[0]\n"
-                "                       USEQ TEMP[3].x, TEMP[2], SV[1]\n"
-                "                       IF TEMP[3]\n"
-                "                               BRK\n"
-                "                       ENDIF\n"
-                "               ENDLOOP\n"
-                "               UADD TEMP[1].x, TEMP[1], IMM[0]\n"
-                "               USEQ TEMP[2].x, TEMP[1], IMM[2]\n"
-                "               IF TEMP[2]\n"
-                "                       BRK\n"
-                "               ENDIF\n"
-                "       ENDLOOP\n"
-                "       UMUL TEMP[1].x, SV[0], SV[1]\n"
-                "       UMUL TEMP[1].x, TEMP[1], IMM[1]\n"
-                "       UADD TEMP[1].x, TEMP[1], TEMP[0]\n"
-                "       LOAD TEMP[0].x, RLOCAL, TEMP[0]\n"
-                "       STORE RES[0].x, TEMP[1], TEMP[0]\n"
-                "       RET\n"
-                "    ENDSUB\n";
-
-        printf("- %s\n", __func__);
-
-        init_prog(ctx, 256, 0, 0, src, NULL);
-        init_tex(ctx, 0, PIPE_BUFFER, true, PIPE_FORMAT_R32_FLOAT,
-                 4096, 0, test_default_init);
-        init_compute_resources(ctx, (int []) { 0, -1 });
-        launch_grid(ctx, (uint []){64, 1, 1}, (uint []){16, 1, 1}, 0, NULL);
-        check_tex(ctx, 0, test_barrier_expect, NULL);
-        destroy_compute_resources(ctx);
-        destroy_tex(ctx);
-        destroy_prog(ctx);
-}
-
-/* test_atom_ops */
-static void test_atom_ops_init(void *p, int s, int x, int y)
-{
-        *(uint32_t *)p = 0xbad;
-}
-
-static void test_atom_ops_expect(void *p, int s, int x, int y)
-{
-        switch (x) {
-        case 0:
-                *(uint32_t *)p = 0xce6c8eef;
-                break;
-        case 1:
-                *(uint32_t *)p = 0xdeadbeef;
-                break;
-        case 2:
-                *(uint32_t *)p = 0x11111111;
-                break;
-        case 3:
-                *(uint32_t *)p = 0x10011001;
-                break;
-        case 4:
-                *(uint32_t *)p = 0xdfbdbfff;
-                break;
-        case 5:
-                *(uint32_t *)p = 0x11111111;
-                break;
-        case 6:
-                *(uint32_t *)p = 0x11111111;
-                break;
-        case 7:
-                *(uint32_t *)p = 0xdeadbeef;
-                break;
-        case 8:
-                *(uint32_t *)p = 0xdeadbeef;
-                break;
-        case 9:
-                *(uint32_t *)p = 0x11111111;
-                break;
-        }
-}
-
-static void test_atom_ops(struct context *ctx, bool global)
-{
-        const char *src = "COMP\n"
-                "#ifdef TARGET_GLOBAL\n"
-                "#define target RES[0]\n"
-                "#else\n"
-                "#define target RLOCAL\n"
-                "#endif\n"
-                ""
-                "DCL RES[0], BUFFER, RAW, WR\n"
-                "#define threadid SV[0]\n"
-                "DCL threadid, THREAD_ID[0]\n"
-                ""
-                "#define offset TEMP[0]\n"
-                "DCL offset, LOCAL\n"
-                "#define tmp TEMP[1]\n"
-                "DCL tmp, LOCAL\n"
-                ""
-                "#define k0 IMM[0]\n"
-                "IMM UINT32 { 0, 0, 0, 0 }\n"
-                "#define k1 IMM[1]\n"
-                "IMM UINT32 { 1, 0, 0, 0 }\n"
-                "#define k2 IMM[2]\n"
-                "IMM UINT32 { 2, 0, 0, 0 }\n"
-                "#define k3 IMM[3]\n"
-                "IMM UINT32 { 3, 0, 0, 0 }\n"
-                "#define k4 IMM[4]\n"
-                "IMM UINT32 { 4, 0, 0, 0 }\n"
-                "#define k5 IMM[5]\n"
-                "IMM UINT32 { 5, 0, 0, 0 }\n"
-                "#define k6 IMM[6]\n"
-                "IMM UINT32 { 6, 0, 0, 0 }\n"
-                "#define k7 IMM[7]\n"
-                "IMM UINT32 { 7, 0, 0, 0 }\n"
-                "#define k8 IMM[8]\n"
-                "IMM UINT32 { 8, 0, 0, 0 }\n"
-                "#define k9 IMM[9]\n"
-                "IMM UINT32 { 9, 0, 0, 0 }\n"
-                "#define korig IMM[10].xxxx\n"
-                "#define karg IMM[10].yyyy\n"
-                "IMM UINT32 { 3735928559, 286331153, 0, 0 }\n"
-                "\n"
-                "    BGNSUB\n"
-                "       UMUL offset.x, threadid, k4\n"
-                "       STORE target.x, offset, korig\n"
-                "       USEQ tmp.x, threadid, k0\n"
-                "       IF tmp\n"
-                "               ATOMUADD tmp.x, target, offset, karg\n"
-                "               ATOMUADD tmp.x, target, offset, tmp\n"
-                "       ENDIF\n"
-                "       USEQ tmp.x, threadid, k1\n"
-                "       IF tmp\n"
-                "               ATOMXCHG tmp.x, target, offset, karg\n"
-                "               ATOMXCHG tmp.x, target, offset, tmp\n"
-                "       ENDIF\n"
-                "       USEQ tmp.x, threadid, k2\n"
-                "       IF tmp\n"
-                "               ATOMCAS tmp.x, target, offset, korig, karg\n"
-                "               ATOMCAS tmp.x, target, offset, tmp, k0\n"
-                "       ENDIF\n"
-                "       USEQ tmp.x, threadid, k3\n"
-                "       IF tmp\n"
-                "               ATOMAND tmp.x, target, offset, karg\n"
-                "               ATOMAND tmp.x, target, offset, tmp\n"
-                "       ENDIF\n"
-                "       USEQ tmp.x, threadid, k4\n"
-                "       IF tmp\n"
-                "               ATOMOR tmp.x, target, offset, karg\n"
-                "               ATOMOR tmp.x, target, offset, tmp\n"
-                "       ENDIF\n"
-                "       USEQ tmp.x, threadid, k5\n"
-                "       IF tmp\n"
-                "               ATOMXOR tmp.x, target, offset, karg\n"
-                "               ATOMXOR tmp.x, target, offset, tmp\n"
-                "       ENDIF\n"
-                "       USEQ tmp.x, threadid, k6\n"
-                "       IF tmp\n"
-                "               ATOMUMIN tmp.x, target, offset, karg\n"
-                "               ATOMUMIN tmp.x, target, offset, tmp\n"
-                "       ENDIF\n"
-                "       USEQ tmp.x, threadid, k7\n"
-                "       IF tmp\n"
-                "               ATOMUMAX tmp.x, target, offset, karg\n"
-                "               ATOMUMAX tmp.x, target, offset, tmp\n"
-                "       ENDIF\n"
-                "       USEQ tmp.x, threadid, k8\n"
-                "       IF tmp\n"
-                "               ATOMIMIN tmp.x, target, offset, karg\n"
-                "               ATOMIMIN tmp.x, target, offset, tmp\n"
-                "       ENDIF\n"
-                "       USEQ tmp.x, threadid, k9\n"
-                "       IF tmp\n"
-                "               ATOMIMAX tmp.x, target, offset, karg\n"
-                "               ATOMIMAX tmp.x, target, offset, tmp\n"
-                "       ENDIF\n"
-                "#ifdef TARGET_LOCAL\n"
-                "       LOAD tmp.x, RLOCAL, offset\n"
-                "       STORE RES[0].x, offset, tmp\n"
-                "#endif\n"
-                "       RET\n"
-                "    ENDSUB\n";
-
-        printf("- %s (%s)\n", __func__, global ? "global" : "local");
-
-        init_prog(ctx, 40, 0, 0, src,
-                  (global ? "-DTARGET_GLOBAL" : "-DTARGET_LOCAL"));
-        init_tex(ctx, 0, PIPE_BUFFER, true, PIPE_FORMAT_R32_FLOAT,
-                 40, 0, test_atom_ops_init);
-        init_compute_resources(ctx, (int []) { 0, -1 });
-        launch_grid(ctx, (uint []){10, 1, 1}, (uint []){1, 1, 1}, 0, NULL);
-        check_tex(ctx, 0, test_atom_ops_expect, NULL);
-        destroy_compute_resources(ctx);
-        destroy_tex(ctx);
-        destroy_prog(ctx);
-}
-
-/* test_atom_race */
-static void test_atom_race_expect(void *p, int s, int x, int y)
-{
-        *(uint32_t *)p = x & 0x20 ? 0x11111111 : 0xffffffff;
-}
-
-static void test_atom_race(struct context *ctx, bool global)
-{
-        const char *src = "COMP\n"
-                "#ifdef TARGET_GLOBAL\n"
-                "#define target RES[0]\n"
-                "#else\n"
-                "#define target RLOCAL\n"
-                "#endif\n"
-                ""
-                "DCL RES[0], BUFFER, RAW, WR\n"
-                ""
-                "#define blockid SV[0]\n"
-                "DCL blockid, BLOCK_ID[0]\n"
-                "#define blocksz SV[1]\n"
-                "DCL blocksz, BLOCK_SIZE[0]\n"
-                "#define threadid SV[2]\n"
-                "DCL threadid, THREAD_ID[0]\n"
-                ""
-                "#define offset TEMP[0]\n"
-                "DCL offset, LOCAL\n"
-                "#define arg TEMP[1]\n"
-                "DCL arg, LOCAL\n"
-                "#define count TEMP[2]\n"
-                "DCL count, LOCAL\n"
-                "#define vlocal TEMP[3]\n"
-                "DCL vlocal, LOCAL\n"
-                "#define vshared TEMP[4]\n"
-                "DCL vshared, LOCAL\n"
-                "#define last TEMP[5]\n"
-                "DCL last, LOCAL\n"
-                "#define tmp0 TEMP[6]\n"
-                "DCL tmp0, LOCAL\n"
-                "#define tmp1 TEMP[7]\n"
-                "DCL tmp1, LOCAL\n"
-                ""
-                "#define k0 IMM[0]\n"
-                "IMM UINT32 { 0, 0, 0, 0 }\n"
-                "#define k1 IMM[1]\n"
-                "IMM UINT32 { 1, 0, 0, 0 }\n"
-                "#define k4 IMM[2]\n"
-                "IMM UINT32 { 4, 0, 0, 0 }\n"
-                "#define k32 IMM[3]\n"
-                "IMM UINT32 { 32, 0, 0, 0 }\n"
-                "#define k128 IMM[4]\n"
-                "IMM UINT32 { 128, 0, 0, 0 }\n"
-                "#define kdeadcafe IMM[5]\n"
-                "IMM UINT32 { 3735931646, 0, 0, 0 }\n"
-                "#define kallowed_set IMM[6]\n"
-                "IMM UINT32 { 559035650, 0, 0, 0 }\n"
-                "#define k11111111 IMM[7]\n"
-                "IMM UINT32 { 286331153, 0, 0, 0 }\n"
-                "\n"
-                "    BGNSUB\n"
-                "       MOV offset.x, threadid\n"
-                "#ifdef TARGET_GLOBAL\n"
-                "       UMUL tmp0.x, blockid, blocksz\n"
-                "       UADD offset.x, offset, tmp0\n"
-                "#endif\n"
-                "       UMUL offset.x, offset, k4\n"
-                "       USLT tmp0.x, threadid, k32\n"
-                "       STORE target.x, offset, k0\n"
-                "       BARRIER\n"
-                "       IF tmp0\n"
-                "               MOV vlocal.x, k0\n"
-                "               MOV arg.x, kdeadcafe\n"
-                "               BGNLOOP\n"
-                "                       INEG arg.x, arg\n"
-                "                       ATOMUADD vshared.x, target, offset, arg\n"
-                "                       SFENCE target\n"
-                "                       USNE tmp0.x, vshared, vlocal\n"
-                "                       IF tmp0\n"
-                "                               BRK\n"
-                "                       ENDIF\n"
-                "                       UADD vlocal.x, vlocal, arg\n"
-                "               ENDLOOP\n"
-                "               UADD vlocal.x, vshared, arg\n"
-                "               LOAD vshared.x, target, offset\n"
-                "               USEQ tmp0.x, vshared, vlocal\n"
-                "               STORE target.x, offset, tmp0\n"
-                "       ELSE\n"
-                "               UADD offset.x, offset, -k128\n"
-                "               MOV count.x, k0\n"
-                "               MOV last.x, k0\n"
-                "               BGNLOOP\n"
-                "                       LOAD vshared.x, target, offset\n"
-                "                       USEQ tmp0.x, vshared, kallowed_set.xxxx\n"
-                "                       USEQ tmp1.x, vshared, kallowed_set.yyyy\n"
-                "                       OR tmp0.x, tmp0, tmp1\n"
-                "                       IF tmp0\n"
-                "                               USEQ tmp0.x, vshared, last\n"
-                "                               IF tmp0\n"
-                "                                       CONT\n"
-                "                               ENDIF\n"
-                "                               MOV last.x, vshared\n"
-                "                       ELSE\n"
-                "                               END\n"
-                "                       ENDIF\n"
-                "                       UADD count.x, count, k1\n"
-                "                       USEQ tmp0.x, count, k128\n"
-                "                       IF tmp0\n"
-                "                               BRK\n"
-                "                       ENDIF\n"
-                "               ENDLOOP\n"
-                "               ATOMXCHG tmp0.x, target, offset, k11111111\n"
-                "               UADD offset.x, offset, k128\n"
-                "               ATOMXCHG tmp0.x, target, offset, k11111111\n"
-                "               SFENCE target\n"
-                "       ENDIF\n"
-                "#ifdef TARGET_LOCAL\n"
-                "       LOAD tmp0.x, RLOCAL, offset\n"
-                "       UMUL tmp1.x, blockid, blocksz\n"
-                "       UMUL tmp1.x, tmp1, k4\n"
-                "       UADD offset.x, offset, tmp1\n"
-                "       STORE RES[0].x, offset, tmp0\n"
-                "#endif\n"
-                "       RET\n"
-                "    ENDSUB\n";
-
-        printf("- %s (%s)\n", __func__, global ? "global" : "local");
-
-        init_prog(ctx, 256, 0, 0, src,
-                  (global ? "-DTARGET_GLOBAL" : "-DTARGET_LOCAL"));
-        init_tex(ctx, 0, PIPE_BUFFER, true, PIPE_FORMAT_R32_FLOAT,
-                 4096, 0, test_default_init);
-        init_compute_resources(ctx, (int []) { 0, -1 });
-        launch_grid(ctx, (uint []){64, 1, 1}, (uint []){16, 1, 1}, 0, NULL);
-        check_tex(ctx, 0, test_atom_race_expect, NULL);
-        destroy_compute_resources(ctx);
-        destroy_tex(ctx);
-        destroy_prog(ctx);
-}
-
-int main(int argc, char *argv[])
-{
-        struct context *ctx = CALLOC_STRUCT(context);
-
-        unsigned tests = (argc > 1) ? strtoul(argv[1], NULL, 0) : ~0;
-
-        init_ctx(ctx);
-
-        if (tests & (1 << 0))
-           test_system_values(ctx);
-        if (tests & (1 << 1))
-           test_resource_access(ctx);
-        if (tests & (1 << 2))
-           test_function_calls(ctx);
-        if (tests & (1 << 3))
-           test_input_global(ctx);
-        if (tests & (1 << 4))
-           test_private(ctx);
-        if (tests & (1 << 5))
-           test_local(ctx);
-        if (tests & (1 << 6))
-           test_sample(ctx);
-        if (tests & (1 << 7))
-           test_many_kern(ctx);
-        if (tests & (1 << 8))
-           test_constant(ctx);
-        if (tests & (1 << 9))
-           test_resource_indirect(ctx);
-        if (tests & (1 << 10))
-           test_surface_ld(ctx);
-        if (tests & (1 << 11))
-           test_surface_st(ctx);
-        if (tests & (1 << 12))
-           test_barrier(ctx);
-        if (tests & (1 << 13))
-           test_atom_ops(ctx, true);
-        if (tests & (1 << 14))
-           test_atom_race(ctx, true);
-        if (tests & (1 << 15))
-           test_atom_ops(ctx, false);
-        if (tests & (1 << 16))
-           test_atom_race(ctx, false);
-
-        destroy_ctx(ctx);
-
-        return 0;
-}
diff --git a/src/gallium/tests/trivial/meson.build b/src/gallium/tests/trivial/meson.build
index a54e71d7225..a2286afe096 100644
--- a/src/gallium/tests/trivial/meson.build
+++ b/src/gallium/tests/trivial/meson.build
@@ -18,7 +18,7 @@
 # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 # SOFTWARE.
 
-foreach t : ['compute', 'tri', 'quad-tex']
+foreach t : ['tri', 'quad-tex']
   executable(
     t,
     '@0@.c'.format(t),
diff --git a/src/imagination/rogue/rogue_nir.c b/src/imagination/rogue/rogue_nir.c
index 3fe90b47abd..00078678dd6 100644
--- a/src/imagination/rogue/rogue_nir.c
+++ b/src/imagination/rogue/rogue_nir.c
@@ -131,7 +131,7 @@ bool rogue_nir_passes(struct rogue_build_ctx *ctx,
    /* Additional I/O lowering. */
    NIR_PASS_V(nir,
               nir_lower_explicit_io,
-              nir_var_mem_ubo,
+              nir_var_mem_ubo, false,
               spirv_options.ubo_addr_format);
    NIR_PASS_V(nir, rogue_nir_lower_io, NULL);
 
diff --git a/src/intel/compiler/brw_kernel.c b/src/intel/compiler/brw_kernel.c
index fd5f4e62180..53a1e64e6c5 100644
--- a/src/intel/compiler/brw_kernel.c
+++ b/src/intel/compiler/brw_kernel.c
@@ -427,15 +427,15 @@ brw_kernel_from_spirv(struct brw_compiler *compiler,
 
    NIR_PASS_V(nir, nir_lower_memcpy);
 
-   NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_mem_constant,
+   NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_mem_constant, false,
               nir_address_format_64bit_global);
 
-   NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_uniform,
+   NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_uniform, false,
               nir_address_format_32bit_offset_as_64bit);
 
    NIR_PASS_V(nir, nir_lower_explicit_io,
               nir_var_shader_temp | nir_var_function_temp |
-              nir_var_mem_shared | nir_var_mem_global,
+              nir_var_mem_shared | nir_var_mem_global, false,
               nir_address_format_62bit_generic);
 
    NIR_PASS_V(nir, nir_lower_frexp);
diff --git a/src/intel/compiler/brw_mesh.cpp b/src/intel/compiler/brw_mesh.cpp
index dfae5ce6370..3dd549eb4f6 100644
--- a/src/intel/compiler/brw_mesh.cpp
+++ b/src/intel/compiler/brw_mesh.cpp
@@ -163,7 +163,7 @@ brw_nir_lower_tue_outputs(nir_shader *nir, brw_tue_map *map)
    NIR_PASS(_, nir, nir_lower_vars_to_explicit_types,
             nir_var_mem_task_payload, shared_type_info);
    NIR_PASS(_, nir, nir_lower_explicit_io,
-            nir_var_mem_task_payload, nir_address_format_32bit_offset);
+            nir_var_mem_task_payload, false, nir_address_format_32bit_offset);
 
    map->size_dw = ALIGN(DIV_ROUND_UP(nir->info.task_payload_size, 4), 8);
 }
@@ -365,7 +365,7 @@ brw_nir_lower_tue_inputs(nir_shader *nir, const brw_tue_map *map)
       nir->info.task_payload_size = 0;
    }
 
-   NIR_PASS(_, nir, nir_lower_explicit_io, nir_var_mem_task_payload,
+   NIR_PASS(_, nir, nir_lower_explicit_io, nir_var_mem_task_payload, false,
             nir_address_format_32bit_offset);
 }
 
diff --git a/src/intel/compiler/brw_nir.c b/src/intel/compiler/brw_nir.c
index cb88c50ffa6..472293991a8 100644
--- a/src/intel/compiler/brw_nir.c
+++ b/src/intel/compiler/brw_nir.c
@@ -1267,7 +1267,7 @@ brw_postprocess_nir(nir_shader *nir, const struct brw_compiler *compiler,
    if (is_scalar && nir_shader_has_local_variables(nir)) {
       OPT(nir_lower_vars_to_explicit_types, nir_var_function_temp,
           glsl_get_natural_size_align_bytes);
-      OPT(nir_lower_explicit_io, nir_var_function_temp,
+      OPT(nir_lower_explicit_io, nir_var_function_temp, false,
           nir_address_format_32bit_offset);
       brw_nir_optimize(nir, compiler, is_scalar, false);
    }
diff --git a/src/intel/compiler/brw_nir_rt.c b/src/intel/compiler/brw_nir_rt.c
index b124928b293..b18248391ab 100644
--- a/src/intel/compiler/brw_nir_rt.c
+++ b/src/intel/compiler/brw_nir_rt.c
@@ -218,7 +218,7 @@ lower_rt_io_and_scratch(nir_shader *nir)
    NIR_PASS_V(nir, nir_lower_explicit_io,
               nir_var_function_temp |
               nir_var_mem_constant |
-              nir_var_ray_hit_attrib,
+              nir_var_ray_hit_attrib, false,
               nir_address_format_64bit_global);
 }
 
diff --git a/src/intel/vulkan/anv_pipeline.c b/src/intel/vulkan/anv_pipeline.c
index 82c1a10a9fa..d04a314169b 100644
--- a/src/intel/vulkan/anv_pipeline.c
+++ b/src/intel/vulkan/anv_pipeline.c
@@ -919,9 +919,9 @@ anv_pipeline_lower_nir(struct anv_pipeline *pipeline,
 
    NIR_PASS(_, nir, brw_nir_lower_storage_image, compiler->devinfo);
 
-   NIR_PASS(_, nir, nir_lower_explicit_io, nir_var_mem_global,
+   NIR_PASS(_, nir, nir_lower_explicit_io, nir_var_mem_global, false,
             nir_address_format_64bit_global);
-   NIR_PASS(_, nir, nir_lower_explicit_io, nir_var_mem_push_const,
+   NIR_PASS(_, nir, nir_lower_explicit_io, nir_var_mem_push_const, false,
             nir_address_format_32bit_offset);
 
    NIR_PASS(_, nir, brw_nir_lower_ray_queries, &pdevice->info);
@@ -934,10 +934,10 @@ anv_pipeline_lower_nir(struct anv_pipeline *pipeline,
               pdevice, pipeline->device->robust_buffer_access,
               layout, &stage->bind_map);
 
-   NIR_PASS(_, nir, nir_lower_explicit_io, nir_var_mem_ubo,
+   NIR_PASS(_, nir, nir_lower_explicit_io, nir_var_mem_ubo, false,
             anv_nir_ubo_addr_format(pdevice,
                pipeline->device->robust_buffer_access));
-   NIR_PASS(_, nir, nir_lower_explicit_io, nir_var_mem_ssbo,
+   NIR_PASS(_, nir, nir_lower_explicit_io, nir_var_mem_ssbo, false,
             anv_nir_ssbo_addr_format(pdevice,
                pipeline->device->robust_buffer_access));
 
@@ -982,7 +982,7 @@ anv_pipeline_lower_nir(struct anv_pipeline *pipeline,
       }
 
       NIR_PASS(_, nir, nir_lower_explicit_io,
-               nir_var_mem_shared, nir_address_format_32bit_offset);
+               nir_var_mem_shared, false, nir_address_format_32bit_offset);
 
       if (nir->info.zero_initialize_shared_memory &&
           nir->info.shared_size > 0) {
diff --git a/src/intel/vulkan_hasvk/anv_pipeline.c b/src/intel/vulkan_hasvk/anv_pipeline.c
index 3df2ab64a11..a0944a6f7c5 100644
--- a/src/intel/vulkan_hasvk/anv_pipeline.c
+++ b/src/intel/vulkan_hasvk/anv_pipeline.c
@@ -643,9 +643,9 @@ anv_pipeline_lower_nir(struct anv_pipeline *pipeline,
 
    NIR_PASS(_, nir, brw_nir_lower_storage_image, compiler->devinfo);
 
-   NIR_PASS(_, nir, nir_lower_explicit_io, nir_var_mem_global,
+   NIR_PASS(_, nir, nir_lower_explicit_io, nir_var_mem_global, false,
             nir_address_format_64bit_global);
-   NIR_PASS(_, nir, nir_lower_explicit_io, nir_var_mem_push_const,
+   NIR_PASS(_, nir, nir_lower_explicit_io, nir_var_mem_push_const, false,
             nir_address_format_32bit_offset);
 
    NIR_PASS(_, nir, brw_nir_lower_ray_queries, &pdevice->info);
@@ -655,10 +655,10 @@ anv_pipeline_lower_nir(struct anv_pipeline *pipeline,
               pdevice, pipeline->device->robust_buffer_access,
               layout, &stage->bind_map);
 
-   NIR_PASS(_, nir, nir_lower_explicit_io, nir_var_mem_ubo,
+   NIR_PASS(_, nir, nir_lower_explicit_io, nir_var_mem_ubo, false,
             anv_nir_ubo_addr_format(pdevice,
                pipeline->device->robust_buffer_access));
-   NIR_PASS(_, nir, nir_lower_explicit_io, nir_var_mem_ssbo,
+   NIR_PASS(_, nir, nir_lower_explicit_io, nir_var_mem_ssbo, false,
             anv_nir_ssbo_addr_format(pdevice,
                pipeline->device->robust_buffer_access));
 
@@ -703,7 +703,7 @@ anv_pipeline_lower_nir(struct anv_pipeline *pipeline,
       }
 
       NIR_PASS(_, nir, nir_lower_explicit_io,
-               nir_var_mem_shared, nir_address_format_32bit_offset);
+               nir_var_mem_shared, false, nir_address_format_32bit_offset);
 
       if (nir->info.zero_initialize_shared_memory &&
           nir->info.shared_size > 0) {
diff --git a/src/mesa/state_tracker/st_glsl_to_nir.cpp b/src/mesa/state_tracker/st_glsl_to_nir.cpp
index 868f4371d01..49284a408e8 100644
--- a/src/mesa/state_tracker/st_glsl_to_nir.cpp
+++ b/src/mesa/state_tracker/st_glsl_to_nir.cpp
@@ -419,7 +419,7 @@ st_nir_preprocess(struct st_context *st, struct gl_program *prog,
       NIR_PASS_V(prog->nir, nir_lower_vars_to_explicit_types,
                  nir_var_mem_shared, shared_type_info);
       NIR_PASS_V(prog->nir, nir_lower_explicit_io,
-                 nir_var_mem_shared, nir_address_format_32bit_offset);
+                 nir_var_mem_shared, false, nir_address_format_32bit_offset);
    }
 
    /* Do a round of constant folding to clean up address calculations */
diff --git a/src/mesa/state_tracker/st_pbo_compute.c b/src/mesa/state_tracker/st_pbo_compute.c
index 45a06d9c192..fc8bc3785fc 100644
--- a/src/mesa/state_tracker/st_pbo_compute.c
+++ b/src/mesa/state_tracker/st_pbo_compute.c
@@ -942,7 +942,7 @@ download_texture_compute(struct st_context *st,
             assert(async->nir && !async->cs);
             struct pipe_compute_state state = {0};
             state.ir_type = PIPE_SHADER_IR_NIR;
-            state.req_local_mem = async->nir->info.shared_size;
+            state.static_shared_mem = async->nir->info.shared_size;
             state.prog = async->nir;
             async->nir = NULL;
             async->cs = pipe->create_compute_state(pipe, &state);
@@ -957,7 +957,7 @@ download_texture_compute(struct st_context *st,
                if (!spec->cs) {
                   struct pipe_compute_state state = {0};
                   state.ir_type = PIPE_SHADER_IR_NIR;
-                  state.req_local_mem = spec->nir->info.shared_size;
+                  state.static_shared_mem = spec->nir->info.shared_size;
                   state.prog = spec->nir;
                   spec->nir = NULL;
                   spec->cs = pipe->create_compute_state(pipe, &state);
diff --git a/src/mesa/state_tracker/st_program.c b/src/mesa/state_tracker/st_program.c
index 376a5f6621e..ff784a44803 100644
--- a/src/mesa/state_tracker/st_program.c
+++ b/src/mesa/state_tracker/st_program.c
@@ -549,7 +549,7 @@ st_create_nir_shader(struct st_context *st, struct pipe_shader_state *state)
    case MESA_SHADER_COMPUTE: {
       struct pipe_compute_state cs = {0};
       cs.ir_type = state->type;
-      cs.req_local_mem = info.shared_size;
+      cs.static_shared_mem = info.shared_size;
 
       if (state->type == PIPE_SHADER_IR_NIR)
          cs.prog = state->ir.nir;
diff --git a/src/microsoft/clc/clc_compiler.c b/src/microsoft/clc/clc_compiler.c
index 92a97a42e7f..b97019cedf3 100644
--- a/src/microsoft/clc/clc_compiler.c
+++ b/src/microsoft/clc/clc_compiler.c
@@ -1020,10 +1020,10 @@ clc_spirv_to_dxil(struct clc_libclc *lib,
    NIR_PASS_V(nir, split_unaligned_loads_stores);
 
    assert(nir->info.cs.ptr_size == 64);
-   NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_mem_ssbo,
+   NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_mem_ssbo, false,
               nir_address_format_32bit_index_offset_pack64);
    NIR_PASS_V(nir, nir_lower_explicit_io,
-              nir_var_mem_shared | nir_var_function_temp | nir_var_uniform,
+              nir_var_mem_shared | nir_var_function_temp | nir_var_uniform, false,
               nir_address_format_32bit_offset_as_64bit);
 
    NIR_PASS_V(nir, nir_lower_system_values);
@@ -1078,7 +1078,7 @@ clc_spirv_to_dxil(struct clc_libclc *lib,
 
    NIR_PASS_V(nir, clc_nir_lower_kernel_input_loads, inputs_var);
    NIR_PASS_V(nir, split_unaligned_loads_stores);
-   NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_mem_ubo,
+   NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_mem_ubo, false,
               nir_address_format_32bit_index_offset);
    NIR_PASS_V(nir, clc_nir_lower_system_values, work_properties_var);
    NIR_PASS_V(nir, dxil_nir_lower_loads_stores_to_dxil);
diff --git a/src/microsoft/spirv_to_dxil/dxil_spirv_nir.c b/src/microsoft/spirv_to_dxil/dxil_spirv_nir.c
index 1681318ed90..1fec301eb63 100644
--- a/src/microsoft/spirv_to_dxil/dxil_spirv_nir.c
+++ b/src/microsoft/spirv_to_dxil/dxil_spirv_nir.c
@@ -653,7 +653,7 @@ dxil_spirv_nir_passes(nir_shader *nir,
               NULL);
 
    uint32_t push_constant_size = 0;
-   NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_mem_push_const,
+   NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_mem_push_const, false,
               nir_address_format_32bit_offset);
    NIR_PASS_V(nir, dxil_spirv_nir_lower_load_push_constant,
               nir_address_format_32bit_index_offset,
@@ -661,14 +661,14 @@ dxil_spirv_nir_passes(nir_shader *nir,
               conf->push_constant_cbv.base_shader_register,
               &push_constant_size);
 
-   NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_mem_ubo | nir_var_mem_ssbo,
+   NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_mem_ubo | nir_var_mem_ssbo, false,
               nir_address_format_32bit_index_offset);
 
    if (!nir->info.shared_memory_explicit_layout) {
       NIR_PASS_V(nir, nir_lower_vars_to_explicit_types, nir_var_mem_shared,
                  shared_var_info);
    }
-   NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_mem_shared,
+   NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_mem_shared, false,
       nir_address_format_32bit_offset_as_64bit);
 
    NIR_PASS_V(nir, nir_lower_clip_cull_distance_arrays);
diff --git a/src/nouveau/codegen/nv50_ir_from_nir.cpp b/src/nouveau/codegen/nv50_ir_from_nir.cpp
index cbefa93d25f..ce7e1679bdd 100644
--- a/src/nouveau/codegen/nv50_ir_from_nir.cpp
+++ b/src/nouveau/codegen/nv50_ir_from_nir.cpp
@@ -3335,7 +3335,7 @@ Converter::run()
 
    /* codegen assumes vec4 alignment for memory */
    NIR_PASS_V(nir, nir_lower_vars_to_explicit_types, nir_var_function_temp, function_temp_type_info);
-   NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_function_temp, nir_address_format_32bit_offset);
+   NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_function_temp, false, nir_address_format_32bit_offset);
    NIR_PASS_V(nir, nir_remove_dead_variables, nir_var_function_temp, NULL);
 
    NIR_PASS_V(nir, nir_lower_io, nir_var_shader_in | nir_var_shader_out,
diff --git a/src/panfrost/util/pan_ir.h b/src/panfrost/util/pan_ir.h
index 98b4decd117..d32ebbcc0c0 100644
--- a/src/panfrost/util/pan_ir.h
+++ b/src/panfrost/util/pan_ir.h
@@ -335,7 +335,10 @@ struct pan_shader_info {
 
                 struct {
                         /* Is it legal to merge workgroups? This is true if the
-                         * shader uses neither barriers nor shared memory.
+                         * shader uses neither barriers nor shared memory. This
+                         * requires caution: if the API allows specifying shared
+                         * memory at launch time (instead of compile time), that
+                         * memory will not be accounted for by the compiler.
                          *
                          * Used by the Valhall hardware.
                          */
diff --git a/src/panfrost/vulkan/panvk_vX_shader.c b/src/panfrost/vulkan/panvk_vX_shader.c
index fde8445ca98..049d1e7e9c9 100644
--- a/src/panfrost/vulkan/panvk_vX_shader.c
+++ b/src/panfrost/vulkan/panvk_vX_shader.c
@@ -316,12 +316,12 @@ panvk_per_arch(shader_create)(struct panvk_device *dev,
    NIR_PASS_V(nir, panvk_per_arch(nir_lower_descriptors),
               dev, layout, &shader->has_img_access);
 
-   NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_mem_ubo,
+   NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_mem_ubo, false,
               nir_address_format_32bit_index_offset);
-   NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_mem_ssbo,
+   NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_mem_ssbo, false,
               spirv_options.ssbo_addr_format);
    NIR_PASS_V(nir, nir_lower_explicit_io,
-              nir_var_mem_push_const,
+              nir_var_mem_push_const, false,
               nir_address_format_32bit_offset);
 
    if (gl_shader_stage_uses_workgroup(stage)) {
@@ -332,7 +332,7 @@ panvk_per_arch(shader_create)(struct panvk_device *dev,
       }
 
       NIR_PASS_V(nir, nir_lower_explicit_io,
-                 nir_var_mem_shared,
+                 nir_var_mem_shared, false,
                  nir_address_format_32bit_offset);
    }
 
