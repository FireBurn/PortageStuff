From 083fe6880e6b5ba5db119830295c6e37fddf4852 Mon Sep 17 00:00:00 2001
From: Pierre-Eric Pelloux-Prayer <pierre-eric.pelloux-prayer@amd.com>
Date: Thu, 25 Nov 2021 10:12:56 +0100
Subject: [PATCH 1/4] radv: partial sdma support

SDMA code adapted from https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/12763

The only supported use case is image (linear or tiled) -> buffer and only GFX9+ is
supported (for now).

TODO: dcc decompression
---
 src/amd/vulkan/meson.build            |   1 +
 src/amd/vulkan/radv_debug.h           |   1 +
 src/amd/vulkan/radv_device.c          |   5 +
 src/amd/vulkan/radv_meta_copy.c       |  15 ++
 src/amd/vulkan/radv_private.h         |   3 +
 src/amd/vulkan/radv_sdma_copy_image.c | 190 ++++++++++++++++++++++++++
 6 files changed, 215 insertions(+)
 create mode 100644 src/amd/vulkan/radv_sdma_copy_image.c

diff --git a/src/amd/vulkan/meson.build b/src/amd/vulkan/meson.build
index c5e4bc2e1cd..ed8345cefa1 100644
--- a/src/amd/vulkan/meson.build
+++ b/src/amd/vulkan/meson.build
@@ -75,6 +75,7 @@ libradv_files = files(
   'radv_pipeline_rt.c',
   'radv_private.h',
   'radv_radeon_winsys.h',
+  'radv_sdma_copy_image.c',
   'radv_shader.c',
   'radv_shader.h',
   'radv_shader_args.c',
diff --git a/src/amd/vulkan/radv_debug.h b/src/amd/vulkan/radv_debug.h
index 5c0dd14220e..22abbc3829f 100644
--- a/src/amd/vulkan/radv_debug.h
+++ b/src/amd/vulkan/radv_debug.h
@@ -64,6 +64,7 @@ enum {
    RADV_DEBUG_NO_ATOC_DITHERING = 1ull << 33,
    RADV_DEBUG_NO_NGGC = 1ull << 34,
    RADV_DEBUG_DUMP_PROLOGS = 1ull << 35,
+   RADV_DEBUG_NO_DMA_BLIT = 1ull << 36,
 };
 
 enum {
diff --git a/src/amd/vulkan/radv_device.c b/src/amd/vulkan/radv_device.c
index aac5f842b76..7f5f96a1436 100644
--- a/src/amd/vulkan/radv_device.c
+++ b/src/amd/vulkan/radv_device.c
@@ -856,6 +856,7 @@ static const struct debug_control radv_debug_options[] = {
    {"noatocdithering", RADV_DEBUG_NO_ATOC_DITHERING},
    {"nonggc", RADV_DEBUG_NO_NGGC},
    {"prologs", RADV_DEBUG_DUMP_PROLOGS},
+   {"nodma", RADV_DEBUG_NO_DMA_BLIT},
    {NULL, 0}};
 
 const char *
@@ -3069,6 +3070,7 @@ radv_CreateDevice(VkPhysicalDevice physicalDevice, const VkDeviceCreateInfo *pCr
       }
 
       memset(device->queues[qfi], 0, queue_create->queueCount * sizeof(struct radv_queue));
+      device->private_sdma_queue = NULL;
 
       device->queue_count[qfi] = queue_create->queueCount;
 
@@ -3769,6 +3771,9 @@ radv_get_preamble_cs(struct radv_queue *queue, uint32_t scratch_size_per_wave,
    unsigned tess_offchip_ring_offset;
    uint32_t ring_bo_flags = RADEON_FLAG_NO_CPU_ACCESS | RADEON_FLAG_NO_INTERPROCESS_SHARING;
    VkResult result = VK_SUCCESS;
+   if (queue->vk.queue_family_index == RADV_QUEUE_TRANSFER)
+      return VK_SUCCESS;
+
    if (!queue->has_tess_rings) {
       if (needs_tess_rings)
          add_tess_rings = true;
diff --git a/src/amd/vulkan/radv_meta_copy.c b/src/amd/vulkan/radv_meta_copy.c
index aed65196c3b..ba467eaceb6 100644
--- a/src/amd/vulkan/radv_meta_copy.c
+++ b/src/amd/vulkan/radv_meta_copy.c
@@ -263,6 +263,21 @@ copy_image_to_buffer(struct radv_cmd_buffer *cmd_buffer, struct radv_buffer *buf
                      struct radv_image *image, VkImageLayout layout,
                      const VkBufferImageCopy2KHR *region)
 {
+   if (cmd_buffer->pool->queue_family_index == RADV_QUEUE_TRANSFER) {
+      /* SDMA copy */
+      assert(!region->imageOffset.x && !region->imageOffset.y && !region->imageOffset.z);
+      assert(image->type == VK_IMAGE_TYPE_2D);
+      assert(image->info.width == region->imageExtent.width);
+      assert(image->info.height == region->imageExtent.height);
+
+      radv_cs_add_buffer(cmd_buffer->device->ws, cmd_buffer->cs,
+                         image->bo);
+      radv_cs_add_buffer(cmd_buffer->device->ws, cmd_buffer->cs,
+                         buffer->bo);
+      radv_sdma_copy_image(cmd_buffer, image, buffer, region);
+      return;
+   }
+
    struct radv_meta_saved_state saved_state;
    bool old_predicating;
 
diff --git a/src/amd/vulkan/radv_private.h b/src/amd/vulkan/radv_private.h
index fc5ac6a2a91..8362790be56 100644
--- a/src/amd/vulkan/radv_private.h
+++ b/src/amd/vulkan/radv_private.h
@@ -755,6 +755,7 @@ struct radv_device {
    struct radv_meta_state meta_state;
 
    struct radv_queue *queues[RADV_MAX_QUEUE_FAMILIES];
+   struct radv_queue *private_sdma_queue;
    int queue_count[RADV_MAX_QUEUE_FAMILIES];
    struct radeon_cmdbuf *empty_cs[RADV_MAX_QUEUE_FAMILIES];
 
@@ -2683,6 +2684,8 @@ void radv_emit_thread_trace_userdata(const struct radv_device *device, struct ra
                                      const void *data, uint32_t num_dwords);
 bool radv_is_instruction_timing_enabled(void);
 
+bool radv_sdma_copy_image(struct radv_cmd_buffer *cmd_buffer, struct radv_image *image, struct radv_buffer *buffer, const VkBufferImageCopy2KHR *region);
+
 /* radv_sqtt_layer_.c */
 struct radv_barrier_data {
    union {
diff --git a/src/amd/vulkan/radv_sdma_copy_image.c b/src/amd/vulkan/radv_sdma_copy_image.c
new file mode 100644
index 00000000000..ec6febc7d02
--- /dev/null
+++ b/src/amd/vulkan/radv_sdma_copy_image.c
@@ -0,0 +1,190 @@
+/*
+ * Copyright 2010 Jerome Glisse <glisse@freedesktop.org>
+ * Copyright 2015-2021 Advanced Micro Devices, Inc.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * on the rights to use, copy, modify, merge, publish, distribute, sub
+ * license, and/or sell copies of the Software, and to permit persons to whom
+ * the Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the next
+ * paragraph) shall be included in all copies or substantial portions of the
+ * Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL
+ * THE AUTHOR(S) AND/OR THEIR SUPPLIERS BE LIABLE FOR ANY CLAIM,
+ * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
+ * OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
+ * USE OR OTHER DEALINGS IN THE SOFTWARE.
+ */
+#include "radv_cs.h"
+#include "radv_private.h"
+#include "sid.h"
+#include "util/u_memory.h"
+
+
+static
+bool radv_translate_format_to_hw(struct radeon_info *info, VkFormat format, unsigned *hw_fmt, unsigned *hw_type)
+{
+   const struct util_format_description *desc = vk_format_description(format);
+   *hw_fmt = radv_translate_colorformat(format);
+
+   int firstchan;
+   for (firstchan = 0; firstchan < 4; firstchan++) {
+      if (desc->channel[firstchan].type != UTIL_FORMAT_TYPE_VOID) {
+         break;
+      }
+   }
+   if (firstchan == 4 || desc->channel[firstchan].type == UTIL_FORMAT_TYPE_FLOAT) {
+      *hw_type = V_028C70_NUMBER_FLOAT;
+   } else {
+      *hw_type = V_028C70_NUMBER_UNORM;
+      if (desc->colorspace == UTIL_FORMAT_COLORSPACE_SRGB)
+         *hw_type = V_028C70_NUMBER_SRGB;
+      else if (desc->channel[firstchan].type == UTIL_FORMAT_TYPE_SIGNED) {
+         if (desc->channel[firstchan].pure_integer) {
+            *hw_type = V_028C70_NUMBER_SINT;
+         } else {
+            assert(desc->channel[firstchan].normalized);
+            *hw_type = V_028C70_NUMBER_SNORM;
+         }
+      } else if (desc->channel[firstchan].type == UTIL_FORMAT_TYPE_UNSIGNED) {
+         if (desc->channel[firstchan].pure_integer) {
+            *hw_type = V_028C70_NUMBER_UINT;
+         } else {
+            assert(desc->channel[firstchan].normalized);
+            *hw_type = V_028C70_NUMBER_UNORM;
+         }
+      } else {
+         return false;
+      }
+   }
+   return true;
+}
+
+static
+bool radv_sdma_v4_v5_copy_image_to_buffer(struct radv_cmd_buffer *cmd_buffer, struct radv_image *image, struct radv_buffer *buffer, const VkBufferImageCopy2KHR *region)
+{
+   assert(image->plane_count == 1);
+   struct radv_device *device = cmd_buffer->device;
+   unsigned bpp = image->planes[0].surface.bpe;
+   uint64_t dst_address = buffer->bo->va;
+   uint64_t src_address = image->bo->va + image->planes[0].surface.u.gfx9.surf_offset;
+   unsigned src_pitch = image->planes[0].surface.u.gfx9.surf_pitch;
+   unsigned copy_width = DIV_ROUND_UP(image->info.width, image->planes[0].surface.blk_w);
+   unsigned copy_height = DIV_ROUND_UP(image->info.height, image->planes[0].surface.blk_h);
+   bool tmz = false;
+
+   uint32_t ib_pad_dw_mask = cmd_buffer->device->physical_device->rad_info.ib_pad_dw_mask[RING_DMA];
+
+   radeon_check_space(cmd_buffer->device->ws, cmd_buffer->cs, 32);
+
+   /* Linear -> linear sub-window copy. */
+   if (image->planes[0].surface.is_linear) {
+      unsigned bytes = src_pitch * copy_height * bpp;
+
+      if (!(bytes < (1u << 22)))
+         return false;
+
+      radeon_emit(cmd_buffer->cs, 0x00000000);
+
+      src_address += image->planes[0].surface.u.gfx9.offset[0];
+
+      radeon_emit(cmd_buffer->cs, CIK_SDMA_PACKET(CIK_SDMA_OPCODE_COPY,
+                                  CIK_SDMA_COPY_SUB_OPCODE_LINEAR,
+                                  (tmz ? 4 : 0)));
+      radeon_emit(cmd_buffer->cs, bytes);
+      radeon_emit(cmd_buffer->cs, 0);
+      radeon_emit(cmd_buffer->cs, src_address);
+      radeon_emit(cmd_buffer->cs, src_address >> 32);
+      radeon_emit(cmd_buffer->cs, dst_address);
+      radeon_emit(cmd_buffer->cs, dst_address >> 32);
+
+      while (cmd_buffer->cs->cdw & ib_pad_dw_mask)
+         radeon_emit(cmd_buffer->cs, 0x00000000); /* NOP packet */
+
+      return true;
+   }
+   /* Tiled sub-window copy -> Linear */
+   else {
+      unsigned tiled_width = copy_width;
+      unsigned tiled_height = copy_height;
+      unsigned linear_pitch = region->bufferRowLength;
+      unsigned linear_slice_pitch = region->bufferRowLength * copy_height;
+      uint64_t tiled_address = src_address;
+      uint64_t linear_address = dst_address;
+      bool is_v5 = device->physical_device->rad_info.chip_class >= GFX10;
+      /* Only SDMA 5 supports DCC with SDMA */
+      bool dcc = radv_dcc_enabled(image, 0) && is_v5;
+
+      /* Check if everything fits into the bitfields */
+      if (!(tiled_width < (1 << 14) && tiled_height < (1 << 14) &&
+            linear_pitch < (1 << 14) && linear_slice_pitch < (1 << 28) &&
+            copy_width < (1 << 14) && copy_height < (1 << 14)))
+         return false;
+
+      radeon_emit(cmd_buffer->cs, 0x00000000);
+      radeon_emit(cmd_buffer->cs, 
+         CIK_SDMA_PACKET(CIK_SDMA_OPCODE_COPY,
+                         CIK_SDMA_COPY_SUB_OPCODE_TILED_SUB_WINDOW,
+                         (tmz ? 4 : 0)) |
+         dcc << 19 |
+         (is_v5 ? 0 : 0 /* tiled->buffer.b.b.last_level */) << 20 |
+         1u << 31);
+      radeon_emit(cmd_buffer->cs, (uint32_t)tiled_address | (image->planes[0].surface.tile_swizzle << 8));
+      radeon_emit(cmd_buffer->cs, (uint32_t)(tiled_address >> 32));
+      radeon_emit(cmd_buffer->cs, 0);
+      radeon_emit(cmd_buffer->cs, ((tiled_width - 1) << 16));
+      radeon_emit(cmd_buffer->cs, (tiled_height - 1));
+      radeon_emit(cmd_buffer->cs, util_logbase2(bpp) |
+                  image->planes[0].surface.u.gfx9.swizzle_mode << 3 |
+                  image->planes[0].surface.u.gfx9.resource_type << 9 |
+                  (is_v5 ? 0 /* tiled->buffer.b.b.last_level */ : image->planes[0].surface.u.gfx9.epitch) << 16);
+      radeon_emit(cmd_buffer->cs, (uint32_t)linear_address);
+      radeon_emit(cmd_buffer->cs, (uint32_t)(linear_address >> 32));
+      radeon_emit(cmd_buffer->cs, 0);
+      radeon_emit(cmd_buffer->cs, ((linear_pitch - 1) << 16));
+      radeon_emit(cmd_buffer->cs, linear_slice_pitch - 1);
+      radeon_emit(cmd_buffer->cs, (copy_width - 1) | ((copy_height - 1) << 16));
+      radeon_emit(cmd_buffer->cs, 0);
+
+      if (dcc) {
+         unsigned hw_fmt, hw_type;
+         uint64_t md_address = tiled_address + image->planes[0].surface.meta_offset;
+
+         radv_translate_format_to_hw(&device->physical_device->rad_info, image->vk_format, &hw_fmt, &hw_type);
+
+         /* Add metadata */
+         radeon_emit(cmd_buffer->cs, (uint32_t)md_address);
+         radeon_emit(cmd_buffer->cs, (uint32_t)(md_address >> 32));
+         radeon_emit(cmd_buffer->cs, hw_fmt |
+                     vi_alpha_is_on_msb(device, image->vk_format) << 8 |
+                     hw_type << 9 |
+                     image->planes[0].surface.u.gfx9.color.dcc.max_compressed_block_size << 24 |
+                     V_028C78_MAX_BLOCK_SIZE_256B << 26 |
+                     tmz << 29 |
+                     image->planes[0].surface.u.gfx9.color.dcc.pipe_aligned << 31);
+      }
+
+      while (cmd_buffer->cs->cdw & ib_pad_dw_mask)
+         radeon_emit(cmd_buffer->cs, 0x00000000); /* NOP packet */
+
+      return true;
+   }
+
+   return false;
+}
+
+
+bool radv_sdma_copy_image(struct radv_cmd_buffer *cmd_buffer, struct radv_image *image, struct radv_buffer *buffer, const VkBufferImageCopy2KHR *region)
+{
+   assert(cmd_buffer->device->physical_device->rad_info.chip_class >= GFX10);
+   bool r = radv_sdma_v4_v5_copy_image_to_buffer(cmd_buffer, image, buffer, region);
+   assert(r);
+   return true;
+}
-- 
GitLab


From 771b1ec200cf7585ff2b4e00c9fe3a8b776d9e0c Mon Sep 17 00:00:00 2001
From: Pierre-Eric Pelloux-Prayer <pierre-eric.pelloux-prayer@amd.com>
Date: Mon, 6 Dec 2021 10:47:34 +0100
Subject: [PATCH 2/4] radv: allocate the prime buffer as uncached

This is a write only buffer so caches aren't needed.
---
 src/amd/vulkan/radv_device.c | 1 +
 1 file changed, 1 insertion(+)

diff --git a/src/amd/vulkan/radv_device.c b/src/amd/vulkan/radv_device.c
index 7f5f96a1436..53e72e664f5 100644
--- a/src/amd/vulkan/radv_device.c
+++ b/src/amd/vulkan/radv_device.c
@@ -5285,6 +5285,7 @@ radv_alloc_memory(struct radv_device *device, const VkMemoryAllocateInfo *pAlloc
        * only for memory allocated by driver this flag is set.
        */
       flags |= RADEON_FLAG_GTT_WC;
+      flags |= RADEON_FLAG_VA_UNCACHED;
    }
 
    if (dedicate_info) {
-- 
GitLab


From 511f176c1c459d68cd857e66197e6a8263b06eff Mon Sep 17 00:00:00 2001
From: Pierre-Eric Pelloux-Prayer <pierre-eric.pelloux-prayer@amd.com>
Date: Wed, 8 Dec 2021 14:05:15 +0100
Subject: [PATCH 3/4] vulkan/wsi: add a private transfer pool to exec the
 DRI_PRIME blit

The idea is to offer the driver a way to execute on a different queue
than the one the app is using for Present.

For instance, this could be used to make the DRI_PRIME blit asynchronous,
by using a transfer queue.

So instead of creating a command buffer to be executed on present using
the supplied queue, this commit uses an internal transfer queue to perform
the blit.
---
 src/vulkan/wsi/wsi_common.c         | 63 ++++++++++++++++++++++++++---
 src/vulkan/wsi/wsi_common.h         |  6 +++
 src/vulkan/wsi/wsi_common_drm.c     |  3 +-
 src/vulkan/wsi/wsi_common_private.h |  1 +
 src/vulkan/wsi/wsi_common_x11.c     | 20 ++++++++-
 5 files changed, 85 insertions(+), 8 deletions(-)

diff --git a/src/vulkan/wsi/wsi_common.c b/src/vulkan/wsi/wsi_common.c
index 2d18d4c62e1..afa15f76eb2 100644
--- a/src/vulkan/wsi/wsi_common.c
+++ b/src/vulkan/wsi/wsi_common.c
@@ -70,6 +70,7 @@ wsi_device_init(struct wsi_device *wsi,
 
    wsi->maxImageDimension2D = pdp2.properties.limits.maxImageDimension2D;
    wsi->override_present_mode = VK_PRESENT_MODE_MAX_ENUM_KHR;
+   wsi->private_queue_family_for_prime_blit = -1;
 
    GetPhysicalDeviceMemoryProperties(pdevice, &wsi->memory_props);
    GetPhysicalDeviceQueueFamilyProperties(pdevice, &wsi->queue_family_count, NULL);
@@ -231,18 +232,21 @@ wsi_swapchain_init(const struct wsi_device *wsi,
    chain->alloc = *pAllocator;
    chain->use_prime_blit = false;
 
+   int cmd_pools_count = wsi->private_queue_family_for_prime_blit >= 0 ? 1 : wsi->queue_family_count;
+
    chain->cmd_pools =
-      vk_zalloc(pAllocator, sizeof(VkCommandPool) * wsi->queue_family_count, 8,
+      vk_zalloc(pAllocator, sizeof(VkCommandPool) * cmd_pools_count, 8,
                 VK_SYSTEM_ALLOCATION_SCOPE_OBJECT);
    if (!chain->cmd_pools)
       return VK_ERROR_OUT_OF_HOST_MEMORY;
 
-   for (uint32_t i = 0; i < wsi->queue_family_count; i++) {
+   for (uint32_t i = 0; i < cmd_pools_count; i++) {
       const VkCommandPoolCreateInfo cmd_pool_info = {
          .sType = VK_STRUCTURE_TYPE_COMMAND_POOL_CREATE_INFO,
          .pNext = NULL,
          .flags = 0,
-         .queueFamilyIndex = i,
+         .queueFamilyIndex = wsi->private_queue_family_for_prime_blit >= 0 ?
+            wsi->private_queue_family_for_prime_blit : i,
       };
       result = wsi->CreateCommandPool(device, &cmd_pool_info, &chain->alloc,
                                       &chain->cmd_pools[i]);
@@ -542,6 +546,17 @@ wsi_CreateSwapchainKHR(VkDevice _device,
       return VK_ERROR_OUT_OF_HOST_MEMORY;
    }
 
+   if (wsi_device->private_queue_family_for_prime_blit >= 0) {
+      swapchain->prime_blit_fences = vk_zalloc(alloc,
+                                         sizeof (*swapchain->prime_blit_fences) * swapchain->image_count,
+                                         sizeof (*swapchain->prime_blit_fences),
+                                         VK_SYSTEM_ALLOCATION_SCOPE_OBJECT);
+      if (!swapchain->prime_blit_fences) {
+         swapchain->destroy(swapchain, alloc);
+         return VK_ERROR_OUT_OF_HOST_MEMORY;
+      }
+   }
+
    *pSwapchain = wsi_swapchain_to_handle(swapchain);
 
    return VK_SUCCESS;
@@ -652,6 +667,20 @@ wsi_common_acquire_next_image2(const struct wsi_device *wsi,
                                    image->memory);
    }
 
+   if (swapchain->use_prime_blit && wsi->private_queue_family_for_prime_blit >= 0) {
+      if (swapchain->fences[*pImageIndex] != VK_NULL_HANDLE) {
+         result =
+            wsi->WaitForFences(_device, 1, &swapchain->prime_blit_fences[*pImageIndex],
+                               true, ~0ull);
+         if (result != VK_SUCCESS)
+            return result;
+
+         result = wsi->ResetFences(_device, 1, &swapchain->prime_blit_fences[*pImageIndex]);
+         if (result != VK_SUCCESS)
+            return result;
+      }
+   }
+
    return result;
 }
 
@@ -694,6 +723,19 @@ wsi_common_queue_present(const struct wsi_device *wsi,
                                    &swapchain->fences[image_index]);
          if (result != VK_SUCCESS)
             goto fail_present;
+
+         if (swapchain->use_prime_blit && wsi->private_queue_family_for_prime_blit >= 0) {
+            const VkFenceCreateInfo fence_info = {
+               .sType = VK_STRUCTURE_TYPE_FENCE_CREATE_INFO,
+               .pNext = NULL,
+               .flags = 0,
+            };
+            result = wsi->CreateFence(device, &fence_info,
+                                      &swapchain->alloc,
+                                      &swapchain->prime_blit_fences[image_index]);
+            if (result != VK_SUCCESS)
+               goto fail_present;
+         }
       } else {
          result =
             wsi->WaitForFences(device, 1, &swapchain->fences[image_index],
@@ -750,8 +792,19 @@ wsi_common_queue_present(const struct wsi_device *wsi,
           * command buffer is attached to the image.
           */
          submit_info.commandBufferCount = 1;
-         submit_info.pCommandBuffers =
-            &image->prime.blit_cmd_buffers[queue_family_index];
+
+         if (wsi->private_queue_family_for_prime_blit >= 0) {
+            submit_info.pCommandBuffers = &image->prime.blit_cmd_buffers[0];
+            /* Submit the copy to the private transfer queue */
+            result = wsi->QueueSubmit(queue, 1, &submit_info, swapchain->prime_blit_fences[image_index]);
+
+            submit_info.commandBufferCount = 0;
+            submit_info.waitSemaphoreCount = 0;
+            submit_info.pCommandBuffers = NULL;
+         } else {
+            submit_info.pCommandBuffers =
+               &image->prime.blit_cmd_buffers[queue_family_index];
+         }
          mem_signal.memory = image->prime.memory;
       }
 
diff --git a/src/vulkan/wsi/wsi_common.h b/src/vulkan/wsi/wsi_common.h
index 63f21ef698b..1afaed807e2 100644
--- a/src/vulkan/wsi/wsi_common.h
+++ b/src/vulkan/wsi/wsi_common.h
@@ -107,6 +107,12 @@ struct wsi_device {
     * available. Not all window systems might support this. */
    bool enable_adaptive_sync;
 
+   /* If the driver wants to use a special queue to execute the prime blit,
+    * it just has to set this to the queue_family_index it wants to use.
+    * -1 is the default value and means that the prime blit is executed on
+    * the present queue. */
+   int private_queue_family_for_prime_blit;
+
    /* List of fences to signal when hotplug event happens. */
    struct list_head hotplug_fences;
 
diff --git a/src/vulkan/wsi/wsi_common_drm.c b/src/vulkan/wsi/wsi_common_drm.c
index 09684b2272d..2305ac232cf 100644
--- a/src/vulkan/wsi/wsi_common_drm.c
+++ b/src/vulkan/wsi/wsi_common_drm.c
@@ -590,7 +590,8 @@ wsi_create_prime_image(const struct wsi_swapchain *chain,
       goto fail;
    }
 
-   for (uint32_t i = 0; i < wsi->queue_family_count; i++) {
+   int cmd_buffer_count = wsi->private_queue_family_for_prime_blit >= 0 ? 1 : wsi->queue_family_count;
+   for (uint32_t i = 0; i < cmd_buffer_count; i++) {
       const VkCommandBufferAllocateInfo cmd_buffer_info = {
          .sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_ALLOCATE_INFO,
          .pNext = NULL,
diff --git a/src/vulkan/wsi/wsi_common_private.h b/src/vulkan/wsi/wsi_common_private.h
index 3eb14d22f9e..66f80af0ebf 100644
--- a/src/vulkan/wsi/wsi_common_private.h
+++ b/src/vulkan/wsi/wsi_common_private.h
@@ -52,6 +52,7 @@ struct wsi_swapchain {
    VkDevice device;
    VkAllocationCallbacks alloc;
    VkFence* fences;
+   VkFence* prime_blit_fences;
    VkPresentModeKHR present_mode;
    uint32_t image_count;
 
diff --git a/src/vulkan/wsi/wsi_common_x11.c b/src/vulkan/wsi/wsi_common_x11.c
index de9794cd1f0..a279c51ae3e 100644
--- a/src/vulkan/wsi/wsi_common_x11.c
+++ b/src/vulkan/wsi/wsi_common_x11.c
@@ -1799,10 +1799,26 @@ x11_surface_create_swapchain(VkIcdSurfaceBase *icd_surface,
     */
    chain->copy_is_suboptimal = false;
 
-   if (!wsi_device->sw)
-      if (!wsi_x11_check_dri3_compatible(wsi_device, conn))
+   if (!wsi_device->sw) {
+      if (!wsi_x11_check_dri3_compatible(wsi_device, conn)) {
          chain->base.use_prime_blit = true;
 
+         #if 0
+         /* Add a private transfer command pool for executing the prime blit */
+         if (wsi_device->private_queue_family_for_prime_blit >= 0) {
+            const VkCommandPoolCreateInfo cmd_pool_info = {
+               .sType = VK_STRUCTURE_TYPE_COMMAND_POOL_CREATE_INFO,
+               .pNext = NULL,
+               .flags = 0,
+               .queueFamilyIndex = wsi_device->private_queue_family_for_prime_blit,
+            };
+            result = wsi_device->CreateCommandPool(device, &cmd_pool_info, &chain->base.alloc,
+                                                   &chain->base.cmd_pools[0]);
+         }
+         #endif
+      }
+   }
+
    chain->event_id = xcb_generate_id(chain->conn);
    xcb_present_select_input(chain->conn, chain->event_id, chain->window,
                             XCB_PRESENT_EVENT_MASK_CONFIGURE_NOTIFY |
-- 
GitLab


From f4584fa9fcaa96210edce43a2d328ab84986c1a0 Mon Sep 17 00:00:00 2001
From: Pierre-Eric Pelloux-Prayer <pierre-eric.pelloux-prayer@amd.com>
Date: Wed, 8 Dec 2021 14:07:43 +0100
Subject: [PATCH 4/4] radv: implement wsi's private transfer queue using SDMA

This uses RADV_QUEUE_TRANSFER_PRIVATE to identify this specific queue.
---
 src/amd/vulkan/radv_cmd_buffer.c | 23 ++++++++++++++++++++++-
 src/amd/vulkan/radv_device.c     | 15 ++++++++++++++-
 src/amd/vulkan/radv_image.c      |  9 +++++++++
 src/amd/vulkan/radv_meta_copy.c  |  3 ++-
 src/amd/vulkan/radv_private.h    | 12 +++++++++---
 src/amd/vulkan/radv_wsi.c        |  6 ++++++
 6 files changed, 62 insertions(+), 6 deletions(-)

diff --git a/src/amd/vulkan/radv_cmd_buffer.c b/src/amd/vulkan/radv_cmd_buffer.c
index ccc49a1df8c..78d1f7b7508 100644
--- a/src/amd/vulkan/radv_cmd_buffer.c
+++ b/src/amd/vulkan/radv_cmd_buffer.c
@@ -384,6 +384,7 @@ radv_queue_family_to_ring(int f)
    case RADV_QUEUE_COMPUTE:
       return RING_COMPUTE;
    case RADV_QUEUE_TRANSFER:
+   case RADV_QUEUE_TRANSFER_PRIVATE:
       return RING_DMA;
    default:
       unreachable("Unknown queue family");
@@ -5764,6 +5765,7 @@ radv_CreateCommandPool(VkDevice _device, const VkCommandPoolCreateInfo *pCreateI
 {
    RADV_FROM_HANDLE(radv_device, device, _device);
    struct radv_cmd_pool *pool;
+   VkResult result;
 
    pool =
       vk_alloc2(&device->vk.alloc, pAllocator, sizeof(*pool), 8, VK_SYSTEM_ALLOCATION_SCOPE_OBJECT);
@@ -5784,7 +5786,26 @@ radv_CreateCommandPool(VkDevice _device, const VkCommandPoolCreateInfo *pCreateI
 
    *pCmdPool = radv_cmd_pool_to_handle(pool);
 
-   return VK_SUCCESS;
+   result = VK_SUCCESS;
+
+   if (pool->queue_family_index == RADV_QUEUE_TRANSFER_PRIVATE) {
+      if (!device->private_sdma_queue) {
+         const VkDeviceQueueCreateInfo queue_create = {
+            .sType = VK_STRUCTURE_TYPE_DEVICE_QUEUE_CREATE_INFO,
+            .queueFamilyIndex = RADV_QUEUE_TRANSFER,
+            .queueCount = 1,
+         };
+         device->private_sdma_queue = vk_alloc(
+               &device->vk.alloc, sizeof(struct radv_queue), 8,
+               VK_SYSTEM_ALLOCATION_SCOPE_DEVICE);
+         memset(device->private_sdma_queue, 0, sizeof(struct radv_queue));
+         result = radv_queue_init(device, device->private_sdma_queue, 0,
+                                  &queue_create, NULL);
+         assert(result == VK_SUCCESS);
+      }
+   }
+
+   return result;
 }
 
 VKAPI_ATTR void VKAPI_CALL
diff --git a/src/amd/vulkan/radv_device.c b/src/amd/vulkan/radv_device.c
index 53e72e664f5..18a7970ee0c 100644
--- a/src/amd/vulkan/radv_device.c
+++ b/src/amd/vulkan/radv_device.c
@@ -2581,7 +2581,7 @@ radv_get_queue_global_priority(const VkDeviceQueueGlobalPriorityCreateInfoEXT *p
    }
 }
 
-static int
+int
 radv_queue_init(struct radv_device *device, struct radv_queue *queue,
                 int idx, const VkDeviceQueueCreateInfo *create_info,
                 const VkDeviceQueueGlobalPriorityCreateInfoEXT *global_priority)
@@ -3325,6 +3325,11 @@ radv_DestroyDevice(VkDevice _device, const VkAllocationCallbacks *pAllocator)
          device->ws->cs_destroy(device->empty_cs[i]);
    }
 
+   if (device->private_sdma_queue) {
+      radv_queue_finish(device->private_sdma_queue);
+      vk_free(&device->vk.alloc, device->private_sdma_queue);
+   }
+
    for (unsigned i = 0; i < RADV_NUM_HW_CTX; i++) {
       if (device->hw_ctx[i])
          device->ws->ctx_destroy(device->hw_ctx[i]);
@@ -5011,6 +5016,14 @@ radv_QueueSubmit2KHR(VkQueue _queue, uint32_t submitCount, const VkSubmitInfo2KH
    uint32_t fence_idx = 0;
    bool flushed_caches = false;
 
+   if (submitCount == 1 && pSubmits[0].commandBufferInfoCount == 1) {
+      RADV_FROM_HANDLE(radv_cmd_buffer, cmd_buffer, pSubmits[0].pCommandBufferInfos[0].commandBuffer);
+      struct radv_device *device = queue->device;
+
+      if (cmd_buffer->pool->queue_family_index == RADV_QUEUE_TRANSFER_PRIVATE)
+         queue = device->private_sdma_queue;
+   }
+
    if (radv_device_is_lost(queue->device))
       return VK_ERROR_DEVICE_LOST;
 
diff --git a/src/amd/vulkan/radv_image.c b/src/amd/vulkan/radv_image.c
index 554249dc54e..c714f0f15b8 100644
--- a/src/amd/vulkan/radv_image.c
+++ b/src/amd/vulkan/radv_image.c
@@ -528,6 +528,13 @@ radv_patch_image_from_extra_info(struct radv_device *device, struct radv_image *
 
          image->info.surf_index = NULL;
       }
+
+      if (create_info->prime_blit_src &&
+          device->physical_device->vk.wsi_device->private_queue_family_for_prime_blit >= 0 &&
+          device->physical_device->rad_info.chip_class < GFX10) {
+         /* Older SDMA hw can't handle DCC */
+         image->planes[plane].surface.flags |= RADEON_SURF_DISABLE_DCC;
+      }
    }
    return VK_SUCCESS;
 }
@@ -2232,11 +2239,13 @@ radv_CreateImage(VkDevice device, const VkImageCreateInfo *pCreateInfo,
    const struct wsi_image_create_info *wsi_info =
       vk_find_struct_const(pCreateInfo->pNext, WSI_IMAGE_CREATE_INFO_MESA);
    bool scanout = wsi_info && wsi_info->scanout;
+   bool prime_blit_src = wsi_info && wsi_info->prime_blit_src;
 
    return radv_image_create(device,
                             &(struct radv_image_create_info){
                                .vk_info = pCreateInfo,
                                .scanout = scanout,
+                               .prime_blit_src = prime_blit_src,
                             },
                             pAllocator, pImage);
 }
diff --git a/src/amd/vulkan/radv_meta_copy.c b/src/amd/vulkan/radv_meta_copy.c
index ba467eaceb6..9e318cf6841 100644
--- a/src/amd/vulkan/radv_meta_copy.c
+++ b/src/amd/vulkan/radv_meta_copy.c
@@ -263,7 +263,8 @@ copy_image_to_buffer(struct radv_cmd_buffer *cmd_buffer, struct radv_buffer *buf
                      struct radv_image *image, VkImageLayout layout,
                      const VkBufferImageCopy2KHR *region)
 {
-   if (cmd_buffer->pool->queue_family_index == RADV_QUEUE_TRANSFER) {
+   if (cmd_buffer->pool->queue_family_index == RADV_QUEUE_TRANSFER ||
+       cmd_buffer->pool->queue_family_index == RADV_QUEUE_TRANSFER_PRIVATE) {
       /* SDMA copy */
       assert(!region->imageOffset.x && !region->imageOffset.y && !region->imageOffset.z);
       assert(image->type == VK_IMAGE_TYPE_2D);
diff --git a/src/amd/vulkan/radv_private.h b/src/amd/vulkan/radv_private.h
index 8362790be56..a5dc3919095 100644
--- a/src/amd/vulkan/radv_private.h
+++ b/src/amd/vulkan/radv_private.h
@@ -668,9 +668,10 @@ struct radv_meta_state {
 };
 
 /* queue types */
-#define RADV_QUEUE_GENERAL  0
-#define RADV_QUEUE_COMPUTE  1
-#define RADV_QUEUE_TRANSFER 2
+#define RADV_QUEUE_GENERAL          0
+#define RADV_QUEUE_COMPUTE          1
+#define RADV_QUEUE_TRANSFER         2
+#define RADV_QUEUE_TRANSFER_PRIVATE 3
 
 /* Not a real queue family */
 #define RADV_QUEUE_FOREIGN 3
@@ -2334,6 +2335,7 @@ struct radv_image_create_info {
    const VkImageCreateInfo *vk_info;
    bool scanout;
    bool no_metadata_planes;
+   bool prime_blit_src;
    const struct radeon_bo_metadata *bo_metadata;
 };
 
@@ -2611,6 +2613,10 @@ struct radv_semaphore {
 
 bool radv_queue_internal_submit(struct radv_queue *queue, struct radeon_cmdbuf *cs);
 
+int radv_queue_init(struct radv_device *device, struct radv_queue *queue, int idx,
+                    const VkDeviceQueueCreateInfo *create_info,
+                    const VkDeviceQueueGlobalPriorityCreateInfoEXT *global_priority);
+
 void radv_set_descriptor_set(struct radv_cmd_buffer *cmd_buffer, VkPipelineBindPoint bind_point,
                              struct radv_descriptor_set *set, unsigned idx);
 
diff --git a/src/amd/vulkan/radv_wsi.c b/src/amd/vulkan/radv_wsi.c
index a8e79585969..fa15f249e90 100644
--- a/src/amd/vulkan/radv_wsi.c
+++ b/src/amd/vulkan/radv_wsi.c
@@ -24,6 +24,7 @@
  */
 
 #include "util/macros.h"
+#include "radv_debug.h"
 #include "radv_meta.h"
 #include "radv_private.h"
 #include "vk_util.h"
@@ -64,6 +65,11 @@ radv_init_wsi(struct radv_physical_device *physical_device)
 
    physical_device->vk.wsi_device = &physical_device->wsi_device;
 
+   if (physical_device->rad_info.chip_class >= GFX9 &&
+       !(physical_device->instance->debug_flags & RADV_DEBUG_NO_DMA_BLIT)) {
+      physical_device->vk.wsi_device->private_queue_family_for_prime_blit = RADV_QUEUE_TRANSFER_PRIVATE;
+   }
+
    return VK_SUCCESS;
 }
 
-- 
GitLab

