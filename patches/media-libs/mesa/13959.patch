From 91bfdfe364d75ede6b7f593466706e0bbb5591a2 Mon Sep 17 00:00:00 2001
From: Pierre-Eric Pelloux-Prayer <pierre-eric.pelloux-prayer@amd.com>
Date: Thu, 25 Nov 2021 10:12:56 +0100
Subject: [PATCH 1/3] radv: partial sdma support

SDMA code adapted from https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/12763

The only supported use case is image (linear or tiled) -> buffer and only GFX9+ is
supported (for now).

TODO: dcc decompression
---
 src/amd/vulkan/meson.build            |   1 +
 src/amd/vulkan/radv_debug.h           |   1 +
 src/amd/vulkan/radv_device.c          |   5 +
 src/amd/vulkan/radv_private.h         |   3 +
 src/amd/vulkan/radv_sdma_copy_image.c | 192 ++++++++++++++++++++++++++
 5 files changed, 202 insertions(+)
 create mode 100644 src/amd/vulkan/radv_sdma_copy_image.c

diff --git a/src/amd/vulkan/meson.build b/src/amd/vulkan/meson.build
index c5e4bc2e1cd..ed8345cefa1 100644
--- a/src/amd/vulkan/meson.build
+++ b/src/amd/vulkan/meson.build
@@ -75,6 +75,7 @@ libradv_files = files(
   'radv_pipeline_rt.c',
   'radv_private.h',
   'radv_radeon_winsys.h',
+  'radv_sdma_copy_image.c',
   'radv_shader.c',
   'radv_shader.h',
   'radv_shader_args.c',
diff --git a/src/amd/vulkan/radv_debug.h b/src/amd/vulkan/radv_debug.h
index 5c0dd14220e..22abbc3829f 100644
--- a/src/amd/vulkan/radv_debug.h
+++ b/src/amd/vulkan/radv_debug.h
@@ -64,6 +64,7 @@ enum {
    RADV_DEBUG_NO_ATOC_DITHERING = 1ull << 33,
    RADV_DEBUG_NO_NGGC = 1ull << 34,
    RADV_DEBUG_DUMP_PROLOGS = 1ull << 35,
+   RADV_DEBUG_NO_DMA_BLIT = 1ull << 36,
 };
 
 enum {
diff --git a/src/amd/vulkan/radv_device.c b/src/amd/vulkan/radv_device.c
index aac5f842b76..7f5f96a1436 100644
--- a/src/amd/vulkan/radv_device.c
+++ b/src/amd/vulkan/radv_device.c
@@ -856,6 +856,7 @@ static const struct debug_control radv_debug_options[] = {
    {"noatocdithering", RADV_DEBUG_NO_ATOC_DITHERING},
    {"nonggc", RADV_DEBUG_NO_NGGC},
    {"prologs", RADV_DEBUG_DUMP_PROLOGS},
+   {"nodma", RADV_DEBUG_NO_DMA_BLIT},
    {NULL, 0}};
 
 const char *
@@ -3069,6 +3070,7 @@ radv_CreateDevice(VkPhysicalDevice physicalDevice, const VkDeviceCreateInfo *pCr
       }
 
       memset(device->queues[qfi], 0, queue_create->queueCount * sizeof(struct radv_queue));
+      device->private_sdma_queue = NULL;
 
       device->queue_count[qfi] = queue_create->queueCount;
 
@@ -3769,6 +3771,9 @@ radv_get_preamble_cs(struct radv_queue *queue, uint32_t scratch_size_per_wave,
    unsigned tess_offchip_ring_offset;
    uint32_t ring_bo_flags = RADEON_FLAG_NO_CPU_ACCESS | RADEON_FLAG_NO_INTERPROCESS_SHARING;
    VkResult result = VK_SUCCESS;
+   if (queue->vk.queue_family_index == RADV_QUEUE_TRANSFER)
+      return VK_SUCCESS;
+
    if (!queue->has_tess_rings) {
       if (needs_tess_rings)
          add_tess_rings = true;
diff --git a/src/amd/vulkan/radv_private.h b/src/amd/vulkan/radv_private.h
index fc5ac6a2a91..8362790be56 100644
--- a/src/amd/vulkan/radv_private.h
+++ b/src/amd/vulkan/radv_private.h
@@ -755,6 +755,7 @@ struct radv_device {
    struct radv_meta_state meta_state;
 
    struct radv_queue *queues[RADV_MAX_QUEUE_FAMILIES];
+   struct radv_queue *private_sdma_queue;
    int queue_count[RADV_MAX_QUEUE_FAMILIES];
    struct radeon_cmdbuf *empty_cs[RADV_MAX_QUEUE_FAMILIES];
 
@@ -2683,6 +2684,8 @@ void radv_emit_thread_trace_userdata(const struct radv_device *device, struct ra
                                      const void *data, uint32_t num_dwords);
 bool radv_is_instruction_timing_enabled(void);
 
+bool radv_sdma_copy_image(struct radv_cmd_buffer *cmd_buffer, struct radv_image *image, struct radv_buffer *buffer, const VkBufferImageCopy2KHR *region);
+
 /* radv_sqtt_layer_.c */
 struct radv_barrier_data {
    union {
diff --git a/src/amd/vulkan/radv_sdma_copy_image.c b/src/amd/vulkan/radv_sdma_copy_image.c
new file mode 100644
index 00000000000..c08b41c2117
--- /dev/null
+++ b/src/amd/vulkan/radv_sdma_copy_image.c
@@ -0,0 +1,192 @@
+/*
+ * Copyright 2010 Jerome Glisse <glisse@freedesktop.org>
+ * Copyright 2015-2021 Advanced Micro Devices, Inc.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * on the rights to use, copy, modify, merge, publish, distribute, sub
+ * license, and/or sell copies of the Software, and to permit persons to whom
+ * the Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the next
+ * paragraph) shall be included in all copies or substantial portions of the
+ * Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL
+ * THE AUTHOR(S) AND/OR THEIR SUPPLIERS BE LIABLE FOR ANY CLAIM,
+ * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
+ * OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
+ * USE OR OTHER DEALINGS IN THE SOFTWARE.
+ */
+#include "radv_cs.h"
+#include "radv_private.h"
+#include "sid.h"
+#include "util/u_memory.h"
+
+
+static
+bool radv_translate_format_to_hw(struct radeon_info *info, VkFormat format, unsigned *hw_fmt, unsigned *hw_type)
+{
+   const struct util_format_description *desc = vk_format_description(format);
+   *hw_fmt = radv_translate_colorformat(format);
+
+   int firstchan;
+   for (firstchan = 0; firstchan < 4; firstchan++) {
+      if (desc->channel[firstchan].type != UTIL_FORMAT_TYPE_VOID) {
+         break;
+      }
+   }
+   if (firstchan == 4 || desc->channel[firstchan].type == UTIL_FORMAT_TYPE_FLOAT) {
+      *hw_type = V_028C70_NUMBER_FLOAT;
+   } else {
+      *hw_type = V_028C70_NUMBER_UNORM;
+      if (desc->colorspace == UTIL_FORMAT_COLORSPACE_SRGB)
+         *hw_type = V_028C70_NUMBER_SRGB;
+      else if (desc->channel[firstchan].type == UTIL_FORMAT_TYPE_SIGNED) {
+         if (desc->channel[firstchan].pure_integer) {
+            *hw_type = V_028C70_NUMBER_SINT;
+         } else {
+            assert(desc->channel[firstchan].normalized);
+            *hw_type = V_028C70_NUMBER_SNORM;
+         }
+      } else if (desc->channel[firstchan].type == UTIL_FORMAT_TYPE_UNSIGNED) {
+         if (desc->channel[firstchan].pure_integer) {
+            *hw_type = V_028C70_NUMBER_UINT;
+         } else {
+            assert(desc->channel[firstchan].normalized);
+            *hw_type = V_028C70_NUMBER_UNORM;
+         }
+      } else {
+         return false;
+      }
+   }
+   return true;
+}
+
+static
+bool radv_sdma_v4_v5_copy_image_to_buffer(struct radv_cmd_buffer *cmd_buffer, struct radv_image *image, struct radv_buffer *buffer, const VkBufferImageCopy2KHR *region)
+{
+   assert(image->plane_count == 1);
+   struct radv_device *device = cmd_buffer->device;
+   unsigned bpp = image->planes[0].surface.bpe;
+   uint64_t dst_address = buffer->bo->va;
+   uint64_t src_address = image->bo->va + image->planes[0].surface.u.gfx9.surf_offset;
+   unsigned src_pitch = image->planes[0].surface.u.gfx9.surf_pitch;
+   unsigned copy_width = DIV_ROUND_UP(image->info.width, image->planes[0].surface.blk_w);
+   unsigned copy_height = DIV_ROUND_UP(image->info.height, image->planes[0].surface.blk_h);
+   bool tmz = false;
+
+   uint32_t ib_pad_dw_mask = cmd_buffer->device->physical_device->rad_info.ib_pad_dw_mask[RING_DMA];
+
+   radeon_check_space(cmd_buffer->device->ws, cmd_buffer->cs, 32);
+
+   /* Linear -> linear sub-window copy. */
+   if (image->planes[0].surface.is_linear) {
+      unsigned bytes = src_pitch * copy_height * bpp;
+
+      if (!(bytes < (1u << 22)))
+         return false;
+
+      radeon_emit(cmd_buffer->cs, 0x00000000);
+
+      src_address += image->planes[0].surface.u.gfx9.offset[0];
+
+      radeon_emit(cmd_buffer->cs, CIK_SDMA_PACKET(CIK_SDMA_OPCODE_COPY,
+                                  CIK_SDMA_COPY_SUB_OPCODE_LINEAR,
+                                  (tmz ? 4 : 0)));
+      radeon_emit(cmd_buffer->cs, bytes);
+      radeon_emit(cmd_buffer->cs, 0);
+      radeon_emit(cmd_buffer->cs, src_address);
+      radeon_emit(cmd_buffer->cs, src_address >> 32);
+      radeon_emit(cmd_buffer->cs, dst_address);
+      radeon_emit(cmd_buffer->cs, dst_address >> 32);
+
+      while (cmd_buffer->cs->cdw & ib_pad_dw_mask)
+         radeon_emit(cmd_buffer->cs, 0x00000000); /* NOP packet */
+
+      return true;
+   }
+   /* Tiled sub-window copy -> Linear */
+   else {
+      unsigned tiled_width = copy_width;
+      unsigned tiled_height = copy_height;
+      unsigned linear_pitch = region->bufferRowLength;
+      unsigned linear_slice_pitch = region->bufferRowLength * copy_height;
+      uint64_t tiled_address = src_address;
+      uint64_t linear_address = dst_address;
+      bool is_v5 = device->physical_device->rad_info.chip_class >= GFX10;
+      /* Only SDMA 5 supports DCC with SDMA */
+      bool dcc = radv_dcc_enabled(image, 0) && is_v5;
+
+      /* TODO: dcc decompress */
+
+      /* Check if everything fits into the bitfields */
+      if (!(tiled_width < (1 << 14) && tiled_height < (1 << 14) &&
+            linear_pitch < (1 << 14) && linear_slice_pitch < (1 << 28) &&
+            copy_width < (1 << 14) && copy_height < (1 << 14)))
+         return false;
+
+      radeon_emit(cmd_buffer->cs, 0x00000000);
+      radeon_emit(cmd_buffer->cs, 
+         CIK_SDMA_PACKET(CIK_SDMA_OPCODE_COPY,
+                         CIK_SDMA_COPY_SUB_OPCODE_TILED_SUB_WINDOW,
+                         (tmz ? 4 : 0)) |
+         dcc << 19 |
+         (is_v5 ? 0 : 0 /* tiled->buffer.b.b.last_level */) << 20 |
+         1u << 31);
+      radeon_emit(cmd_buffer->cs, (uint32_t)tiled_address | (image->planes[0].surface.tile_swizzle << 8));
+      radeon_emit(cmd_buffer->cs, (uint32_t)(tiled_address >> 32));
+      radeon_emit(cmd_buffer->cs, 0);
+      radeon_emit(cmd_buffer->cs, ((tiled_width - 1) << 16));
+      radeon_emit(cmd_buffer->cs, (tiled_height - 1));
+      radeon_emit(cmd_buffer->cs, util_logbase2(bpp) |
+                  image->planes[0].surface.u.gfx9.swizzle_mode << 3 |
+                  image->planes[0].surface.u.gfx9.resource_type << 9 |
+                  (is_v5 ? 0 /* tiled->buffer.b.b.last_level */ : image->planes[0].surface.u.gfx9.epitch) << 16);
+      radeon_emit(cmd_buffer->cs, (uint32_t)linear_address);
+      radeon_emit(cmd_buffer->cs, (uint32_t)(linear_address >> 32));
+      radeon_emit(cmd_buffer->cs, 0);
+      radeon_emit(cmd_buffer->cs, ((linear_pitch - 1) << 16));
+      radeon_emit(cmd_buffer->cs, linear_slice_pitch - 1);
+      radeon_emit(cmd_buffer->cs, (copy_width - 1) | ((copy_height - 1) << 16));
+      radeon_emit(cmd_buffer->cs, 0);
+
+      if (dcc) {
+         unsigned hw_fmt, hw_type;
+         uint64_t md_address = tiled_address + image->planes[0].surface.meta_offset;
+
+         radv_translate_format_to_hw(&device->physical_device->rad_info, image->vk_format, &hw_fmt, &hw_type);
+
+         /* Add metadata */
+         radeon_emit(cmd_buffer->cs, (uint32_t)md_address);
+         radeon_emit(cmd_buffer->cs, (uint32_t)(md_address >> 32));
+         radeon_emit(cmd_buffer->cs, hw_fmt |
+                     vi_alpha_is_on_msb(device, image->vk_format) << 8 |
+                     hw_type << 9 |
+                     image->planes[0].surface.u.gfx9.color.dcc.max_compressed_block_size << 24 |
+                     V_028C78_MAX_BLOCK_SIZE_256B << 26 |
+                     tmz << 29 |
+                     image->planes[0].surface.u.gfx9.color.dcc.pipe_aligned << 31);
+      }
+
+      while (cmd_buffer->cs->cdw & ib_pad_dw_mask)
+         radeon_emit(cmd_buffer->cs, 0x00000000); /* NOP packet */
+
+      return true;
+   }
+
+   return false;
+}
+
+
+bool radv_sdma_copy_image(struct radv_cmd_buffer *cmd_buffer, struct radv_image *image, struct radv_buffer *buffer, const VkBufferImageCopy2KHR *region)
+{
+   assert(cmd_buffer->device->physical_device->rad_info.chip_class >= GFX10);
+   bool r = radv_sdma_v4_v5_copy_image_to_buffer(cmd_buffer, image, buffer, region);
+   assert(r);
+   return true;
+}
-- 
GitLab


From 453af40a40c1f48799994fb8e41e4cebc78a5dd0 Mon Sep 17 00:00:00 2001
From: Pierre-Eric Pelloux-Prayer <pierre-eric.pelloux-prayer@amd.com>
Date: Mon, 6 Dec 2021 10:47:34 +0100
Subject: [PATCH 2/3] radv: allocate the prime buffer as uncached

This is a write only buffer so caches aren't needed.
---
 src/amd/vulkan/radv_device.c | 1 +
 1 file changed, 1 insertion(+)

diff --git a/src/amd/vulkan/radv_device.c b/src/amd/vulkan/radv_device.c
index 7f5f96a1436..53e72e664f5 100644
--- a/src/amd/vulkan/radv_device.c
+++ b/src/amd/vulkan/radv_device.c
@@ -5285,6 +5285,7 @@ radv_alloc_memory(struct radv_device *device, const VkMemoryAllocateInfo *pAlloc
        * only for memory allocated by driver this flag is set.
        */
       flags |= RADEON_FLAG_GTT_WC;
+      flags |= RADEON_FLAG_VA_UNCACHED;
    }
 
    if (dedicate_info) {
-- 
GitLab


From 64330835e3d7ba725c61b39535ddaf814de4bb2b Mon Sep 17 00:00:00 2001
From: Pierre-Eric Pelloux-Prayer <pierre-eric.pelloux-prayer@amd.com>
Date: Thu, 25 Nov 2021 14:08:28 +0100
Subject: [PATCH 3/3] vulkan/wsi,radv: add a private SDMA pool to exec the
 DRI_PRIME blit

Based on https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/12763.

The idea is to make the DRI_PRIME blit completely asynchronous using SDMA.

So instead of creating a command buffer to be executed on present using
the supplied queue, this commit uses an internal SDMA queue to perform
the blit.

The change in radv_QueueSubmit is definitely hacky, but allowed me to test.
Maybe this private_sdma_queue (private_transfer_queue?) should be moved to
vulkan/wsi.

Similarly, when SDMA is used, the original command buffers created in
wsi_create_prime_image become unused (because the SDMA one is always used).
This could probably be cleaned up.
---
 src/amd/vulkan/radv_device.c        | 22 ++++++++++++
 src/amd/vulkan/radv_meta_copy.c     | 15 ++++++++
 src/amd/vulkan/radv_wsi.c           |  5 +++
 src/vulkan/wsi/wsi_common.c         | 56 +++++++++++++++++++++++++++--
 src/vulkan/wsi/wsi_common.h         |  2 ++
 src/vulkan/wsi/wsi_common_drm.c     |  3 +-
 src/vulkan/wsi/wsi_common_private.h |  1 +
 src/vulkan/wsi/wsi_common_x11.c     | 18 ++++++++--
 8 files changed, 116 insertions(+), 6 deletions(-)

diff --git a/src/amd/vulkan/radv_device.c b/src/amd/vulkan/radv_device.c
index 53e72e664f5..cc82114295a 100644
--- a/src/amd/vulkan/radv_device.c
+++ b/src/amd/vulkan/radv_device.c
@@ -5011,6 +5011,28 @@ radv_QueueSubmit2KHR(VkQueue _queue, uint32_t submitCount, const VkSubmitInfo2KH
    uint32_t fence_idx = 0;
    bool flushed_caches = false;
 
+   if (submitCount == 1 && pSubmits[0].commandBufferInfoCount == 1) {
+      RADV_FROM_HANDLE(radv_cmd_buffer, cmd_buffer, pSubmits[0].pCommandBufferInfos[0].commandBuffer);
+      if (cmd_buffer->pool->queue_family_index == 2) {
+         struct radv_device *device = queue->device;
+         if (!queue->device->private_sdma_queue) {
+            const VkDeviceQueueCreateInfo queue_create = {
+               .sType = VK_STRUCTURE_TYPE_DEVICE_QUEUE_CREATE_INFO,
+               .queueFamilyIndex = RADV_QUEUE_TRANSFER,
+               .queueCount = 1,
+            };
+            device->private_sdma_queue = vk_alloc(
+                  &device->vk.alloc, sizeof(struct radv_queue), 8,
+                  VK_SYSTEM_ALLOCATION_SCOPE_DEVICE);
+            memset(device->private_sdma_queue, 0, sizeof(struct radv_queue));
+            result = radv_queue_init(device, device->private_sdma_queue, 0,
+                                     &queue_create, NULL);
+            assert(result == VK_SUCCESS);
+         }
+         queue = device->private_sdma_queue;
+      }
+   }
+
    if (radv_device_is_lost(queue->device))
       return VK_ERROR_DEVICE_LOST;
 
diff --git a/src/amd/vulkan/radv_meta_copy.c b/src/amd/vulkan/radv_meta_copy.c
index aed65196c3b..ba467eaceb6 100644
--- a/src/amd/vulkan/radv_meta_copy.c
+++ b/src/amd/vulkan/radv_meta_copy.c
@@ -263,6 +263,21 @@ copy_image_to_buffer(struct radv_cmd_buffer *cmd_buffer, struct radv_buffer *buf
                      struct radv_image *image, VkImageLayout layout,
                      const VkBufferImageCopy2KHR *region)
 {
+   if (cmd_buffer->pool->queue_family_index == RADV_QUEUE_TRANSFER) {
+      /* SDMA copy */
+      assert(!region->imageOffset.x && !region->imageOffset.y && !region->imageOffset.z);
+      assert(image->type == VK_IMAGE_TYPE_2D);
+      assert(image->info.width == region->imageExtent.width);
+      assert(image->info.height == region->imageExtent.height);
+
+      radv_cs_add_buffer(cmd_buffer->device->ws, cmd_buffer->cs,
+                         image->bo);
+      radv_cs_add_buffer(cmd_buffer->device->ws, cmd_buffer->cs,
+                         buffer->bo);
+      radv_sdma_copy_image(cmd_buffer, image, buffer, region);
+      return;
+   }
+
    struct radv_meta_saved_state saved_state;
    bool old_predicating;
 
diff --git a/src/amd/vulkan/radv_wsi.c b/src/amd/vulkan/radv_wsi.c
index a8e79585969..9f02566b599 100644
--- a/src/amd/vulkan/radv_wsi.c
+++ b/src/amd/vulkan/radv_wsi.c
@@ -24,6 +24,7 @@
  */
 
 #include "util/macros.h"
+#include "radv_debug.h"
 #include "radv_meta.h"
 #include "radv_private.h"
 #include "vk_util.h"
@@ -64,6 +65,10 @@ radv_init_wsi(struct radv_physical_device *physical_device)
 
    physical_device->vk.wsi_device = &physical_device->wsi_device;
 
+   physical_device->vk.wsi_device->allow_present_sdma =
+      physical_device->rad_info.chip_class >= GFX9 &&
+      !(physical_device->instance->debug_flags & RADV_DEBUG_NO_DMA_BLIT);
+
    return VK_SUCCESS;
 }
 
diff --git a/src/vulkan/wsi/wsi_common.c b/src/vulkan/wsi/wsi_common.c
index 2d18d4c62e1..3dd538e3218 100644
--- a/src/vulkan/wsi/wsi_common.c
+++ b/src/vulkan/wsi/wsi_common.c
@@ -232,7 +232,7 @@ wsi_swapchain_init(const struct wsi_device *wsi,
    chain->use_prime_blit = false;
 
    chain->cmd_pools =
-      vk_zalloc(pAllocator, sizeof(VkCommandPool) * wsi->queue_family_count, 8,
+      vk_zalloc(pAllocator, sizeof(VkCommandPool) * (wsi->queue_family_count + (wsi->allow_present_sdma ? 1 : 0)), 8,
                 VK_SYSTEM_ALLOCATION_SCOPE_OBJECT);
    if (!chain->cmd_pools)
       return VK_ERROR_OUT_OF_HOST_MEMORY;
@@ -542,6 +542,17 @@ wsi_CreateSwapchainKHR(VkDevice _device,
       return VK_ERROR_OUT_OF_HOST_MEMORY;
    }
 
+   if (wsi_device->allow_present_sdma) {
+      swapchain->sdma_fences = vk_zalloc(alloc,
+                                         sizeof (*swapchain->sdma_fences) * swapchain->image_count,
+                                         sizeof (*swapchain->sdma_fences),
+                                         VK_SYSTEM_ALLOCATION_SCOPE_OBJECT);
+      if (!swapchain->sdma_fences) {
+         swapchain->destroy(swapchain, alloc);
+         return VK_ERROR_OUT_OF_HOST_MEMORY;
+      }
+   }
+
    *pSwapchain = wsi_swapchain_to_handle(swapchain);
 
    return VK_SUCCESS;
@@ -652,6 +663,20 @@ wsi_common_acquire_next_image2(const struct wsi_device *wsi,
                                    image->memory);
    }
 
+   if (swapchain->use_prime_blit && wsi->allow_present_sdma) {
+      if (swapchain->fences[*pImageIndex] != VK_NULL_HANDLE) {
+         result =
+            wsi->WaitForFences(device, 1, &swapchain->sdma_fences[*pImageIndex],
+                               true, ~0ull);
+         if (result != VK_SUCCESS)
+            return result;
+
+         result = wsi->ResetFences(device, 1, &swapchain->sdma_fences[*pImageIndex]);
+         if (result != VK_SUCCESS)
+            return result;
+      }
+   }
+
    return result;
 }
 
@@ -694,6 +719,19 @@ wsi_common_queue_present(const struct wsi_device *wsi,
                                    &swapchain->fences[image_index]);
          if (result != VK_SUCCESS)
             goto fail_present;
+
+         if (swapchain->use_prime_blit && wsi->allow_present_sdma) {
+            const VkFenceCreateInfo fence_info = {
+               .sType = VK_STRUCTURE_TYPE_FENCE_CREATE_INFO,
+               .pNext = NULL,
+               .flags = 0,
+            };
+            result = wsi->CreateFence(device, &fence_info,
+                                      &swapchain->alloc,
+                                      &swapchain->sdma_fences[image_index]);
+            if (result != VK_SUCCESS)
+               goto fail_present;
+         }
       } else {
          result =
             wsi->WaitForFences(device, 1, &swapchain->fences[image_index],
@@ -750,8 +788,20 @@ wsi_common_queue_present(const struct wsi_device *wsi,
           * command buffer is attached to the image.
           */
          submit_info.commandBufferCount = 1;
-         submit_info.pCommandBuffers =
-            &image->prime.blit_cmd_buffers[queue_family_index];
+
+         if (wsi->allow_present_sdma) {
+            submit_info.pCommandBuffers =
+               &image->prime.blit_cmd_buffers[wsi->queue_family_count];
+            /* Submit the copy to the SDMA queue */
+            result = wsi->QueueSubmit(queue, 1, &submit_info, swapchain->sdma_fences[image_index]);
+
+            submit_info.commandBufferCount = 0;
+            submit_info.waitSemaphoreCount = 0;
+            submit_info.pCommandBuffers = NULL;
+         } else {
+            submit_info.pCommandBuffers =
+               &image->prime.blit_cmd_buffers[queue_family_index];
+         }
          mem_signal.memory = image->prime.memory;
       }
 
diff --git a/src/vulkan/wsi/wsi_common.h b/src/vulkan/wsi/wsi_common.h
index 63f21ef698b..c6a17931080 100644
--- a/src/vulkan/wsi/wsi_common.h
+++ b/src/vulkan/wsi/wsi_common.h
@@ -107,6 +107,8 @@ struct wsi_device {
     * available. Not all window systems might support this. */
    bool enable_adaptive_sync;
 
+   bool allow_present_sdma;
+
    /* List of fences to signal when hotplug event happens. */
    struct list_head hotplug_fences;
 
diff --git a/src/vulkan/wsi/wsi_common_drm.c b/src/vulkan/wsi/wsi_common_drm.c
index 09684b2272d..81e98fca6c4 100644
--- a/src/vulkan/wsi/wsi_common_drm.c
+++ b/src/vulkan/wsi/wsi_common_drm.c
@@ -590,7 +590,8 @@ wsi_create_prime_image(const struct wsi_swapchain *chain,
       goto fail;
    }
 
-   for (uint32_t i = 0; i < wsi->queue_family_count; i++) {
+   /* TODO: or create a single CommandBuffer when allow_present_sdma is enabled? */
+   for (uint32_t i = 0; i < wsi->queue_family_count + wsi->allow_present_sdma ? 1 : 0; i++) {
       const VkCommandBufferAllocateInfo cmd_buffer_info = {
          .sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_ALLOCATE_INFO,
          .pNext = NULL,
diff --git a/src/vulkan/wsi/wsi_common_private.h b/src/vulkan/wsi/wsi_common_private.h
index 3eb14d22f9e..b28d053aff5 100644
--- a/src/vulkan/wsi/wsi_common_private.h
+++ b/src/vulkan/wsi/wsi_common_private.h
@@ -52,6 +52,7 @@ struct wsi_swapchain {
    VkDevice device;
    VkAllocationCallbacks alloc;
    VkFence* fences;
+   VkFence* sdma_fences;
    VkPresentModeKHR present_mode;
    uint32_t image_count;
 
diff --git a/src/vulkan/wsi/wsi_common_x11.c b/src/vulkan/wsi/wsi_common_x11.c
index de9794cd1f0..1be8c512379 100644
--- a/src/vulkan/wsi/wsi_common_x11.c
+++ b/src/vulkan/wsi/wsi_common_x11.c
@@ -1799,10 +1799,24 @@ x11_surface_create_swapchain(VkIcdSurfaceBase *icd_surface,
     */
    chain->copy_is_suboptimal = false;
 
-   if (!wsi_device->sw)
-      if (!wsi_x11_check_dri3_compatible(wsi_device, conn))
+   if (!wsi_device->sw) {
+      if (!wsi_x11_check_dri3_compatible(wsi_device, conn)) {
          chain->base.use_prime_blit = true;
 
+         /* Add a private SDMA command pool */
+         if (wsi_device->allow_present_sdma) {
+            const VkCommandPoolCreateInfo cmd_pool_info = {
+               .sType = VK_STRUCTURE_TYPE_COMMAND_POOL_CREATE_INFO,
+               .pNext = NULL,
+               .flags = 0,
+               .queueFamilyIndex = 2,
+            };
+            result = wsi_device->CreateCommandPool(device, &cmd_pool_info, &chain->base.alloc,
+                                                   &chain->base.cmd_pools[wsi_device->queue_family_count]);
+         }
+      }
+   }
+
    chain->event_id = xcb_generate_id(chain->conn);
    xcb_present_select_input(chain->conn, chain->event_id, chain->window,
                             XCB_PRESENT_EVENT_MASK_CONFIGURE_NOTIFY |
-- 
GitLab

